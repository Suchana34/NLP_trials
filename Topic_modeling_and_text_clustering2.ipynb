{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Topic_modeling and text_clustering2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJoWX-SHqODB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "import gensim\n",
        "from gensim import corpora,models\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models import CoherenceModel\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
        "from nltk.stem.porter import *\n",
        "import numpy as np\n",
        "np.random.seed(2018)\n",
        "\n",
        "#!pip install pyLDAvis\n",
        "\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim \n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Enable logging for gensim - optional\n",
        "import logging\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
        "\n",
        "#import warnings\n",
        "#warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RneP_reKNV00",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this will slove broken link issue with nltk using ssl.\n",
        "#import ssl\n",
        "#try:\n",
        "#    _create_unverified_https_context = ssl._create_unverified_context\n",
        "#except AttributeError:\n",
        "#    pass\n",
        "#else:\n",
        "#    ssl._create_default_https_context = _create_unverified_https_context"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5L5AIMlZ2hoo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "fe7ec0cf-102a-4034-8155-6ee29a9199a6"
      },
      "source": [
        "import nltk\n",
        "#nltk.download('wordnet')\n",
        "#nltk.download('stopwords')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJa95bXeDLH3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oh-Vw6uA2hks",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv('/content/drive/My Drive/result1.csv');"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSoWwYeuGCWM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "506308c4-8652-44e2-eafe-7172eac526fe"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(162, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFRwGMjhZlPL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.dropna(subset=['content'], inplace = True)\n",
        "data.dropna(subset = ['topic'], inplace = True)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImSvOSrMaGWz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b856159e-e967-485e-ac94-baed552ed404"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(148, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBVVZIpe2hjX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data preprocessing\n",
        "stemmer = SnowballStemmer(language='english',ignore_stopwords=True)\n",
        "def lemmatize_stemming(text):\n",
        "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
        "def preprocess(text):\n",
        "    result = []\n",
        "    for token in gensim.utils.simple_preprocess(text):\n",
        "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
        "            result.append(lemmatize_stemming(token))\n",
        "    return result"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIfyn-R72hgb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "9b212a75-10f5-4b65-b732-4965ba1d7148"
      },
      "source": [
        "# preview after preprocessing\n",
        "doc_sample = data.content[0]\n",
        "print('original document: ')\n",
        "words = []\n",
        "for word in doc_sample.split(' '):\n",
        "    words.append(word)\n",
        "print(words)\n",
        "print('\\n\\n tokenized and lemmatized document: ')\n",
        "print(preprocess(doc_sample))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "original document: \n",
            "['[\"Prime', 'Minister', '(PM)', 'Narendra', 'Modi', 'recently', 'announced', 'that', 'India', 'must', 'become', '\",\"(self-reliant).', 'One', 'aspect', 'of', 'this', 'could', 'be', 'that', 'India', 'will', 'remove', 'barriers', 'within', 'its', 'internal', 'markets', 'to', 'truly', 'become', 'a', 'single', 'market.', 'It', 'will', 'remove', 'the', 'hurdles', 'to', 'efficiency', 'improvements', 'and', 'become', 'more', 'competitive.', 'The', 'Goods', 'and', 'Services', 'Tax', '(GST)', 'was', 'a', 'step', 'in', 'this', 'direction.', 'Recent', 'decisions', 'to', 'remove', 'hurdles', 'in', 'inter-state', 'agricultural', 'trade', 'are', 'also', 'similar.', 'For', 'agricultural', 'and', 'industrial', 'products,', 'as', 'well', 'as', 'capital,', 'India', 'is', 'increasingly', 'becoming', 'a', 'single', 'market.', 'The', 'creation', 'of', 'a', 'barrier-free', 'domestic', 'market', 'is', 'also', 'an', 'intent', 'reflected', 'in', 'Article', '301', 'of', 'the', 'Constitution.\",\"However,', 'there', 'is', 'one', 'market', 'where', 'frictions', 'are', 'being', 'added', 'rather', 'than', 'reduced.', 'This', 'is', 'the', 'labour', 'market.', 'For', 'different', 'reasons,', 'leaders', 'from', 'out-migration', 'and', 'in-migration', 'states', 'have', 'made', 'statements', 'suggesting', 'that', 'there', 'may', 'be', 'more', 'impediments', 'to', 'the', 'inter-state', 'migration', 'of', 'workers.', 'Some', 'states', 'have', 'announced', 'preferential', 'treatment', 'for', 'workers', 'from', 'within', 'the', 'state.', 'Others', 'have', 'spoken', 'of', 'instituting', 'an', 'approval', 'system', 'before', 'allowing', 'their', 'workers', 'to', 'move', 'to', 'other', 'states,', 'in', 'the', 'backdrop', 'of', 'how', 'they', 'were', 'treated.\",\"There', 'are', 'compelling', 'reasons', 'for', 'internal', 'migration', 'in', 'India.\",\"First,', 'India', 'has', 'much', 'higher', 'economic', 'differences', 'across', 'states', 'than', 'comparable', 'countries', '—', 'with', 'the', 'per', 'capita', 'income', 'of', 'the', 'richest', 'large', 'state', '(Haryana)', 'being', 'more', 'than', 'six', 'times', 'that', 'of', 'the', 'poorest', 'state', '(Bihar).', 'The', 'wage', 'gap', 'between', 'states', 'is', 'as', 'high', 'as', '100%', 'for', 'regular', 'workers', 'and', '250%', 'for', 'casual', 'workers.', 'It', 'is,', 'therefore,', 'no', 'wonder', 'that', 'workers', 'from', 'the', 'poorer', 'states', 'migrate', 'to', 'richer', 'states', 'for', 'work.', 'As', 'of', 'now,', 'the', 'best', 'option', 'for', 'many', 'poor', 'people', 'looking', 'to', 'escape', 'poverty', 'is', 'to', 'leave', 'the', 'states', 'they', 'live', 'in,', 'because', 'of', 'economic', 'opportunities', 'in', 'richer', 'states.', 'This', 'movement', 'is', 'difficult', 'since', 'the', 'cost', 'of', 'living', 'is', 'also', 'higher', 'in', 'richer', 'states.', 'However,', 'millions', 'still', 'migrate', 'and', 'brave', 'squalid', 'conditions', 'in', 'in-migration', 'states', 'because', 'they', 'need', 'livelihoods.\",\"Second,', 'some', 'of', 'the', 'poorer', 'states', 'such', 'as', 'Uttar', 'Pradesh', 'and', 'Bihar', 'have', 'younger', 'and', 'larger', 'populations,', 'with', 'many', 'more', 'workers', 'than', 'work', 'opportunities.', 'While', 'these', 'states', 'must', 'develop', 'their', 'economies,', 'in', 'the', 'short-term,', 'migration', 'is', 'an', 'essential', 'component', 'of', 'development', 'for', 'them.\",\"Third,', 'India’s', 'growth', 'has', 'been', 'largely', 'services-led.', 'For', 'most', 'services,', 'the', 'availability', 'of', 'physical', 'labour', 'is', 'essential.', 'For', 'services', 'such', 'as', 'cooking,', 'driving,', 'hairdressing', 'and', 'security,', 'there', 'is', 'a', 'need', 'for', 'workers', 'to', 'be', 'physically', 'present', 'to', 'provide', 'the', 'service.\",\"While', 'beneficial', 'for', 'migrants,', 'migration', 'also', 'has', 'negative', 'implications.', 'Migration', 'can', 'put', 'downward', 'pressure', 'on', 'wages', 'in', 'richer', 'states,', 'with', 'the', 'increase', 'in', 'the', 'supply', 'of', 'workers.', 'This', 'creates', 'an', 'incentive', 'for', 'regional', 'and', 'local', 'leaders', 'to', 'generate', 'anti-migrant', 'sentiments,', 'and', 'to', 'promote', 'policies', 'that', 'favour', 'local', 'workers.', 'This', 'dynamic', 'is', 'not', 'very', 'different', 'from', 'the', 'one', 'seen', 'in', 'international', 'migration', '—', 'after', 'a', 'point,', 'a', 'political', 'economy', 'develops', 'to', 'oppose', 'migration.\",\"Throughout', 'India’s', 'history,', 'states', 'have', 'enacted', 'laws', 'and', 'measures', 'that', 'are', 'discriminatory', 'vis-à-vis', 'non-resident', 'migrants.', 'Many', 'state', 'laws', 'discourage', 'or', 'prevent', 'non-residents', 'from', 'applying', 'for', 'government', 'jobs', 'or', 'other', 'professions', 'that', 'require', 'government', 'licensing', '(auto,', 'taxi', 'licences),', 'or', 'deny', 'them', 'the', 'benefits', 'of', 'educational', 'reservations.', 'Other', 'laws,', 'prevalent', 'in', 'some', 'states', 'of', 'the', 'Northeast,', 'regulate', 'the', 'entry', 'of', 'non-residents', 'within', 'the', 'state.', 'Yet', 'another', 'category', 'of', 'laws', 'prevents', 'non-residents', 'from', 'owning', 'property', '(such', 'as', 'in', 'Himachal', 'Pradesh,', 'Uttarakhand', 'and', 'others).', 'The', 'Union', 'government', 'has', 'recently', 'announced', '“One', 'Nation', 'One', 'Ration', 'Card”', 'because', 'non-resident', 'migrants', 'are', 'currently', 'ineligible', 'for', 'many', 'state', 'welfare', 'schemes.\",\"Even', 'though', 'Article', '19(1)(d)', 'of', 'the', 'Constitution', 'guarantees', 'free', 'movement', 'and', 'residence,', 'states', 'have', 'enacted', '“reasonable', 'restrictions”', 'to', 'disfavour', 'non-resident', 'migrants.', 'Article', '16', 'outlaws', 'discrimination', 'in', 'employment', 'on', 'the', 'grounds', 'of', 'residence,', 'but', 'the', 'criteria', 'for', 'determining', 'reservations', 'is', 'usually', 'linked', 'to', 'local', 'demographic', 'characteristics.', 'The', 'courts', 'have', 'also', 'largely', 'upheld', 'positive', 'discrimination', 'in', 'employment', 'and', 'education', 'that', 'nonetheless', 'discriminates', 'against', 'non-residents.', 'They', 'have', 'upheld', 'not', 'just', 'residency', 'as', 'a', 'ground', 'for', 'eligibility', 'for', 'jobs', 'and', 'educational', 'seats,', 'but', 'also', 'the', 'charging', 'of', 'differential', 'capitation', 'fees', 'based', 'on', 'residency.', 'In', 'doing', 'so,', 'courts', 'have', 'generally', 'privileged', 'the', 'equality', 'interests', 'in', 'the', 'Constitution', 'at', 'the', 'cost', 'of', 'free', 'movement', 'and', 'residence.\",\"While', 'such', 'measures', 'ostensibly', 'serve', 'to', 'protect', 'local', 'constituents,', 'they', 'inhibit', 'migration', 'and', 'thus', 'the', 'law', 'of', 'comparative', 'advantage', 'from', 'operating', 'to', 'the', 'benefit', 'of', 'in-migration', 'states.', 'Bengaluru', 'could', 'not', 'have', 'become', 'a', 'hub', 'for', 'information', 'technology', 'if', 'it', 'had', 'imposed', 'restrictions', 'on', 'the', 'movement', 'of', 'skilled', 'professional', 'migrants', 'who', 'eventually', 'settled', 'in', 'the', 'city.', 'Contrary', 'to', 'nativist', 'sentiments,', 'Karnataka’s', 'population', 'has', 'been', 'a', 'net', 'beneficiary', 'of', 'this', 'in-migration', 'because', 'of', 'the', 'increased', 'contribution', 'of', 'Bengaluru', 'to', 'Karnataka’s', 'Gross', 'Domestic', 'Product', '(GDP)', 'besides', 'the', 'value', 'of', 'diversity.\",\"This', 'benefit', 'is', 'not', 'limited', 'to', 'skilled', 'or', 'high-end', 'services.', 'To', 'the', 'extent', 'that', 'Bengaluru’s', 'economy', 'powers', 'Karnataka’s', 'growth,', 'a', 'migrant', 'hairdresser', 'working', 'in', 'Bangalore', 'is', 'also', 'important', 'for', 'the', 'state’s', 'economy.', 'This', 'was', 'evident', 'recently', 'when', 'the', 'Karnataka', 'government', 'wanted', 'to', 'prevent', 'migrants', 'from', 'leaving', 'for', 'their', 'home', 'states', 'because', 'of', 'their', 'importance', 'to', 'the', 'construction', 'industry.', 'It', 'is,', 'therefore,', 'time', 'to', 'seriously', 're-examine', 'the', 'legal', 'framework', 'that', 'inhibits', 'the', 'movement', 'of', 'migrants', 'across', 'the', 'country,', 'and', 'prevents', 'them', 'from', 'accessing', 'safety,', 'shelter', 'and', 'welfare', 'services', 'on', 'equal', 'terms', 'as', 'residents.\"]']\n",
            "\n",
            "\n",
            " tokenized and lemmatized document: \n",
            "['prime', 'minist', 'narendra', 'modi', 'recent', 'announc', 'india', 'self', 'reliant', 'aspect', 'india', 'remov', 'barrier', 'intern', 'market', 'truli', 'singl', 'market', 'remov', 'hurdl', 'effici', 'improv', 'competit', 'good', 'servic', 'step', 'direct', 'recent', 'decis', 'remov', 'hurdl', 'inter', 'state', 'agricultur', 'trade', 'similar', 'agricultur', 'industri', 'product', 'capit', 'india', 'increas', 'singl', 'market', 'creation', 'barrier', 'free', 'domest', 'market', 'intent', 'reflect', 'articl', 'constitut', 'market', 'friction', 'add', 'reduc', 'labour', 'market', 'differ', 'reason', 'leader', 'migrat', 'migrat', 'state', 'statement', 'suggest', 'impedi', 'inter', 'state', 'migrat', 'worker', 'state', 'announc', 'preferenti', 'treatment', 'worker', 'state', 'speak', 'institut', 'approv', 'allow', 'worker', 'state', 'backdrop', 'treat', 'compel', 'reason', 'intern', 'migrat', 'india', 'india', 'higher', 'econom', 'differ', 'state', 'compar', 'countri', 'capita', 'incom', 'richest', 'larg', 'state', 'haryana', 'time', 'poorest', 'state', 'bihar', 'wage', 'state', 'high', 'regular', 'worker', 'casual', 'worker', 'wonder', 'worker', 'poorer', 'state', 'migrat', 'richer', 'state', 'work', 'best', 'option', 'poor', 'peopl', 'look', 'escap', 'poverti', 'leav', 'state', 'live', 'econom', 'opportun', 'richer', 'state', 'movement', 'difficult', 'cost', 'live', 'higher', 'richer', 'state', 'million', 'migrat', 'brave', 'squalid', 'condit', 'migrat', 'state', 'need', 'livelihood', 'second', 'poorer', 'state', 'uttar', 'pradesh', 'bihar', 'younger', 'larger', 'popul', 'worker', 'work', 'opportun', 'state', 'develop', 'economi', 'short', 'term', 'migrat', 'essenti', 'compon', 'develop', 'india', 'growth', 'larg', 'servic', 'servic', 'avail', 'physic', 'labour', 'essenti', 'servic', 'cook', 'drive', 'hairdress', 'secur', 'need', 'worker', 'physic', 'present', 'provid', 'servic', 'benefici', 'migrant', 'migrat', 'negat', 'implic', 'migrat', 'downward', 'pressur', 'wag', 'richer', 'state', 'increas', 'suppli', 'worker', 'creat', 'incent', 'region', 'local', 'leader', 'generat', 'anti', 'migrant', 'sentiment', 'promot', 'polici', 'favour', 'local', 'worker', 'dynam', 'differ', 'see', 'intern', 'migrat', 'point', 'polit', 'economi', 'develop', 'oppos', 'migrat', 'india', 'histori', 'state', 'enact', 'law', 'measur', 'discriminatori', 'resid', 'migrant', 'state', 'law', 'discourag', 'prevent', 'resid', 'appli', 'govern', 'job', 'profess', 'requir', 'govern', 'licens', 'auto', 'taxi', 'licenc', 'deni', 'benefit', 'educ', 'reserv', 'law', 'preval', 'state', 'northeast', 'regul', 'entri', 'resid', 'state', 'categori', 'law', 'prevent', 'resid', 'own', 'properti', 'himach', 'pradesh', 'uttarakhand', 'union', 'govern', 'recent', 'announc', 'nation', 'ration', 'card', 'resid', 'migrant', 'current', 'inelig', 'state', 'welfar', 'scheme', 'articl', 'constitut', 'guarante', 'free', 'movement', 'resid', 'state', 'enact', 'reason', 'restrict', 'disfavour', 'resid', 'migrant', 'articl', 'outlaw', 'discrimin', 'employ', 'ground', 'resid', 'criteria', 'determin', 'reserv', 'usual', 'link', 'local', 'demograph', 'characterist', 'court', 'larg', 'uphold', 'posit', 'discrimin', 'employ', 'educ', 'nonetheless', 'discrimin', 'resid', 'uphold', 'resid', 'grind', 'elig', 'job', 'educ', 'seat', 'charg', 'differenti', 'capit', 'fee', 'base', 'resid', 'court', 'general', 'privileg', 'equal', 'interest', 'constitut', 'cost', 'free', 'movement', 'resid', 'measur', 'ostens', 'serv', 'protect', 'local', 'constitu', 'inhibit', 'migrat', 'compar', 'advantag', 'oper', 'benefit', 'migrat', 'state', 'bengaluru', 'inform', 'technolog', 'impos', 'restrict', 'movement', 'skill', 'profession', 'migrant', 'eventu', 'settl', 'citi', 'contrari', 'nativist', 'sentiment', 'karnataka', 'popul', 'beneficiari', 'migrat', 'increas', 'contribut', 'bengaluru', 'karnataka', 'gross', 'domest', 'product', 'valu', 'divers', 'benefit', 'limit', 'skill', 'high', 'servic', 'extent', 'bengaluru', 'economi', 'power', 'karnataka', 'growth', 'migrant', 'hairdress', 'work', 'bangalor', 'import', 'state', 'economi', 'evid', 'recent', 'karnataka', 'govern', 'want', 'prevent', 'migrant', 'leav', 'home', 'state', 'import', 'construct', 'industri', 'time', 'serious', 'examin', 'legal', 'framework', 'inhibit', 'movement', 'migrant', 'countri', 'prevent', 'access', 'safeti', 'shelter', 'welfar', 'servic', 'equal', 'term', 'resid']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIVgkjVL2hec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preprocess the headline text, saving the results as ‘processed_docs’\n",
        "processed_docs = data['content'].map(preprocess)\n",
        "#processed_docs.head(5)\n",
        "data['processed_heading'] = processed_docs"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bH4pXIp2aVc_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data['removed_list'] = data['processed_heading'].apply(lambda x: ' '.join(x))\n",
        "#data.head(2)\n",
        "#removed_list = data.removed_list"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQhU10ZPcb7c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "09664774-9185-486f-e04c-3d3bee515506"
      },
      "source": [
        "#Create a dictionary from ‘processed_docs’ containing the number of times a word appears in the training set\n",
        "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
        "count = 0\n",
        "for k, v in dictionary.iteritems():\n",
        "    print(k, v)\n",
        "    count += 1\n",
        "    if count > 10:\n",
        "        break"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 access\n",
            "1 add\n",
            "2 advantag\n",
            "3 agricultur\n",
            "4 allow\n",
            "5 announc\n",
            "6 anti\n",
            "7 appli\n",
            "8 approv\n",
            "9 articl\n",
            "10 aspect\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqIPcn6Ccb5E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9H40fDHXcb1v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8577e592-7e78-4e66-e224-5431691884a4"
      },
      "source": [
        "# gensim doc2bow\n",
        "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
        "bow_corpus[0]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 1),\n",
              " (1, 1),\n",
              " (2, 1),\n",
              " (3, 2),\n",
              " (4, 1),\n",
              " (5, 3),\n",
              " (6, 1),\n",
              " (7, 1),\n",
              " (8, 1),\n",
              " (9, 3),\n",
              " (10, 1),\n",
              " (11, 1),\n",
              " (12, 1),\n",
              " (13, 1),\n",
              " (14, 1),\n",
              " (15, 2),\n",
              " (16, 1),\n",
              " (17, 1),\n",
              " (18, 1),\n",
              " (19, 3),\n",
              " (20, 3),\n",
              " (21, 1),\n",
              " (22, 2),\n",
              " (23, 1),\n",
              " (24, 2),\n",
              " (25, 1),\n",
              " (26, 1),\n",
              " (27, 1),\n",
              " (28, 1),\n",
              " (29, 1),\n",
              " (30, 1),\n",
              " (31, 1),\n",
              " (32, 2),\n",
              " (33, 1),\n",
              " (34, 1),\n",
              " (35, 1),\n",
              " (36, 1),\n",
              " (37, 1),\n",
              " (38, 3),\n",
              " (39, 1),\n",
              " (40, 1),\n",
              " (41, 1),\n",
              " (42, 1),\n",
              " (43, 2),\n",
              " (44, 2),\n",
              " (45, 2),\n",
              " (46, 1),\n",
              " (47, 1),\n",
              " (48, 1),\n",
              " (49, 1),\n",
              " (50, 1),\n",
              " (51, 1),\n",
              " (52, 1),\n",
              " (53, 1),\n",
              " (54, 3),\n",
              " (55, 3),\n",
              " (56, 1),\n",
              " (57, 1),\n",
              " (58, 1),\n",
              " (59, 1),\n",
              " (60, 3),\n",
              " (61, 1),\n",
              " (62, 1),\n",
              " (63, 1),\n",
              " (64, 2),\n",
              " (65, 1),\n",
              " (66, 1),\n",
              " (67, 1),\n",
              " (68, 2),\n",
              " (69, 4),\n",
              " (70, 3),\n",
              " (71, 1),\n",
              " (72, 1),\n",
              " (73, 2),\n",
              " (74, 2),\n",
              " (75, 1),\n",
              " (76, 2),\n",
              " (77, 1),\n",
              " (78, 2),\n",
              " (79, 1),\n",
              " (80, 1),\n",
              " (81, 1),\n",
              " (82, 1),\n",
              " (83, 1),\n",
              " (84, 1),\n",
              " (85, 1),\n",
              " (86, 3),\n",
              " (87, 1),\n",
              " (88, 1),\n",
              " (89, 1),\n",
              " (90, 1),\n",
              " (91, 4),\n",
              " (92, 1),\n",
              " (93, 1),\n",
              " (94, 1),\n",
              " (95, 2),\n",
              " (96, 1),\n",
              " (97, 2),\n",
              " (98, 1),\n",
              " (99, 2),\n",
              " (100, 2),\n",
              " (101, 1),\n",
              " (102, 1),\n",
              " (103, 1),\n",
              " (104, 2),\n",
              " (105, 1),\n",
              " (106, 1),\n",
              " (107, 2),\n",
              " (108, 1),\n",
              " (109, 1),\n",
              " (110, 1),\n",
              " (111, 1),\n",
              " (112, 3),\n",
              " (113, 7),\n",
              " (114, 2),\n",
              " (115, 1),\n",
              " (116, 1),\n",
              " (117, 2),\n",
              " (118, 1),\n",
              " (119, 1),\n",
              " (120, 2),\n",
              " (121, 1),\n",
              " (122, 3),\n",
              " (123, 2),\n",
              " (124, 4),\n",
              " (125, 2),\n",
              " (126, 3),\n",
              " (127, 1),\n",
              " (128, 4),\n",
              " (129, 2),\n",
              " (130, 2),\n",
              " (131, 1),\n",
              " (132, 1),\n",
              " (133, 1),\n",
              " (134, 1),\n",
              " (135, 1),\n",
              " (136, 2),\n",
              " (137, 1),\n",
              " (138, 4),\n",
              " (139, 1),\n",
              " (140, 6),\n",
              " (141, 2),\n",
              " (142, 9),\n",
              " (143, 15),\n",
              " (144, 1),\n",
              " (145, 1),\n",
              " (146, 1),\n",
              " (147, 5),\n",
              " (148, 1),\n",
              " (149, 1),\n",
              " (150, 1),\n",
              " (151, 2),\n",
              " (152, 1),\n",
              " (153, 1),\n",
              " (154, 1),\n",
              " (155, 1),\n",
              " (156, 2),\n",
              " (157, 1),\n",
              " (158, 1),\n",
              " (159, 1),\n",
              " (160, 1),\n",
              " (161, 1),\n",
              " (162, 1),\n",
              " (163, 2),\n",
              " (164, 1),\n",
              " (165, 1),\n",
              " (166, 1),\n",
              " (167, 1),\n",
              " (168, 2),\n",
              " (169, 1),\n",
              " (170, 2),\n",
              " (171, 1),\n",
              " (172, 1),\n",
              " (173, 1),\n",
              " (174, 2),\n",
              " (175, 1),\n",
              " (176, 1),\n",
              " (177, 1),\n",
              " (178, 1),\n",
              " (179, 4),\n",
              " (180, 1),\n",
              " (181, 1),\n",
              " (182, 2),\n",
              " (183, 1),\n",
              " (184, 1),\n",
              " (185, 1),\n",
              " (186, 1),\n",
              " (187, 1),\n",
              " (188, 1),\n",
              " (189, 1),\n",
              " (190, 3),\n",
              " (191, 4),\n",
              " (192, 1),\n",
              " (193, 1),\n",
              " (194, 1),\n",
              " (195, 1),\n",
              " (196, 1),\n",
              " (197, 1),\n",
              " (198, 3),\n",
              " (199, 1),\n",
              " (200, 2),\n",
              " (201, 13),\n",
              " (202, 2),\n",
              " (203, 4),\n",
              " (204, 1),\n",
              " (205, 1),\n",
              " (206, 1),\n",
              " (207, 1),\n",
              " (208, 1),\n",
              " (209, 1),\n",
              " (210, 1),\n",
              " (211, 1),\n",
              " (212, 2),\n",
              " (213, 1),\n",
              " (214, 1),\n",
              " (215, 7),\n",
              " (216, 1),\n",
              " (217, 1),\n",
              " (218, 1),\n",
              " (219, 1),\n",
              " (220, 2),\n",
              " (221, 2),\n",
              " (222, 1),\n",
              " (223, 1),\n",
              " (224, 28),\n",
              " (225, 1),\n",
              " (226, 1),\n",
              " (227, 1),\n",
              " (228, 1),\n",
              " (229, 1),\n",
              " (230, 1),\n",
              " (231, 2),\n",
              " (232, 2),\n",
              " (233, 1),\n",
              " (234, 1),\n",
              " (235, 1),\n",
              " (236, 1),\n",
              " (237, 1),\n",
              " (238, 2),\n",
              " (239, 1),\n",
              " (240, 1),\n",
              " (241, 1),\n",
              " (242, 1),\n",
              " (243, 1),\n",
              " (244, 1),\n",
              " (245, 1),\n",
              " (246, 2),\n",
              " (247, 1),\n",
              " (248, 3),\n",
              " (249, 10),\n",
              " (250, 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFx_Ifpccb0M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "34f62dee-0e02-4116-c647-517454322df4"
      },
      "source": [
        "# Preview Bag Of Words for our sample preprocessed document.\n",
        "bow_doc_0 = bow_corpus[0]\n",
        "for i in range(len(bow_doc_0)):\n",
        "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_0[i][0], \n",
        "                                               dictionary[bow_doc_0[i][0]], \n",
        "bow_doc_0[i][1]))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word 0 (\"access\") appears 1 time.\n",
            "Word 1 (\"add\") appears 1 time.\n",
            "Word 2 (\"advantag\") appears 1 time.\n",
            "Word 3 (\"agricultur\") appears 2 time.\n",
            "Word 4 (\"allow\") appears 1 time.\n",
            "Word 5 (\"announc\") appears 3 time.\n",
            "Word 6 (\"anti\") appears 1 time.\n",
            "Word 7 (\"appli\") appears 1 time.\n",
            "Word 8 (\"approv\") appears 1 time.\n",
            "Word 9 (\"articl\") appears 3 time.\n",
            "Word 10 (\"aspect\") appears 1 time.\n",
            "Word 11 (\"auto\") appears 1 time.\n",
            "Word 12 (\"avail\") appears 1 time.\n",
            "Word 13 (\"backdrop\") appears 1 time.\n",
            "Word 14 (\"bangalor\") appears 1 time.\n",
            "Word 15 (\"barrier\") appears 2 time.\n",
            "Word 16 (\"base\") appears 1 time.\n",
            "Word 17 (\"benefici\") appears 1 time.\n",
            "Word 18 (\"beneficiari\") appears 1 time.\n",
            "Word 19 (\"benefit\") appears 3 time.\n",
            "Word 20 (\"bengaluru\") appears 3 time.\n",
            "Word 21 (\"best\") appears 1 time.\n",
            "Word 22 (\"bihar\") appears 2 time.\n",
            "Word 23 (\"brave\") appears 1 time.\n",
            "Word 24 (\"capit\") appears 2 time.\n",
            "Word 25 (\"capita\") appears 1 time.\n",
            "Word 26 (\"card\") appears 1 time.\n",
            "Word 27 (\"casual\") appears 1 time.\n",
            "Word 28 (\"categori\") appears 1 time.\n",
            "Word 29 (\"characterist\") appears 1 time.\n",
            "Word 30 (\"charg\") appears 1 time.\n",
            "Word 31 (\"citi\") appears 1 time.\n",
            "Word 32 (\"compar\") appears 2 time.\n",
            "Word 33 (\"compel\") appears 1 time.\n",
            "Word 34 (\"competit\") appears 1 time.\n",
            "Word 35 (\"compon\") appears 1 time.\n",
            "Word 36 (\"condit\") appears 1 time.\n",
            "Word 37 (\"constitu\") appears 1 time.\n",
            "Word 38 (\"constitut\") appears 3 time.\n",
            "Word 39 (\"construct\") appears 1 time.\n",
            "Word 40 (\"contrari\") appears 1 time.\n",
            "Word 41 (\"contribut\") appears 1 time.\n",
            "Word 42 (\"cook\") appears 1 time.\n",
            "Word 43 (\"cost\") appears 2 time.\n",
            "Word 44 (\"countri\") appears 2 time.\n",
            "Word 45 (\"court\") appears 2 time.\n",
            "Word 46 (\"creat\") appears 1 time.\n",
            "Word 47 (\"creation\") appears 1 time.\n",
            "Word 48 (\"criteria\") appears 1 time.\n",
            "Word 49 (\"current\") appears 1 time.\n",
            "Word 50 (\"decis\") appears 1 time.\n",
            "Word 51 (\"demograph\") appears 1 time.\n",
            "Word 52 (\"deni\") appears 1 time.\n",
            "Word 53 (\"determin\") appears 1 time.\n",
            "Word 54 (\"develop\") appears 3 time.\n",
            "Word 55 (\"differ\") appears 3 time.\n",
            "Word 56 (\"differenti\") appears 1 time.\n",
            "Word 57 (\"difficult\") appears 1 time.\n",
            "Word 58 (\"direct\") appears 1 time.\n",
            "Word 59 (\"discourag\") appears 1 time.\n",
            "Word 60 (\"discrimin\") appears 3 time.\n",
            "Word 61 (\"discriminatori\") appears 1 time.\n",
            "Word 62 (\"disfavour\") appears 1 time.\n",
            "Word 63 (\"divers\") appears 1 time.\n",
            "Word 64 (\"domest\") appears 2 time.\n",
            "Word 65 (\"downward\") appears 1 time.\n",
            "Word 66 (\"drive\") appears 1 time.\n",
            "Word 67 (\"dynam\") appears 1 time.\n",
            "Word 68 (\"econom\") appears 2 time.\n",
            "Word 69 (\"economi\") appears 4 time.\n",
            "Word 70 (\"educ\") appears 3 time.\n",
            "Word 71 (\"effici\") appears 1 time.\n",
            "Word 72 (\"elig\") appears 1 time.\n",
            "Word 73 (\"employ\") appears 2 time.\n",
            "Word 74 (\"enact\") appears 2 time.\n",
            "Word 75 (\"entri\") appears 1 time.\n",
            "Word 76 (\"equal\") appears 2 time.\n",
            "Word 77 (\"escap\") appears 1 time.\n",
            "Word 78 (\"essenti\") appears 2 time.\n",
            "Word 79 (\"eventu\") appears 1 time.\n",
            "Word 80 (\"evid\") appears 1 time.\n",
            "Word 81 (\"examin\") appears 1 time.\n",
            "Word 82 (\"extent\") appears 1 time.\n",
            "Word 83 (\"favour\") appears 1 time.\n",
            "Word 84 (\"fee\") appears 1 time.\n",
            "Word 85 (\"framework\") appears 1 time.\n",
            "Word 86 (\"free\") appears 3 time.\n",
            "Word 87 (\"friction\") appears 1 time.\n",
            "Word 88 (\"general\") appears 1 time.\n",
            "Word 89 (\"generat\") appears 1 time.\n",
            "Word 90 (\"good\") appears 1 time.\n",
            "Word 91 (\"govern\") appears 4 time.\n",
            "Word 92 (\"grind\") appears 1 time.\n",
            "Word 93 (\"gross\") appears 1 time.\n",
            "Word 94 (\"ground\") appears 1 time.\n",
            "Word 95 (\"growth\") appears 2 time.\n",
            "Word 96 (\"guarante\") appears 1 time.\n",
            "Word 97 (\"hairdress\") appears 2 time.\n",
            "Word 98 (\"haryana\") appears 1 time.\n",
            "Word 99 (\"high\") appears 2 time.\n",
            "Word 100 (\"higher\") appears 2 time.\n",
            "Word 101 (\"himach\") appears 1 time.\n",
            "Word 102 (\"histori\") appears 1 time.\n",
            "Word 103 (\"home\") appears 1 time.\n",
            "Word 104 (\"hurdl\") appears 2 time.\n",
            "Word 105 (\"impedi\") appears 1 time.\n",
            "Word 106 (\"implic\") appears 1 time.\n",
            "Word 107 (\"import\") appears 2 time.\n",
            "Word 108 (\"impos\") appears 1 time.\n",
            "Word 109 (\"improv\") appears 1 time.\n",
            "Word 110 (\"incent\") appears 1 time.\n",
            "Word 111 (\"incom\") appears 1 time.\n",
            "Word 112 (\"increas\") appears 3 time.\n",
            "Word 113 (\"india\") appears 7 time.\n",
            "Word 114 (\"industri\") appears 2 time.\n",
            "Word 115 (\"inelig\") appears 1 time.\n",
            "Word 116 (\"inform\") appears 1 time.\n",
            "Word 117 (\"inhibit\") appears 2 time.\n",
            "Word 118 (\"institut\") appears 1 time.\n",
            "Word 119 (\"intent\") appears 1 time.\n",
            "Word 120 (\"inter\") appears 2 time.\n",
            "Word 121 (\"interest\") appears 1 time.\n",
            "Word 122 (\"intern\") appears 3 time.\n",
            "Word 123 (\"job\") appears 2 time.\n",
            "Word 124 (\"karnataka\") appears 4 time.\n",
            "Word 125 (\"labour\") appears 2 time.\n",
            "Word 126 (\"larg\") appears 3 time.\n",
            "Word 127 (\"larger\") appears 1 time.\n",
            "Word 128 (\"law\") appears 4 time.\n",
            "Word 129 (\"leader\") appears 2 time.\n",
            "Word 130 (\"leav\") appears 2 time.\n",
            "Word 131 (\"legal\") appears 1 time.\n",
            "Word 132 (\"licenc\") appears 1 time.\n",
            "Word 133 (\"licens\") appears 1 time.\n",
            "Word 134 (\"limit\") appears 1 time.\n",
            "Word 135 (\"link\") appears 1 time.\n",
            "Word 136 (\"live\") appears 2 time.\n",
            "Word 137 (\"livelihood\") appears 1 time.\n",
            "Word 138 (\"local\") appears 4 time.\n",
            "Word 139 (\"look\") appears 1 time.\n",
            "Word 140 (\"market\") appears 6 time.\n",
            "Word 141 (\"measur\") appears 2 time.\n",
            "Word 142 (\"migrant\") appears 9 time.\n",
            "Word 143 (\"migrat\") appears 15 time.\n",
            "Word 144 (\"million\") appears 1 time.\n",
            "Word 145 (\"minist\") appears 1 time.\n",
            "Word 146 (\"modi\") appears 1 time.\n",
            "Word 147 (\"movement\") appears 5 time.\n",
            "Word 148 (\"narendra\") appears 1 time.\n",
            "Word 149 (\"nation\") appears 1 time.\n",
            "Word 150 (\"nativist\") appears 1 time.\n",
            "Word 151 (\"need\") appears 2 time.\n",
            "Word 152 (\"negat\") appears 1 time.\n",
            "Word 153 (\"nonetheless\") appears 1 time.\n",
            "Word 154 (\"northeast\") appears 1 time.\n",
            "Word 155 (\"oper\") appears 1 time.\n",
            "Word 156 (\"opportun\") appears 2 time.\n",
            "Word 157 (\"oppos\") appears 1 time.\n",
            "Word 158 (\"option\") appears 1 time.\n",
            "Word 159 (\"ostens\") appears 1 time.\n",
            "Word 160 (\"outlaw\") appears 1 time.\n",
            "Word 161 (\"own\") appears 1 time.\n",
            "Word 162 (\"peopl\") appears 1 time.\n",
            "Word 163 (\"physic\") appears 2 time.\n",
            "Word 164 (\"point\") appears 1 time.\n",
            "Word 165 (\"polici\") appears 1 time.\n",
            "Word 166 (\"polit\") appears 1 time.\n",
            "Word 167 (\"poor\") appears 1 time.\n",
            "Word 168 (\"poorer\") appears 2 time.\n",
            "Word 169 (\"poorest\") appears 1 time.\n",
            "Word 170 (\"popul\") appears 2 time.\n",
            "Word 171 (\"posit\") appears 1 time.\n",
            "Word 172 (\"poverti\") appears 1 time.\n",
            "Word 173 (\"power\") appears 1 time.\n",
            "Word 174 (\"pradesh\") appears 2 time.\n",
            "Word 175 (\"preferenti\") appears 1 time.\n",
            "Word 176 (\"present\") appears 1 time.\n",
            "Word 177 (\"pressur\") appears 1 time.\n",
            "Word 178 (\"preval\") appears 1 time.\n",
            "Word 179 (\"prevent\") appears 4 time.\n",
            "Word 180 (\"prime\") appears 1 time.\n",
            "Word 181 (\"privileg\") appears 1 time.\n",
            "Word 182 (\"product\") appears 2 time.\n",
            "Word 183 (\"profess\") appears 1 time.\n",
            "Word 184 (\"profession\") appears 1 time.\n",
            "Word 185 (\"promot\") appears 1 time.\n",
            "Word 186 (\"properti\") appears 1 time.\n",
            "Word 187 (\"protect\") appears 1 time.\n",
            "Word 188 (\"provid\") appears 1 time.\n",
            "Word 189 (\"ration\") appears 1 time.\n",
            "Word 190 (\"reason\") appears 3 time.\n",
            "Word 191 (\"recent\") appears 4 time.\n",
            "Word 192 (\"reduc\") appears 1 time.\n",
            "Word 193 (\"reflect\") appears 1 time.\n",
            "Word 194 (\"region\") appears 1 time.\n",
            "Word 195 (\"regul\") appears 1 time.\n",
            "Word 196 (\"regular\") appears 1 time.\n",
            "Word 197 (\"reliant\") appears 1 time.\n",
            "Word 198 (\"remov\") appears 3 time.\n",
            "Word 199 (\"requir\") appears 1 time.\n",
            "Word 200 (\"reserv\") appears 2 time.\n",
            "Word 201 (\"resid\") appears 13 time.\n",
            "Word 202 (\"restrict\") appears 2 time.\n",
            "Word 203 (\"richer\") appears 4 time.\n",
            "Word 204 (\"richest\") appears 1 time.\n",
            "Word 205 (\"safeti\") appears 1 time.\n",
            "Word 206 (\"scheme\") appears 1 time.\n",
            "Word 207 (\"seat\") appears 1 time.\n",
            "Word 208 (\"second\") appears 1 time.\n",
            "Word 209 (\"secur\") appears 1 time.\n",
            "Word 210 (\"see\") appears 1 time.\n",
            "Word 211 (\"self\") appears 1 time.\n",
            "Word 212 (\"sentiment\") appears 2 time.\n",
            "Word 213 (\"serious\") appears 1 time.\n",
            "Word 214 (\"serv\") appears 1 time.\n",
            "Word 215 (\"servic\") appears 7 time.\n",
            "Word 216 (\"settl\") appears 1 time.\n",
            "Word 217 (\"shelter\") appears 1 time.\n",
            "Word 218 (\"short\") appears 1 time.\n",
            "Word 219 (\"similar\") appears 1 time.\n",
            "Word 220 (\"singl\") appears 2 time.\n",
            "Word 221 (\"skill\") appears 2 time.\n",
            "Word 222 (\"speak\") appears 1 time.\n",
            "Word 223 (\"squalid\") appears 1 time.\n",
            "Word 224 (\"state\") appears 28 time.\n",
            "Word 225 (\"statement\") appears 1 time.\n",
            "Word 226 (\"step\") appears 1 time.\n",
            "Word 227 (\"suggest\") appears 1 time.\n",
            "Word 228 (\"suppli\") appears 1 time.\n",
            "Word 229 (\"taxi\") appears 1 time.\n",
            "Word 230 (\"technolog\") appears 1 time.\n",
            "Word 231 (\"term\") appears 2 time.\n",
            "Word 232 (\"time\") appears 2 time.\n",
            "Word 233 (\"trade\") appears 1 time.\n",
            "Word 234 (\"treat\") appears 1 time.\n",
            "Word 235 (\"treatment\") appears 1 time.\n",
            "Word 236 (\"truli\") appears 1 time.\n",
            "Word 237 (\"union\") appears 1 time.\n",
            "Word 238 (\"uphold\") appears 2 time.\n",
            "Word 239 (\"usual\") appears 1 time.\n",
            "Word 240 (\"uttar\") appears 1 time.\n",
            "Word 241 (\"uttarakhand\") appears 1 time.\n",
            "Word 242 (\"valu\") appears 1 time.\n",
            "Word 243 (\"wag\") appears 1 time.\n",
            "Word 244 (\"wage\") appears 1 time.\n",
            "Word 245 (\"want\") appears 1 time.\n",
            "Word 246 (\"welfar\") appears 2 time.\n",
            "Word 247 (\"wonder\") appears 1 time.\n",
            "Word 248 (\"work\") appears 3 time.\n",
            "Word 249 (\"worker\") appears 10 time.\n",
            "Word 250 (\"younger\") appears 1 time.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99zK3Yr_cwbC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "4e89897b-65aa-4f9e-f8db-78c0b08c4770"
      },
      "source": [
        "# tf-idf\n",
        "tfidf = models.TfidfModel(bow_corpus)\n",
        "corpus_tfidf = tfidf[bow_corpus]\n",
        "for doc in corpus_tfidf:\n",
        "    print(doc)\n",
        "    break"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, 0.023482283267781765), (1, 0.009404684218986006), (2, 0.02579755493806464), (3, 0.08043534940659296), (4, 0.013692706843115665), (5, 0.046022690392083315), (6, 0.023482283267781765), (7, 0.031376018749902874), (8, 0.02455694686361218), (9, 0.09412805624970863), (10, 0.02906074707962001), (11, 0.03463921089145825), (12, 0.01652076479423945), (13, 0.02906074707962001), (14, 0.04021767470329648), (15, 0.0692784217829165), (16, 0.014640627314388163), (17, 0.02579755493806464), (18, 0.04021767470329648), (19, 0.0676030883895278), (20, 0.12065302410988943), (21, 0.016107955228600358), (22, 0.05812149415924002), (23, 0.03463921089145825), (24, 0.03684645379776645), (25, 0.04021767470329648), (26, 0.02579755493806464), (27, 0.03463921089145825), (28, 0.02906074707962001), (29, 0.031376018749902874), (30, 0.019574905647757514), (31, 0.017415911161147962), (32, 0.04696456653556353), (33, 0.04021767470329648), (34, 0.02579755493806464), (35, 0.02906074707962001), (36, 0.021686419040438592), (37, 0.031376018749902874), (38, 0.07367084059083653), (39, 0.02726488285227683), (40, 0.04021767470329648), (41, 0.023482283267781765), (42, 0.03463921089145825), (43, 0.03795696610354789), (44, 0.02146649938872781), (45, 0.03684645379776645), (46, 0.017415911161147962), (47, 0.031376018749902874), (48, 0.03463921089145825), (49, 0.012844763087044986), (50, 0.014983148030824244), (51, 0.03463921089145825), (52, 0.02455694686361218), (53, 0.02579755493806464), (54, 0.046022690392083315), (55, 0.042936273003771536), (56, 0.04021767470329648), (57, 0.02091936060919934), (58, 0.012580869869060783), (59, 0.04021767470329648), (60, 0.10391763267437475), (61, 0.04021767470329648), (62, 0.04021767470329648), (63, 0.04021767470329648), (64, 0.043372838080877184), (65, 0.04021767470329648), (66, 0.016107955228600358), (67, 0.031376018749902874), (68, 0.031430581820437155), (69, 0.06443182091440143), (70, 0.05526968069664967), (71, 0.02726488285227683), (72, 0.02906074707962001), (73, 0.04183872121839868), (74, 0.08043534940659296), (75, 0.031376018749902874), (76, 0.06275203749980575), (77, 0.02906074707962001), (78, 0.05159510987612928), (79, 0.02906074707962001), (80, 0.023482283267781765), (81, 0.021686419040438592), (82, 0.04021767470329648), (83, 0.02455694686361218), (84, 0.02906074707962001), (85, 0.02726488285227683), (86, 0.0676030883895278), (87, 0.03463921089145825), (88, 0.01695589898467103), (89, 0.02455694686361218), (90, 0.012580869869060783), (91, 0.03128622171238988), (92, 0.021686419040438592), (93, 0.02906074707962001), (94, 0.02906074707962001), (95, 0.04696456653556353), (96, 0.02726488285227683), (97, 0.08043534940659296), (98, 0.02579755493806464), (99, 0.025689526174089972), (100, 0.043372838080877184), (101, 0.04021767470329648), (102, 0.023482283267781765), (103, 0.011377435172832795), (104, 0.0692784217829165), (105, 0.04021767470329648), (106, 0.03463921089145825), (107, 0.026800038479871415), (108, 0.018978483051773944), (109, 0.0202190911262264), (110, 0.03463921089145825), (111, 0.02455694686361218), (112, 0.048323865685801076), (113, 0.05475088799668228), (114, 0.03580763891188707), (115, 0.04021767470329648), (116, 0.014640627314388163), (117, 0.08043534940659296), (118, 0.017415911161147962), (119, 0.031376018749902874), (120, 0.05812149415924002), (121, 0.021686419040438592), (122, 0.044949444092472736), (123, 0.05159510987612928), (124, 0.11624298831848004), (125, 0.06275203749980575), (126, 0.06505925712131577), (127, 0.02906074707962001), (128, 0.1255040749996115), (129, 0.03684645379776645), (130, 0.025161739738121566), (131, 0.02906074707962001), (132, 0.04021767470329648), (133, 0.03463921089145825), (134, 0.023482283267781765), (135, 0.018978483051773944), (136, 0.025689526174089972), (137, 0.03463921089145825), (138, 0.0736929075955329), (139, 0.013117603523379413), (140, 0.12551616365519605), (141, 0.03580763891188707), (142, 0.28238416874912586), (143, 0.5195881633718737), (144, 0.014640627314388163), (145, 0.009581570945489618), (146, 0.018978483051773944), (147, 0.14530373539810004), (148, 0.018978483051773944), (149, 0.013117603523379413), (150, 0.04021767470329648), (151, 0.02146649938872781), (152, 0.02726488285227683), (153, 0.03463921089145825), (154, 0.04021767470329648), (155, 0.017415911161147962), (156, 0.04696456653556353), (157, 0.02906074707962001), (158, 0.021686419040438592), (159, 0.04021767470329648), (160, 0.04021767470329648), (161, 0.02579755493806464), (162, 0.007679108840845846), (163, 0.04911389372722436), (164, 0.012580869869060783), (165, 0.018423226898883226), (166, 0.015340896797361104), (167, 0.022534362796509267), (168, 0.08043534940659296), (169, 0.04021767470329648), (170, 0.0692784217829165), (171, 0.014312091001257179), (172, 0.03463921089145825), (173, 0.01652076479423945), (174, 0.045068725593018534), (175, 0.04021767470329648), (176, 0.018423226898883226), (177, 0.02726488285227683), (178, 0.04021767470329648), (179, 0.08674567616175437), (180, 0.017903819455943534), (181, 0.02726488285227683), (182, 0.034831822322295924), (183, 0.04021767470329648), (184, 0.022534362796509267), (185, 0.02091936060919934), (186, 0.02579755493806464), (187, 0.0202190911262264), (188, 0.015340896797361104), (189, 0.02906074707962001), (190, 0.060657273378679204), (191, 0.05360007695974283), (192, 0.018978483051773944), (193, 0.02726488285227683), (194, 0.019574905647757514), (195, 0.02455694686361218), (196, 0.022534362796509267), (197, 0.04021767470329648), (198, 0.07739266481419392), (199, 0.015715290910218577), (200, 0.043372838080877184), (201, 0.2929467163546205), (202, 0.043372838080877184), (203, 0.16087069881318591), (204, 0.03463921089145825), (205, 0.022534362796509267), (206, 0.022534362796509267), (207, 0.02906074707962001), (208, 0.013117603523379413), (209, 0.017903819455943534), (210, 0.016107955228600358), (211, 0.02091936060919934), (212, 0.05159510987612928), (213, 0.02726488285227683), (214, 0.02091936060919934), (215, 0.1415336378835848), (216, 0.02579755493806464), (217, 0.031376018749902874), (218, 0.021686419040438592), (219, 0.018978483051773944), (220, 0.05159510987612928), (221, 0.05812149415924002), (222, 0.01652076479423945), (223, 0.04021767470329648), (224, 0.22719880487576796), (225, 0.018423226898883226), (226, 0.015715290910218577), (227, 0.01652076479423945), (228, 0.02726488285227683), (229, 0.02906074707962001), (230, 0.0202190911262264), (231, 0.034831822322295924), (232, 0.011156927623676476), (233, 0.019574905647757514), (234, 0.02091936060919934), (235, 0.02726488285227683), (236, 0.02579755493806464), (237, 0.015715290910218577), (238, 0.0692784217829165), (239, 0.022534362796509267), (240, 0.02726488285227683), (241, 0.04021767470329648), (242, 0.02455694686361218), (243, 0.031376018749902874), (244, 0.04021767470329648), (245, 0.013400019239935708), (246, 0.04696456653556353), (247, 0.02579755493806464), (248, 0.030410481295141012), (249, 0.22534362796509266), (250, 0.031376018749902874)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6GnOwb7cwYN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#LDA using Bag of Words\n",
        "# # Build LDA model\n",
        "# lda_model = gensim.models.ldamodel.LdaModel(corpus=bow_corpus,\n",
        "#                                            id2word=dictionary,\n",
        "#                                            num_topics=10, \n",
        "#                                            random_state=100,\n",
        "#                                            update_every=1,\n",
        "#                                            chunksize=100,\n",
        "#                                            passes=10,\n",
        "#                                            alpha='auto',\n",
        "#                                            per_word_topics=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_6-wc--cwVK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train our lda model using gensim.models.LdaMulticore and save it to ‘lda_model’\n",
        "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=2, workers=2)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erHOC2BlcwTe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "244c4758-bb27-4e78-99b1-e3b4befe95ea"
      },
      "source": [
        "# For each topic, we will explore the words occuring in that topic and its relative weight.\n",
        "for idx, topic in lda_model.print_topics(-1):\n",
        "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic: 0 \n",
            "Words: 0.014*\"india\" + 0.013*\"china\" + 0.007*\"say\" + 0.007*\"labour\" + 0.006*\"indian\" + 0.005*\"militari\" + 0.005*\"chines\" + 0.004*\"power\" + 0.004*\"nation\" + 0.004*\"state\"\n",
            "Topic: 1 \n",
            "Words: 0.009*\"say\" + 0.008*\"test\" + 0.007*\"patient\" + 0.007*\"covid\" + 0.006*\"india\" + 0.006*\"friend\" + 0.005*\"today\" + 0.005*\"exercis\" + 0.005*\"lucki\" + 0.005*\"case\"\n",
            "Topic: 2 \n",
            "Words: 0.012*\"result\" + 0.008*\"board\" + 0.007*\"share\" + 0.007*\"say\" + 0.007*\"class\" + 0.007*\"time\" + 0.006*\"post\" + 0.004*\"year\" + 0.004*\"dubey\" + 0.004*\"actor\"\n",
            "Topic: 3 \n",
            "Words: 0.020*\"say\" + 0.007*\"delhi\" + 0.006*\"learn\" + 0.006*\"govern\" + 0.006*\"school\" + 0.005*\"covid\" + 0.004*\"test\" + 0.004*\"class\" + 0.004*\"teacher\" + 0.004*\"polic\"\n",
            "Topic: 4 \n",
            "Words: 0.011*\"say\" + 0.011*\"india\" + 0.006*\"china\" + 0.005*\"actor\" + 0.005*\"sushant\" + 0.005*\"time\" + 0.005*\"year\" + 0.004*\"post\" + 0.004*\"like\" + 0.004*\"peopl\"\n",
            "Topic: 5 \n",
            "Words: 0.006*\"say\" + 0.006*\"time\" + 0.006*\"peopl\" + 0.005*\"year\" + 0.005*\"india\" + 0.005*\"line\" + 0.004*\"test\" + 0.004*\"play\" + 0.004*\"chines\" + 0.004*\"share\"\n",
            "Topic: 6 \n",
            "Words: 0.016*\"say\" + 0.009*\"india\" + 0.006*\"chines\" + 0.005*\"china\" + 0.005*\"singh\" + 0.005*\"case\" + 0.004*\"time\" + 0.004*\"pakistan\" + 0.004*\"covid\" + 0.004*\"base\"\n",
            "Topic: 7 \n",
            "Words: 0.012*\"test\" + 0.011*\"say\" + 0.009*\"covid\" + 0.008*\"hospit\" + 0.007*\"govern\" + 0.007*\"india\" + 0.006*\"patient\" + 0.005*\"coal\" + 0.005*\"court\" + 0.005*\"school\"\n",
            "Topic: 8 \n",
            "Words: 0.014*\"state\" + 0.010*\"govern\" + 0.009*\"case\" + 0.007*\"india\" + 0.007*\"say\" + 0.006*\"minist\" + 0.006*\"covid\" + 0.005*\"home\" + 0.005*\"need\" + 0.005*\"maharashtra\"\n",
            "Topic: 9 \n",
            "Words: 0.009*\"love\" + 0.009*\"say\" + 0.007*\"share\" + 0.007*\"video\" + 0.005*\"look\" + 0.004*\"post\" + 0.004*\"write\" + 0.004*\"actor\" + 0.004*\"good\" + 0.003*\"play\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFs6ggNWdTL3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2ef1602f-93ee-457f-cb74-f9e9882b1c11"
      },
      "source": [
        "# Compute Perplexity\n",
        "print('\\nPerplexity: ', lda_model.log_perplexity(bow_corpus))  # a measure of how good the model is. lower the better.\n",
        "\n",
        "# Compute Coherence Score\n",
        "coherence_model_lda = CoherenceModel(model=lda_model, texts=processed_docs, dictionary=dictionary, coherence='c_v')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Perplexity:  -8.24305717280266\n",
            "\n",
            "Coherence Score:  0.33510514984144024\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJwQSyH1dTI3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 861
        },
        "outputId": "d9646440-ecf4-466d-d4ec-567a93a1572b"
      },
      "source": [
        "# Visualize the topics\n",
        "pyLDAvis.enable_notebook()\n",
        "vis = pyLDAvis.gensim.prepare(lda_model, bow_corpus, dictionary)\n",
        "vis"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el1241404475002830007593808241\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el1241404475002830007593808241_data = {\"mdsDat\": {\"x\": [-0.00028795652524053603, 0.014161560119413427, 0.042771488152140005, 0.062473241203094186, -0.05124635872609094, -0.08696747132690537, 0.04682695801317309, 0.08865103849313356, -0.03860689483058262, -0.07777560457213445], \"y\": [0.04199993652930402, -0.0934571972604271, 0.0069926998161393295, -0.002646440587180593, 0.0548333164014905, -0.046752831691498374, 0.05142188570433884, -0.028520863403403058, 0.033721420512831876, -0.01759192602159522], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [12.81282901763916, 12.018830299377441, 11.952091217041016, 10.70505428314209, 9.824070930480957, 9.624974250793457, 9.486126899719238, 8.348922729492188, 8.032031059265137, 7.195072650909424]}, \"tinfo\": {\"Term\": [\"test\", \"china\", \"result\", \"love\", \"share\", \"covid\", \"patient\", \"board\", \"class\", \"hospit\", \"state\", \"video\", \"labour\", \"exam\", \"school\", \"govern\", \"coal\", \"lucki\", \"india\", \"case\", \"exercis\", \"actor\", \"friend\", \"chines\", \"learn\", \"student\", \"sushant\", \"post\", \"antigen\", \"militari\", \"scott\", \"communist\", \"labour\", \"hugo\", \"donnel\", \"tourism\", \"freedom\", \"grieder\", \"karma\", \"tommi\", \"unctad\", \"timm\", \"aspen\", \"hilfig\", \"aircraft\", \"langer\", \"commend\", \"muslim\", \"contractor\", \"defens\", \"jinp\", \"deploy\", \"escal\", \"felin\", \"fcra\", \"fighter\", \"reform\", \"bitter\", \"xinjiang\", \"mgnreg\", \"succeed\", \"greater\", \"militari\", \"scenario\", \"sheet\", \"contribut\", \"china\", \"advantag\", \"law\", \"peac\", \"moral\", \"power\", \"western\", \"border\", \"india\", \"foreign\", \"realiti\", \"indian\", \"parti\", \"nation\", \"chines\", \"market\", \"stand\", \"strateg\", \"capit\", \"continu\", \"forc\", \"econom\", \"say\", \"economi\", \"state\", \"world\", \"intern\", \"person\", \"polit\", \"time\", \"govern\", \"peopl\", \"countri\", \"like\", \"mafia\", \"leclerc\", \"inflow\", \"spielberg\", \"karen\", \"verstappen\", \"trailer\", \"pais\", \"sisodia\", \"amrish\", \"reunion\", \"deduct\", \"halp\", \"queen\", \"benchmark\", \"circular\", \"forex\", \"tenni\", \"crematorium\", \"sania\", \"sensex\", \"tale\", \"cent\", \"yaara\", \"offenc\", \"rupe\", \"maya\", \"youngest\", \"hype\", \"matur\", \"indirect\", \"ferrari\", \"oximet\", \"learn\", \"teacher\", \"vettel\", \"race\", \"school\", \"delhi\", \"say\", \"deputi\", \"hamilton\", \"game\", \"bodi\", \"feel\", \"council\", \"class\", \"polic\", \"govern\", \"follow\", \"onlin\", \"read\", \"student\", \"person\", \"covid\", \"start\", \"test\", \"court\", \"close\", \"point\", \"film\", \"add\", \"year\", \"minist\", \"post\", \"time\", \"like\", \"write\", \"india\", \"sudhakar\", \"intel\", \"throne\", \"gemma\", \"delist\", \"meng\", \"postal\", \"putin\", \"cash\", \"editori\", \"mpsc\", \"zonal\", \"sovereignti\", \"yara\", \"speedi\", \"app\", \"exempt\", \"zhao\", \"intellig\", \"euro\", \"relianc\", \"franc\", \"appointe\", \"spavor\", \"probationari\", \"explanatori\", \"adani\", \"huawei\", \"canada\", \"kovrig\", \"canadian\", \"tiktok\", \"ballot\", \"commission\", \"vancouv\", \"thane\", \"pakistan\", \"khalistan\", \"digit\", \"singh\", \"terror\", \"ban\", \"chines\", \"oper\", \"say\", \"approv\", \"valu\", \"india\", \"punjab\", \"data\", \"base\", \"case\", \"allow\", \"china\", \"countri\", \"coronavirus\", \"compani\", \"lockdown\", \"time\", \"polic\", \"secur\", \"economi\", \"indian\", \"covid\", \"minist\", \"report\", \"year\", \"econom\", \"govern\", \"ministri\", \"work\", \"state\", \"migrant\", \"prasar\", \"alumni\", \"bharati\", \"yatra\", \"migrat\", \"odisha\", \"rath\", \"richer\", \"srpf\", \"devot\", \"recruit\", \"iitbhf\", \"reopen\", \"articl\", \"dharavi\", \"frog\", \"strang\", \"msmes\", \"railway\", \"bengaluru\", \"puri\", \"inmat\", \"stray\", \"maharashtra\", \"jagannath\", \"undergradu\", \"grim\", \"sawant\", \"hurdl\", \"bombay\", \"broadcast\", \"state\", \"resid\", \"higher\", \"fund\", \"talli\", \"case\", \"govern\", \"death\", \"policemen\", \"worker\", \"shah\", \"need\", \"home\", \"minist\", \"coronavirus\", \"covid\", \"onlin\", \"countri\", \"india\", \"student\", \"say\", \"delhi\", \"base\", \"polit\", \"school\", \"take\", \"singh\", \"number\", \"class\", \"time\", \"court\", \"year\", \"athlet\", \"celsius\", \"rain\", \"mental\", \"jariwala\", \"namrata\", \"shekhar\", \"tomato\", \"breakfast\", \"onion\", \"amazon\", \"deepika\", \"fortun\", \"batra\", \"shefali\", \"salt\", \"ford\", \"olymp\", \"vogu\", \"karan\", \"mill\", \"rainfal\", \"airport\", \"manikarnika\", \"johar\", \"grief\", \"vermicelli\", \"bezo\", \"meal\", \"weather\", \"anaita\", \"sushant\", \"kangana\", \"degre\", \"fashion\", \"intens\", \"suicid\", \"cover\", \"babu\", \"coach\", \"mumbai\", \"shoot\", \"depress\", \"normal\", \"india\", \"actor\", \"china\", \"say\", \"post\", \"right\", \"year\", \"write\", \"recent\", \"like\", \"style\", \"time\", \"share\", \"video\", \"peopl\", \"want\", \"famili\", \"follow\", \"good\", \"film\", \"show\", \"go\", \"state\", \"june\", \"mpbse\", \"madhya\", \"crpf\", \"hindustantim\", \"ahsec\", \"download\", \"credenti\", \"login\", \"urdu\", \"fastresult\", \"hsslc\", \"mussoori\", \"photograph\", \"khanna\", \"assam\", \"shilpa\", \"noon\", \"chest\", \"window\", \"homepag\", \"visibl\", \"sindoor\", \"rectangular\", \"dass\", \"honor\", \"grimezsz\", \"lauren\", \"screengrab\", \"jawan\", \"judiciari\", \"dubey\", \"click\", \"alter\", \"result\", \"precious\", \"websit\", \"fire\", \"woman\", \"board\", \"check\", \"crimin\", \"dancer\", \"grime\", \"secondari\", \"marriag\", \"appear\", \"class\", \"share\", \"twitter\", \"terrorist\", \"exam\", \"shoot\", \"post\", \"hous\", \"time\", \"student\", \"wear\", \"actor\", \"love\", \"year\", \"film\", \"say\", \"write\", \"video\", \"want\", \"take\", \"polic\", \"offici\", \"like\", \"come\", \"peopl\", \"live\", \"refund\", \"indi\", \"aerob\", \"simmon\", \"bypass\", \"zodiac\", \"alphabet\", \"lucki\", \"mourinho\", \"biden\", \"giudicelli\", \"exercis\", \"actigraph\", \"pakistani\", \"libra\", \"cbdt\", \"taxpay\", \"dose\", \"islamabad\", \"remdesivir\", \"squad\", \"taurus\", \"capricorn\", \"kane\", \"ari\", \"questionnair\", \"psqi\", \"attari\", \"phil\", \"ticket\", \"trump\", \"sleep\", \"surgeri\", \"cricket\", \"virgo\", \"romant\", \"player\", \"friend\", \"colour\", \"patient\", \"today\", \"focus\", \"ganguli\", \"number\", \"test\", \"health\", \"presid\", \"covid\", \"capac\", \"help\", \"say\", \"week\", \"case\", \"love\", \"care\", \"india\", \"peopl\", \"indian\", \"time\", \"issu\", \"like\", \"good\", \"state\", \"famili\", \"add\", \"rial\", \"iranian\", \"coal\", \"shelar\", \"mine\", \"tehran\", \"jahangiri\", \"ward\", \"sion\", \"cbse\", \"affidavit\", \"tonn\", \"petit\", \"scope\", \"convalesc\", \"iran\", \"plea\", \"waiver\", \"blood\", \"cmpdil\", \"admiss\", \"claus\", \"arsenicum\", \"joshi\", \"entranc\", \"healthcar\", \"jain\", \"prescript\", \"sampl\", \"reimpos\", \"antigen\", \"procur\", \"administ\", \"commerci\", \"hospit\", \"submit\", \"plasma\", \"bed\", \"test\", \"valid\", \"hear\", \"exam\", \"privat\", \"covid\", \"court\", \"decis\", \"command\", \"patient\", \"oxygen\", \"trade\", \"school\", \"export\", \"govern\", \"high\", \"say\", \"assess\", \"parent\", \"class\", \"inform\", \"india\", \"minist\", \"student\", \"time\", \"union\", \"state\", \"board\", \"lockdown\", \"delhi\", \"start\", \"direct\", \"offici\", \"case\", \"home\", \"morata\", \"mona\", \"jassi\", \"navya\", \"madrid\", \"agneepath\", \"markit\", \"mallorca\", \"newspap\", \"apurva\", \"atl\\u00e9tico\", \"mamata\", \"setien\", \"laudabl\", \"banerje\", \"admir\", \"taskmast\", \"distress\", \"liga\", \"prompt\", \"chhath\", \"dua\", \"refere\", \"cylind\", \"trendsett\", \"guru\", \"perfectionist\", \"farmer\", \"roshan\", \"betti\", \"leagu\", \"exposur\", \"chin\", \"saroj\", \"scheme\", \"choreograph\", \"ration\", \"bengal\", \"welfar\", \"line\", \"child\", \"barcelona\", \"legend\", \"elect\", \"bihar\", \"danc\", \"miss\", \"area\", \"season\", \"celina\", \"contract\", \"peopl\", \"year\", \"play\", \"poor\", \"time\", \"work\", \"actor\", \"come\", \"month\", \"chines\", \"screen\", \"test\", \"polit\", \"share\", \"say\", \"continu\", \"india\", \"june\", \"love\", \"film\", \"govern\", \"indian\", \"take\", \"follow\", \"minist\", \"sidharth\", \"kevin\", \"somebodi\", \"dope\", \"puzzl\", \"tallulah\", \"mous\", \"therapeut\", \"cupp\", \"shehnaaz\", \"outer\", \"crash\", \"satisfi\", \"ektarkapoor\", \"golf\", \"memorandum\", \"tulsi\", \"panel\", \"smriti\", \"chairmanship\", \"calm\", \"bite\", \"dust\", \"traumat\", \"mirror\", \"sudha\", \"masumimewawalla\", \"bhattacharya\", \"grate\", \"sandeep\", \"desai\", \"serial\", \"clip\", \"scene\", \"doggo\", \"love\", \"video\", \"sign\", \"ekta\", \"beauti\", \"thank\", \"share\", \"look\", \"sport\", \"write\", \"attack\", \"read\", \"say\", \"post\", \"friend\", \"good\", \"twitter\", \"actor\", \"believ\", \"play\", \"tell\", \"possibl\", \"think\", \"chines\", \"like\", \"year\", \"govern\", \"time\", \"follow\", \"person\", \"know\", \"go\", \"state\", \"india\"], \"Freq\": [104.0, 116.0, 64.0, 69.0, 79.0, 107.0, 65.0, 54.0, 67.0, 42.0, 121.0, 55.0, 34.0, 30.0, 57.0, 125.0, 16.0, 22.0, 215.0, 94.0, 23.0, 62.0, 40.0, 78.0, 42.0, 49.0, 26.0, 73.0, 21.0, 38.0, 3.427323341369629, 7.453925132751465, 25.62514877319336, 4.687904357910156, 3.273099660873413, 4.558229923248291, 5.1351494789123535, 3.2074878215789795, 4.381793975830078, 2.447166919708252, 3.0446338653564453, 2.410712480545044, 3.6002182960510254, 2.3954529762268066, 2.3952276706695557, 2.361827850341797, 1.7629460096359253, 4.0895795822143555, 2.300687789916992, 1.6904058456420898, 2.2521510124206543, 1.682813048362732, 2.24450945854187, 2.220217704772949, 2.2170042991638184, 1.6645482778549194, 10.636189460754395, 1.643579363822937, 1.6333658695220947, 1.631190538406372, 2.1656196117401123, 5.209330081939697, 20.896501541137695, 6.117181301116943, 7.051737308502197, 6.021328449249268, 53.00532150268555, 4.590634822845459, 7.6405229568481445, 10.032398223876953, 3.6220543384552, 17.367958068847656, 5.252156734466553, 13.723262786865234, 57.04951095581055, 11.978363037109375, 8.29458999633789, 25.391984939575195, 14.294278144836426, 16.82703971862793, 19.54640007019043, 9.620651245117188, 10.677532196044922, 6.897701263427734, 9.926133155822754, 12.935552597045898, 11.64366626739502, 11.010544776916504, 27.53318214416504, 10.137032508850098, 16.354679107666016, 10.081591606140137, 8.92264175415039, 10.402782440185547, 10.066873550415039, 12.419870376586914, 11.38563346862793, 10.316688537597656, 9.491637229919434, 9.681867599487305, 3.879267692565918, 10.942848205566406, 2.5585782527923584, 5.757500171661377, 3.7876296043395996, 11.340842247009277, 4.293992519378662, 2.417840003967285, 7.226494312286377, 3.6126699447631836, 2.3577985763549805, 2.3509907722473145, 2.3151352405548096, 4.585638046264648, 2.2835543155670166, 3.4331142902374268, 1.7120765447616577, 1.6962153911590576, 5.0600786209106445, 1.6870660781860352, 2.2421815395355225, 2.791369915008545, 8.915606498718262, 3.3046107292175293, 3.2847776412963867, 6.571686744689941, 9.103814125061035, 2.170287847518921, 2.1681995391845703, 2.1633713245391846, 2.6891095638275146, 3.757962226867676, 5.138900279998779, 23.336166381835938, 15.463833808898926, 3.723172187805176, 10.7977876663208, 21.177865982055664, 25.075061798095703, 72.51612091064453, 4.260305881500244, 5.5600481033325195, 11.109172821044922, 9.611547470092773, 9.51906681060791, 6.284441947937012, 15.829191207885742, 14.903499603271484, 21.790510177612305, 14.483406066894531, 11.963597297668457, 10.45452880859375, 11.770776748657227, 12.076401710510254, 16.79886817932129, 11.335647583007812, 16.2330322265625, 11.329813003540039, 8.835948944091797, 9.834562301635742, 10.359477996826172, 10.87022876739502, 13.170391082763672, 11.840986251831055, 11.363117218017578, 11.601219177246094, 10.811158180236816, 10.148307800292969, 10.873759269714355, 3.754535675048828, 4.433478355407715, 4.901091575622559, 4.844541072845459, 3.4470839500427246, 6.858893394470215, 3.3957102298736572, 4.720939636230469, 5.952181816101074, 6.636621952056885, 2.649649143218994, 2.6351230144500732, 4.500808238983154, 2.557920455932617, 1.9207303524017334, 12.767662048339844, 3.172178268432617, 3.729412078857422, 3.7283222675323486, 3.026883125305176, 1.8258795738220215, 9.059151649475098, 1.7764253616333008, 2.3564977645874023, 1.7734580039978027, 1.7486826181411743, 1.7340519428253174, 5.221475124359131, 6.844306468963623, 2.28823184967041, 5.109035491943359, 2.8623318672180176, 3.440965175628662, 3.3800225257873535, 2.8072290420532227, 5.606313228607178, 14.692647933959961, 5.8891448974609375, 11.183077812194824, 18.622854232788086, 6.855485916137695, 6.865342140197754, 23.758434295654297, 9.674155235290527, 57.73238754272461, 5.14769983291626, 5.982816696166992, 34.327484130859375, 7.301014423370361, 7.442075252532959, 13.280708312988281, 18.028717041015625, 11.459065437316895, 19.447080612182617, 13.158522605895996, 11.847825050354004, 9.221096992492676, 11.114840507507324, 16.257532119750977, 11.867633819580078, 8.694802284240723, 9.651449203491211, 13.042362213134766, 13.957574844360352, 12.189602851867676, 10.46827507019043, 12.043962478637695, 9.07453727722168, 11.67640495300293, 8.236960411071777, 9.008299827575684, 9.314839363098145, 7.316104412078857, 6.602749347686768, 2.3236567974090576, 6.359065055847168, 6.873525142669678, 9.465642929077148, 7.73698616027832, 4.9740777015686035, 2.717257499694824, 1.6222431659698486, 6.451718330383301, 4.291518211364746, 1.583657145500183, 3.6784870624542236, 3.1357593536376953, 2.088811159133911, 2.0981006622314453, 2.5672404766082764, 2.5540966987609863, 2.0259265899658203, 2.012537956237793, 5.548342704772949, 2.0075294971466064, 4.067052364349365, 15.0642671585083, 1.9746567010879517, 1.481681227684021, 1.9400256872177124, 2.4253952503204346, 1.9372965097427368, 6.7523112297058105, 3.271855115890503, 45.17819595336914, 8.96086597442627, 8.294914245605469, 6.252002716064453, 6.242063045501709, 28.984689712524414, 33.92404556274414, 12.72999095916748, 4.413496017456055, 8.452187538146973, 8.982359886169434, 15.729832649230957, 16.37238311767578, 18.587238311767578, 13.644795417785645, 18.225223541259766, 11.393248558044434, 12.906264305114746, 22.500904083251953, 10.757792472839355, 21.431278228759766, 11.872316360473633, 10.399843215942383, 10.219545364379883, 10.207313537597656, 10.255807876586914, 9.655508995056152, 9.165492057800293, 9.859612464904785, 10.729726791381836, 9.224444389343262, 8.903128623962402, 6.08474588394165, 4.745874881744385, 10.467252731323242, 3.9587666988372803, 2.8250560760498047, 3.384714365005493, 5.485321998596191, 3.254842519760132, 3.792238712310791, 3.2139854431152344, 2.6815524101257324, 3.1619598865509033, 2.628993511199951, 2.104687452316284, 2.094475269317627, 2.61472749710083, 3.133497476577759, 4.165721416473389, 4.661952495574951, 2.5725908279418945, 2.045431137084961, 2.040980339050293, 3.5440187454223633, 2.015444040298462, 2.00345516204834, 3.5255753993988037, 1.9960920810699463, 1.9820821285247803, 1.9768704175949097, 3.964524269104004, 3.853846549987793, 14.753106117248535, 5.2003173828125, 5.058464527130127, 9.723688125610352, 4.88361930847168, 4.022561073303223, 9.145956039428711, 3.2840144634246826, 6.981038570404053, 10.722357749938965, 10.790130615234375, 3.862114906311035, 6.140292644500732, 32.84944534301758, 14.979364395141602, 19.495708465576172, 33.07192611694336, 13.318094253540039, 8.264081954956055, 14.035346031188965, 10.868577003479004, 8.343271255493164, 11.557377815246582, 5.289479732513428, 14.036127090454102, 11.104948997497559, 9.487919807434082, 11.35921573638916, 7.81096076965332, 7.254816055297852, 8.519808769226074, 7.96039342880249, 7.317549705505371, 6.879368305206299, 7.177688121795654, 7.617186069488525, 7.01061487197876, 10.533400535583496, 5.572138786315918, 3.6746115684509277, 4.328505039215088, 2.426354169845581, 3.648698329925537, 2.334676742553711, 2.3151466846466064, 4.591129779815674, 2.2824602127075195, 1.6614786386489868, 3.2806506156921387, 2.178497314453125, 3.2296628952026367, 4.835958480834961, 3.162810802459717, 1.5834113359451294, 2.0742008686065674, 2.061959743499756, 1.548130750656128, 2.04380202293396, 2.5511720180511475, 1.532927393913269, 1.5164241790771484, 2.022394895553589, 1.511398434638977, 1.5094047784805298, 1.50464928150177, 1.4919228553771973, 1.9912545680999756, 11.715861320495605, 4.441662788391113, 7.283992767333984, 35.200965881347656, 2.471270799636841, 6.033404350280762, 3.797908306121826, 7.710489749908447, 24.7601318359375, 10.925885200500488, 5.754594326019287, 3.715304136276245, 2.8858699798583984, 6.644003391265869, 4.561157703399658, 8.170828819274902, 20.036991119384766, 21.580785751342773, 11.160311698913574, 6.891049861907959, 9.733555793762207, 10.56074333190918, 16.446044921875, 7.726885795593262, 19.749622344970703, 11.193692207336426, 6.076709747314453, 11.569917678833008, 11.517068862915039, 13.255366325378418, 9.437300682067871, 20.948957443237305, 10.327280044555664, 9.852702140808105, 8.433327674865723, 9.935432434082031, 9.731480598449707, 8.307368278503418, 9.083669662475586, 8.62974739074707, 9.259795188903809, 7.847072601318359, 10.26301383972168, 4.547628402709961, 6.331954479217529, 3.659935474395752, 4.312592029571533, 8.50832748413086, 7.741361141204834, 15.46052074432373, 5.920116901397705, 3.534038543701172, 2.9371540546417236, 15.62542724609375, 2.849639415740967, 3.4018197059631348, 4.508718967437744, 2.228083610534668, 8.818222999572754, 1.66486394405365, 3.888792037963867, 1.6610618829727173, 2.1904969215393066, 3.273836851119995, 3.256859302520752, 2.7190728187561035, 3.202052116394043, 2.146949291229248, 2.145500659942627, 2.114847421646118, 1.5739916563034058, 2.1054766178131104, 7.354208946228027, 12.867671012878418, 5.62591028213501, 7.738765239715576, 2.5941057205200195, 3.8621981143951416, 6.799306392669678, 16.552932739257812, 8.006819725036621, 21.764923095703125, 15.722841262817383, 9.884525299072266, 5.445931434631348, 13.810576438903809, 24.287906646728516, 13.619357109069824, 8.210790634155273, 20.41166114807129, 5.571755409240723, 9.881098747253418, 27.565597534179688, 10.824350357055664, 14.296116828918457, 11.446840286254883, 8.02296257019043, 16.73312759399414, 12.162580490112305, 11.586528778076172, 13.078958511352539, 9.43844223022461, 10.15340805053711, 9.13033676147461, 9.776714324951172, 8.432769775390625, 8.058424949645996, 4.9593186378479, 3.3366317749023438, 13.00308609008789, 4.471928119659424, 4.87202787399292, 1.7292563915252686, 1.7201464176177979, 2.8336007595062256, 2.802382707595825, 2.1669399738311768, 1.5805139541625977, 2.0926408767700195, 4.644661903381348, 1.5175790786743164, 2.5172042846679688, 5.031623363494873, 4.976100921630859, 1.4847784042358398, 2.4776766300201416, 1.4597371816635132, 1.4468281269073486, 1.4391610622406006, 1.909144639968872, 1.432182788848877, 1.4103225469589233, 1.3774750232696533, 2.292133092880249, 1.8271771669387817, 3.6303646564483643, 0.9073131084442139, 11.751311302185059, 3.159147024154663, 2.729846954345703, 4.093750476837158, 19.3720703125, 6.274275779724121, 5.99292516708374, 2.251370906829834, 30.592012405395508, 2.9657819271087646, 7.0799665451049805, 10.346498489379883, 6.3961920738220215, 22.59174919128418, 12.8373384475708, 9.991569519042969, 5.4492645263671875, 14.644912719726562, 5.7119364738464355, 7.133455753326416, 12.05134105682373, 4.2383341789245605, 18.691537857055664, 9.235880851745605, 28.636106491088867, 6.049023151397705, 6.003740310668945, 10.62096118927002, 8.474767684936523, 17.153303146362305, 10.795882225036621, 8.461666107177734, 11.135345458984375, 7.149549961090088, 10.400276184082031, 8.124995231628418, 7.696896076202393, 8.291221618652344, 7.49985933303833, 7.168102741241455, 7.3866753578186035, 7.623715400695801, 7.228983402252197, 4.527356147766113, 3.3426389694213867, 3.338894844055176, 3.3150453567504883, 4.284087181091309, 2.1024632453918457, 2.637200117111206, 2.6355247497558594, 2.099095106124878, 3.6513941287994385, 2.578153610229492, 2.0024383068084717, 2.4660727977752686, 1.4790141582489014, 1.943722128868103, 1.4581698179244995, 1.4589896202087402, 1.9332385063171387, 1.9257967472076416, 1.444753646850586, 1.4385912418365479, 1.4362715482711792, 1.9065163135528564, 1.4300878047943115, 1.4275054931640625, 1.4149909019470215, 1.4111887216567993, 1.409654974937439, 1.4079642295837402, 1.4055125713348389, 4.488857269287109, 2.929175853729248, 2.2122533321380615, 7.993714809417725, 6.752820014953613, 4.088088035583496, 2.786484718322754, 3.673935651779175, 4.633325099945068, 12.124885559082031, 3.5540919303894043, 2.4488887786865234, 2.426298141479492, 6.270369052886963, 3.1854536533355713, 6.55118989944458, 5.978054523468018, 8.60265064239502, 6.1981635093688965, 4.055120944976807, 5.181966781616211, 13.708023071289062, 13.351892471313477, 9.622515678405762, 4.738062381744385, 14.119190216064453, 8.92117691040039, 9.054774284362793, 8.928159713745117, 7.366352558135986, 9.609994888305664, 5.674108982086182, 10.631146430969238, 7.81965446472168, 9.202837944030762, 15.744012832641602, 7.780094623565674, 12.56938648223877, 7.563215255737305, 7.732367992401123, 6.605155944824219, 7.667929172515869, 6.972034931182861, 6.404667377471924, 6.333793640136719, 6.412760257720947, 4.734431743621826, 6.371924877166748, 3.043172836303711, 3.516111135482788, 3.970902681350708, 5.6968536376953125, 2.238584041595459, 2.760939359664917, 2.7261550426483154, 1.6264842748641968, 1.618970513343811, 2.1319870948791504, 2.5302000045776367, 2.5113794803619385, 2.966207504272461, 2.4932758808135986, 1.987761378288269, 1.487112283706665, 1.96006441116333, 1.4485514163970947, 1.4337531328201294, 1.4220566749572754, 1.41692054271698, 1.4004720449447632, 1.3556095361709595, 1.3513644933700562, 1.3486467599868774, 1.7862862348556519, 1.3387200832366943, 1.3349312543869019, 2.6065049171447754, 2.5892937183380127, 4.935234546661377, 3.810262680053711, 4.372014045715332, 20.792282104492188, 15.259017944335938, 5.1391921043396, 2.9245123863220215, 4.825592517852783, 6.638184070587158, 15.523188591003418, 10.096821784973145, 6.471779823303223, 9.514854431152344, 5.45884370803833, 7.2295427322387695, 20.241716384887695, 9.704867362976074, 7.1744704246521, 7.965827941894531, 6.556488990783691, 8.197264671325684, 4.187668800354004, 7.4729413986206055, 6.460354804992676, 5.3747239112854, 5.786226749420166, 7.462771892547607, 7.104463577270508, 6.784419536590576, 6.862638473510742, 6.896144390106201, 6.022127628326416, 5.726450443267822, 5.483519554138184, 5.566633701324463, 5.6098833084106445, 5.593892574310303], \"Total\": [104.0, 116.0, 64.0, 69.0, 79.0, 107.0, 65.0, 54.0, 67.0, 42.0, 121.0, 55.0, 34.0, 30.0, 57.0, 125.0, 16.0, 22.0, 215.0, 94.0, 23.0, 62.0, 40.0, 78.0, 42.0, 49.0, 26.0, 73.0, 21.0, 38.0, 4.544824123382568, 9.998537063598633, 34.522132873535156, 6.335310935974121, 4.516066074371338, 6.335682392120361, 7.216277122497559, 4.510110378265381, 6.287298202514648, 3.592698812484741, 4.498477458953857, 3.5871541500091553, 5.381716728210449, 3.5844321250915527, 3.5863869190216064, 3.5821168422698975, 2.6934421062469482, 6.302971839904785, 3.5884997844696045, 2.678982734680176, 3.576500177383423, 2.677656888961792, 3.5757813453674316, 3.5670111179351807, 3.563605308532715, 2.676175832748413, 17.12628936767578, 2.6764798164367676, 2.6715431213378906, 2.6792898178100586, 3.560748815536499, 8.921875, 38.03489303588867, 10.617555618286133, 12.423504829406738, 10.609766006469727, 116.48515319824219, 7.962027072906494, 14.050694465637207, 19.241836547851562, 6.18977689743042, 39.42292022705078, 9.678461074829102, 31.3648681640625, 215.94985961914062, 30.486352920532227, 19.031248092651367, 86.73637390136719, 40.59223937988281, 59.40133285522461, 78.41410827636719, 25.882583618164062, 30.78915023803711, 16.63351821899414, 32.292118072509766, 52.82896041870117, 44.545997619628906, 41.43046951293945, 325.4212951660156, 38.210975646972656, 121.12763214111328, 40.69709014892578, 32.77238464355469, 53.24056625366211, 50.55164337158203, 130.02374267578125, 125.56517028808594, 93.89069366455078, 63.10004425048828, 77.06950378417969, 5.052973747253418, 14.33125114440918, 3.3628439903259277, 7.599043369293213, 5.046842575073242, 15.236551284790039, 5.894110679626465, 3.3621246814727783, 10.091957092285156, 5.068212985992432, 3.366760015487671, 3.367311716079712, 3.3618526458740234, 6.679996013641357, 3.3583457469940186, 5.051551818847656, 2.521287202835083, 2.5189332962036133, 7.550742149353027, 2.5185184478759766, 3.356452703475952, 4.220731735229492, 13.514375686645508, 5.07217264175415, 5.076740264892578, 10.16933536529541, 14.125709533691406, 3.3682854175567627, 3.3666412830352783, 3.3702011108398438, 4.206773281097412, 5.938209533691406, 8.378116607666016, 42.20551681518555, 28.3686466217041, 5.960748195648193, 23.01883888244629, 57.04342269897461, 72.09542846679688, 325.4212951660156, 7.719845771789551, 11.25360107421875, 30.32613754272461, 26.89593505859375, 26.577251434326172, 14.200517654418945, 67.73320770263672, 63.97243118286133, 125.56517028808594, 67.44889831542969, 48.48944854736328, 38.605262756347656, 49.690425872802734, 53.24056625366211, 107.18629455566406, 47.771728515625, 104.69618225097656, 48.60279083251953, 29.626510620117188, 39.03202438354492, 45.49854278564453, 52.3051643371582, 97.26411437988281, 82.08197021484375, 73.37113189697266, 130.02374267578125, 77.06950378417969, 57.90434646606445, 215.94985961914062, 4.525247573852539, 5.43137788772583, 6.285073280334473, 6.275835037231445, 4.485886573791504, 8.961522102355957, 4.479318618774414, 6.267961025238037, 8.060599327087402, 8.997872352600098, 3.596654176712036, 3.594343662261963, 6.254371166229248, 3.5702619552612305, 2.68205189704895, 17.88121223449707, 4.4741010665893555, 5.332240104675293, 5.3570404052734375, 4.435365676879883, 2.676131248474121, 13.336738586425781, 2.6748833656311035, 3.5484962463378906, 2.674332618713379, 2.6600191593170166, 2.658147096633911, 8.03766918182373, 10.573836326599121, 3.537620782852173, 7.938540458679199, 4.4330291748046875, 5.390349864959717, 5.338648796081543, 4.409876823425293, 9.625349044799805, 32.421871185302734, 11.257869720458984, 26.052947998046875, 50.95402526855469, 13.805145263671875, 13.837382316589355, 78.41410827636719, 23.48540687561035, 325.4212951660156, 9.609212875366211, 12.210878372192383, 215.94985961914062, 17.241178512573242, 18.184324264526367, 52.65406036376953, 94.82232666015625, 41.71485137939453, 116.48515319824219, 63.10004425048828, 54.044464111328125, 31.751605987548828, 51.087310791015625, 130.02374267578125, 63.97243118286133, 28.96169090270996, 38.210975646972656, 86.73637390136719, 107.18629455566406, 82.08197021484375, 51.297149658203125, 97.26411437988281, 41.43046951293945, 125.56517028808594, 30.75606918334961, 56.357017517089844, 121.12763214111328, 9.725726127624512, 8.913627624511719, 3.243530035018921, 8.940232276916504, 9.756783485412598, 13.885504722595215, 11.38189697265625, 7.333182334899902, 4.065168380737305, 2.436208963394165, 9.751938819885254, 6.555410861968994, 2.4417641162872314, 5.691556453704834, 4.888287544250488, 3.260408639907837, 3.2898812294006348, 4.1118693351745605, 4.103384017944336, 3.2743451595306396, 3.2634389400482178, 8.997049331665039, 3.274348735809326, 6.633727073669434, 24.584794998168945, 3.263914108276367, 2.449688196182251, 3.2602288722991943, 4.078275203704834, 3.263021230697632, 11.394808769226074, 5.739634037017822, 121.12763214111328, 19.95032501220703, 18.81700897216797, 13.389151573181152, 13.372869491577148, 94.82232666015625, 125.56517028808594, 35.522891998291016, 8.902444839477539, 21.934843063354492, 24.91944122314453, 56.88267517089844, 61.41548538208008, 82.08197021484375, 54.044464111328125, 107.18629455566406, 48.48944854736328, 63.10004425048828, 215.94985961914062, 49.690425872802734, 325.4212951660156, 72.09542846679688, 52.65406036376953, 50.55164337158203, 57.04342269897461, 59.93064498901367, 50.95402526855469, 43.86124801635742, 67.73320770263672, 130.02374267578125, 48.60279083251953, 97.26411437988281, 8.060121536254883, 6.423932075500488, 14.496423721313477, 5.630794048309326, 4.034230709075928, 4.842773914337158, 8.0648193359375, 4.853468418121338, 5.672638893127441, 4.851144313812256, 4.05411434173584, 4.838890552520752, 4.056996822357178, 3.2507381439208984, 3.237750291824341, 4.052142143249512, 4.857577800750732, 6.462956428527832, 7.267330169677734, 4.043963432312012, 3.233114004135132, 3.2347183227539062, 5.651134967803955, 3.2365739345550537, 3.236337184906006, 5.699450492858887, 3.249647855758667, 3.249760150909424, 3.25105357170105, 6.553641319274902, 6.480465888977051, 26.74024772644043, 8.92308521270752, 8.987447738647461, 19.054975509643555, 8.925328254699707, 7.238948345184326, 19.478702545166016, 5.689425945281982, 16.39408302307129, 33.0051383972168, 34.9697151184082, 7.280928134918213, 15.032631874084473, 215.94985961914062, 62.99592971801758, 116.48515319824219, 325.4212951660156, 73.37113189697266, 30.652395248413086, 97.26411437988281, 57.90434646606445, 33.464969635009766, 77.06950378417969, 13.108444213867188, 130.02374267578125, 79.21881866455078, 55.32257843017578, 93.89069366455078, 36.36807632446289, 35.21171951293945, 67.44889831542969, 53.27109146118164, 45.49854278564453, 34.689430236816406, 52.62635803222656, 121.12763214111328, 58.15795135498047, 12.252777099609375, 7.380185604095459, 4.868008613586426, 5.74713134765625, 3.2634427547454834, 4.922661304473877, 3.2814111709594727, 3.284315586090088, 6.5427961349487305, 3.2888898849487305, 2.454793930053711, 4.905586242675781, 3.2749905586242676, 4.9143548011779785, 7.458979606628418, 4.8961310386657715, 2.4688727855682373, 3.2899556159973145, 3.2910163402557373, 2.473534107208252, 3.2771589756011963, 4.1031389236450195, 2.4756925106048584, 2.4508728981018066, 3.2936432361602783, 2.462373971939087, 2.459139108657837, 2.459390640258789, 2.4503650665283203, 3.285433292388916, 19.77404022216797, 7.438168525695801, 12.495468139648438, 64.81736755371094, 4.131804466247559, 10.759393692016602, 6.559225559234619, 14.643515586853027, 54.10811233520508, 22.061750411987305, 10.729659080505371, 6.600303649902344, 4.926607131958008, 13.870464324951172, 9.032363891601562, 19.961225509643555, 67.73320770263672, 79.21881866455078, 36.699119567871094, 17.60723114013672, 30.540803909301758, 34.9697151184082, 73.37113189697266, 21.571699142456055, 130.02374267578125, 49.690425872802734, 15.791473388671875, 62.99592971801758, 69.12626647949219, 97.26411437988281, 45.49854278564453, 325.4212951660156, 57.90434646606445, 55.32257843017578, 36.36807632446289, 59.93064498901367, 63.97243118286133, 47.6443977355957, 77.06950378417969, 61.75168228149414, 93.89069366455078, 40.189857482910156, 12.8150053024292, 5.972026348114014, 8.610779762268066, 5.10573673248291, 6.024189472198486, 11.934762954711914, 11.081831932067871, 22.183879852294922, 8.595808029174805, 5.1341681480407715, 4.274089813232422, 23.159645080566406, 4.302295207977295, 5.13866662979126, 6.818291664123535, 3.4036037921905518, 13.644567489624023, 2.5779452323913574, 6.03220272064209, 2.5782017707824707, 3.4032559394836426, 5.105251312255859, 5.108487606048584, 4.292431831359863, 5.0998711585998535, 3.433197498321533, 3.4405088424682617, 3.4184653759002686, 2.5510425567626953, 3.415299415588379, 12.044546127319336, 21.358991622924805, 9.412031173706055, 13.5255765914917, 4.251685619354248, 6.75392484664917, 13.563926696777344, 40.92235565185547, 16.834142684936523, 65.11002349853516, 43.857051849365234, 24.630521774291992, 10.907544136047363, 43.86124801635742, 104.69618225097656, 47.00774002075195, 21.544443130493164, 107.18629455566406, 12.04931640625, 39.332664489746094, 325.4212951660156, 47.89739227294922, 94.82232666015625, 69.12626647949219, 29.276044845581055, 215.94985961914062, 93.89069366455078, 86.73637390136719, 130.02374267578125, 46.82162857055664, 77.06950378417969, 53.27109146118164, 121.12763214111328, 35.21171951293945, 52.3051643371582, 5.870209217071533, 4.193231105804443, 16.828022003173828, 5.861122131347656, 6.729979515075684, 2.5143845081329346, 2.515410900115967, 4.185271739959717, 4.185521125793457, 3.362628936767578, 2.5131099224090576, 3.363016366958618, 7.513629913330078, 2.518399477005005, 4.2028326988220215, 8.50171947479248, 8.418519020080566, 2.5183446407318115, 4.209289073944092, 2.525770902633667, 2.526503562927246, 2.527020215988159, 3.352931022644043, 2.5220463275909424, 2.527003288269043, 2.5126030445098877, 4.188246726989746, 3.350036382675171, 6.658694267272949, 1.676725149154663, 21.851186752319336, 5.867243766784668, 5.050310134887695, 7.705358982086182, 42.67033767700195, 12.59453296661377, 12.686135292053223, 4.186036109924316, 104.69618225097656, 5.894792556762695, 17.592552185058594, 30.540803909301758, 17.578031539916992, 107.18629455566406, 48.60279083251953, 34.62680435180664, 14.253949165344238, 65.11002349853516, 15.955275535583496, 23.202777862548828, 57.04342269897461, 10.13601016998291, 125.56517028808594, 40.4994010925293, 325.4212951660156, 18.84401512145996, 19.07063865661621, 67.73320770263672, 41.12773513793945, 215.94985961914062, 82.08197021484375, 49.690425872802734, 130.02374267578125, 31.996566772460938, 121.12763214111328, 54.10811233520508, 51.087310791015625, 72.09542846679688, 47.771728515625, 38.72808837890625, 47.6443977355957, 94.82232666015625, 61.41548538208008, 6.532296180725098, 4.885761260986328, 4.8855814933776855, 4.9248552322387695, 6.505058765411377, 3.2636969089508057, 4.094030380249023, 4.092909812927246, 3.261249542236328, 5.712218284606934, 4.106170654296875, 3.2691662311553955, 4.06273889541626, 2.4552574157714844, 3.270740270614624, 2.4558002948760986, 2.457261562347412, 3.270665168762207, 3.2676661014556885, 2.455505847930908, 2.455965518951416, 2.454411029815674, 3.2672996520996094, 2.4567487239837646, 2.454918622970581, 2.4574501514434814, 2.457054615020752, 2.456376791000366, 2.456911325454712, 2.4569005966186523, 8.217367172241211, 5.728634834289551, 4.146674156188965, 19.142240524291992, 16.63789939880371, 9.089986801147461, 5.699788570404053, 8.178093910217285, 11.399539947509766, 41.0759391784668, 8.240076065063477, 4.969249725341797, 4.950481414794922, 19.351831436157227, 7.305019855499268, 21.618946075439453, 18.9435977935791, 33.787391662597656, 21.154760360717773, 11.101945877075195, 16.730899810791016, 93.89069366455078, 97.26411437988281, 56.42521286010742, 15.215781211853027, 130.02374267578125, 56.357017517089844, 62.99592971801758, 61.75168228149414, 41.54679489135742, 78.41410827636719, 23.693317413330078, 104.69618225097656, 50.55164337158203, 79.21881866455078, 325.4212951660156, 52.82896041870117, 215.94985961914062, 58.15795135498047, 69.12626647949219, 45.49854278564453, 125.56517028808594, 86.73637390136719, 59.93064498901367, 67.44889831542969, 82.08197021484375, 5.5881195068359375, 8.008697509765625, 4.01457405090332, 4.860995292663574, 5.61967658996582, 8.074874877929688, 3.2148468494415283, 4.021883964538574, 4.022800445556641, 2.422778844833374, 2.4233570098876953, 3.223107099533081, 4.038558006286621, 4.046650409698486, 4.824681282043457, 4.06356143951416, 3.244372844696045, 2.442559242248535, 3.241525888442993, 2.448298454284668, 2.435487747192383, 2.4312655925750732, 2.4305777549743652, 2.4300405979156494, 2.4373111724853516, 2.4419660568237305, 2.440502166748047, 3.2552242279052734, 2.440276622772217, 2.4396510124206543, 4.847160339355469, 4.840977668762207, 10.613372802734375, 8.125809669494629, 9.803886413574219, 69.12626647949219, 55.32257843017578, 14.020702362060547, 6.548015594482422, 13.828716278076172, 22.12923812866211, 79.21881866455078, 42.05497741699219, 23.794448852539062, 57.90434646606445, 21.1575984954834, 38.605262756347656, 325.4212951660156, 73.37113189697266, 40.92235565185547, 53.27109146118164, 36.699119567871094, 62.99592971801758, 13.367600440979004, 56.42521286010742, 42.40682601928711, 25.86659812927246, 32.74878692626953, 78.41410827636719, 77.06950378417969, 97.26411437988281, 125.56517028808594, 130.02374267578125, 67.44889831542969, 53.24056625366211, 38.363319396972656, 52.62635803222656, 121.12763214111328, 215.94985961914062], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -7.046899795532227, -6.269999980926514, -5.035200119018555, -6.733699798583984, -7.0929999351501465, -6.7617998123168945, -6.642600059509277, -7.1132001876831055, -6.801300048828125, -7.383800029754639, -7.165299892425537, -7.398799896240234, -6.997700214385986, -7.405200004577637, -7.405200004577637, -7.419300079345703, -7.711699962615967, -6.870299816131592, -7.445499897003174, -7.753799915313721, -7.466800212860107, -7.758299827575684, -7.470200061798096, -7.481100082397461, -7.482600212097168, -7.769199848175049, -5.9145002365112305, -7.781899929046631, -7.788099765777588, -7.789400100708008, -7.50600004196167, -6.628300189971924, -5.239099979400635, -6.467599868774414, -6.325500011444092, -6.483399868011475, -4.308300018310547, -6.754700183868408, -6.245299816131592, -5.972899913787842, -6.991700172424316, -5.424099922180176, -6.620100021362305, -5.659599781036377, -4.234799861907959, -5.795599937438965, -6.163099765777588, -5.044300079345703, -5.618899822235107, -5.455699920654297, -5.3059000968933105, -6.014800071716309, -5.910600185394287, -6.347499847412109, -5.98360013961792, -5.718699932098389, -5.823999881744385, -5.879899978637695, -4.9633002281188965, -5.962500095367432, -5.4842000007629395, -5.9679999351501465, -6.090099811553955, -5.936699867248535, -5.9695000648498535, -5.759399890899658, -5.846399784088135, -5.945000171661377, -6.028299808502197, -6.008500099182129, -6.859099864959717, -5.8221001625061035, -7.275300025939941, -6.464300155639648, -6.882999897003174, -5.786300182342529, -6.757500171661377, -7.331900119781494, -6.236999988555908, -6.930300235748291, -7.35699987411499, -7.359899997711182, -7.37529993057251, -6.691800117492676, -7.388999938964844, -6.981299877166748, -7.677000045776367, -7.686399936676025, -6.593400001525879, -7.691800117492676, -7.407299995422363, -7.188199996948242, -6.0269999504089355, -7.019400119781494, -7.0254998207092285, -6.331999778747559, -6.006100177764893, -7.439899921417236, -7.440899848937988, -7.4430999755859375, -7.225500106811523, -6.890900135040283, -6.577899932861328, -5.064799785614014, -5.47629976272583, -6.900199890136719, -5.835400104522705, -5.161799907684326, -4.9928998947143555, -3.9309000968933105, -6.765399932861328, -6.499100208282471, -5.807000160217285, -5.9517998695373535, -5.96150016784668, -6.376699924468994, -5.452899932861328, -5.513199806213379, -5.133299827575684, -5.541800022125244, -5.732900142669678, -5.867700099945068, -5.749100208282471, -5.723499774932861, -5.393400192260742, -5.786799907684326, -5.427700042724609, -5.787300109863281, -6.035900115966797, -5.928899765014648, -5.8769001960754395, -5.828700065612793, -5.6367998123168945, -5.743199825286865, -5.78439998626709, -5.763599872589111, -5.834199905395508, -5.89739990234375, -5.828400135040283, -6.886199951171875, -6.71999979019165, -6.619699954986572, -6.63129997253418, -6.971700191497803, -6.283599853515625, -6.986700057983398, -6.657199859619141, -6.4253997802734375, -6.3165998458862305, -7.234799861907959, -7.240300178527832, -6.704899787902832, -7.269999980926514, -7.55649995803833, -5.662300109863281, -7.054800033569336, -6.892899990081787, -6.893199920654297, -7.1016998291015625, -7.607100009918213, -6.00540018081665, -7.6346001625061035, -7.3520002365112305, -7.636300086975098, -7.650300025939941, -7.658699989318848, -6.556399822235107, -6.285799980163574, -7.381400108337402, -6.578199863433838, -7.157599925994873, -6.973400115966797, -6.991300106048584, -7.177000045776367, -6.485300064086914, -5.5218000411987305, -6.436100006103516, -5.7947998046875, -5.284800052642822, -6.28410005569458, -6.282700061798096, -5.041200160980225, -5.939700126647949, -4.15339994430542, -6.5706000328063965, -6.420300006866455, -4.6732001304626465, -6.221199989318848, -6.202000141143799, -5.622900009155273, -5.317200183868408, -5.770400047302246, -5.241499900817871, -5.6321001052856445, -5.736999988555908, -5.98769998550415, -5.800899982452393, -5.420599937438965, -5.735400199890137, -6.046500205993652, -5.9421000480651855, -5.640999794006348, -5.573200225830078, -5.708600044250488, -5.860799789428711, -5.720600128173828, -6.003699779510498, -5.7515997886657715, -6.100599765777588, -6.011000156402588, -5.97760009765625, -6.10890007019043, -6.21150016784668, -7.255899906158447, -6.249100208282471, -6.171299934387207, -5.85129976272583, -6.052999973297119, -6.494800090789795, -7.099400043487549, -7.615200042724609, -6.234600067138672, -6.642399787902832, -7.6392998695373535, -6.796500205993652, -6.956099987030029, -7.362400054931641, -7.357999801635742, -7.156199932098389, -7.161300182342529, -7.39300012588501, -7.399600028991699, -6.385499954223633, -7.402100086212158, -6.696100234985352, -5.38670015335083, -7.418600082397461, -7.7058000564575195, -7.436299800872803, -7.2129998207092285, -7.437699794769287, -6.1890997886657715, -6.913599967956543, -4.288400173187256, -5.906099796295166, -5.983399868011475, -6.26609992980957, -6.2677001953125, -4.7322001457214355, -4.574900150299072, -5.554999828338623, -6.614299774169922, -5.964600086212158, -5.90369987487793, -5.343400001525879, -5.303400039672852, -5.176499843597412, -5.485599994659424, -5.196199893951416, -5.665999889373779, -5.541299819946289, -4.985400199890137, -5.723400115966797, -5.03410005569458, -5.624800205230713, -5.757199764251709, -5.774700164794922, -5.775899887084961, -5.771200180053711, -5.831500053405762, -5.883600234985352, -5.810500144958496, -5.72599983215332, -5.877099990844727, -5.912600040435791, -6.207300186157227, -6.4558000564575195, -5.664899826049805, -6.637199878692627, -6.974599838256836, -6.793799877166748, -6.310999870300293, -6.833000183105469, -6.680200099945068, -6.845600128173828, -7.026700019836426, -6.8618998527526855, -7.046500205993652, -7.268899917602539, -7.273799896240234, -7.052000045776367, -6.870999813079834, -6.58620023727417, -6.473700046539307, -7.06820011138916, -7.297500133514404, -7.299699783325195, -6.747900009155273, -7.312300205230713, -7.31820011138916, -6.7530999183654785, -7.321899890899658, -7.328999996185303, -7.331600189208984, -6.635700225830078, -6.664000034332275, -5.321700096130371, -6.3643999099731445, -6.392099857330322, -5.73859977722168, -6.427199840545654, -6.621200084686279, -5.799799919128418, -6.823999881744385, -6.069900035858154, -5.6407999992370605, -5.634500026702881, -6.661900043487549, -6.198200225830078, -4.521200180053711, -5.306399822235107, -5.042900085449219, -4.514400005340576, -5.423999786376953, -5.901199817657471, -5.371500015258789, -5.627200126647949, -5.89169979095459, -5.565800189971924, -6.347400188446045, -5.371500015258789, -5.6057000160217285, -5.7631001472473145, -5.583099842071533, -5.957600116729736, -6.031499862670898, -5.870699882507324, -5.938600063323975, -6.022799968719482, -6.08459997177124, -6.042099952697754, -5.982699871063232, -6.065700054168701, -5.6381001472473145, -6.274899959564209, -6.691199779510498, -6.527400016784668, -7.106299877166748, -6.698299884796143, -7.144800186157227, -7.153200149536133, -6.468500137329102, -7.167399883270264, -7.484899997711182, -6.804599761962891, -7.214000225067139, -6.820300102233887, -6.416600227355957, -6.84119987487793, -7.533100128173828, -7.2631001472473145, -7.269000053405762, -7.555600166320801, -7.2778000831604, -7.056099891662598, -7.565499782562256, -7.576300144195557, -7.288400173187256, -7.579599857330322, -7.580900192260742, -7.584099769592285, -7.592599868774414, -7.303899765014648, -5.531700134277344, -6.5015997886657715, -6.006999969482422, -4.431600093841553, -7.087900161743164, -6.195300102233887, -6.658199787139893, -5.950099945068359, -4.783400058746338, -5.601500034332275, -6.242599964141846, -6.680200099945068, -6.932799816131592, -6.098899841308594, -6.475100040435791, -5.892099857330322, -4.995100021362305, -4.92080020904541, -5.5802998542785645, -6.062399864196777, -5.717100143432617, -5.635499954223633, -5.192599773406982, -5.94789981842041, -5.009500026702881, -5.577300071716309, -6.188199996948242, -5.5441999435424805, -5.548799991607666, -5.408199787139893, -5.748000144958496, -4.9506001472473145, -5.657899856567383, -5.704899787902832, -5.860400199890137, -5.696499824523926, -5.717299938201904, -5.875500202178955, -5.786200046539307, -5.837399959564209, -5.767000198364258, -5.932499885559082, -5.649600028991699, -6.463500022888184, -6.132500171661377, -6.680699825286865, -6.516600131988525, -5.837100028991699, -5.93149995803833, -5.239799976348877, -6.19980001449585, -6.715700149536133, -6.900700092315674, -5.2291998863220215, -6.9309000968933105, -6.753799915313721, -6.472099781036377, -7.177000045776367, -5.801300048828125, -7.468400001525879, -6.619999885559082, -7.470699787139893, -7.193999767303467, -6.792099952697754, -6.797299861907959, -6.977799892425537, -6.814300060272217, -7.214099884033203, -7.214700222015381, -7.229100227355957, -7.524499893188477, -7.23360013961792, -5.982800006866455, -5.423399925231934, -6.250699996948242, -5.9319000244140625, -7.024899959564209, -6.6269001960754395, -6.061299800872803, -5.171500205993652, -5.897799968719482, -4.897799968719482, -5.2230000495910645, -5.687099933624268, -6.283199787139893, -5.352700233459473, -4.788099765777588, -5.366600036621094, -5.872700214385986, -4.961999893188477, -6.26039981842041, -5.6875, -4.661499977111816, -5.59630012512207, -5.3180999755859375, -5.54040002822876, -5.8958001136779785, -5.160699844360352, -5.479700088500977, -5.528299808502197, -5.407100200653076, -5.73330020904541, -5.660299777984619, -5.766499996185303, -5.6981000900268555, -5.8460001945495605, -5.89139986038208, -6.249100208282471, -6.645500183105469, -5.285200119018555, -6.35260009765625, -6.266900062561035, -7.302700042724609, -7.308000087738037, -6.808899879455566, -6.819900035858154, -7.077099800109863, -7.3927001953125, -7.111999988555908, -6.314700126647949, -7.433300018310547, -6.927299976348877, -6.2347002029418945, -6.245800018310547, -7.455100059509277, -6.9430999755859375, -7.4721999168396, -7.480999946594238, -7.486400127410889, -7.203800201416016, -7.491199970245361, -7.5065999031066895, -7.530200004577637, -7.020899772644043, -7.247600078582764, -6.561100006103516, -7.947700023651123, -5.38640022277832, -6.700099945068359, -6.846199989318848, -6.440999984741211, -4.886600017547607, -6.013999938964844, -6.059800148010254, -7.038899898529053, -4.429699897766113, -6.763299942016602, -5.893099784851074, -5.513800144195557, -5.994699954986572, -4.732800006866455, -5.298099994659424, -5.548699855804443, -6.154900074005127, -5.166299819946289, -6.107900142669678, -5.8856000900268555, -5.361199855804443, -6.406199932098389, -4.922299861907959, -5.627299785614014, -4.495699882507324, -6.05049991607666, -6.058000087738037, -5.487599849700928, -5.7133002281188965, -5.008200168609619, -5.471199989318848, -5.714900016784668, -5.440299987792969, -5.883399963378906, -5.508600234985352, -5.755499839782715, -5.809599876403809, -5.735199928283691, -5.8354997634887695, -5.880799770355225, -5.8506999015808105, -5.8190999031066895, -5.872300148010254, -6.301599979400635, -6.605000019073486, -6.606100082397461, -6.6132001876831055, -6.356800079345703, -7.068600177764893, -6.8420000076293945, -6.842599868774414, -7.070199966430664, -6.516600131988525, -6.86460018157959, -7.117400169372559, -6.90910005569458, -7.420300006866455, -7.14709997177124, -7.434500217437744, -7.434000015258789, -7.152500152587891, -7.156400203704834, -7.44379997253418, -7.4481000900268555, -7.449699878692627, -7.166399955749512, -7.453999996185303, -7.4558000564575195, -7.464600086212158, -7.467299938201904, -7.468400001525879, -7.469600200653076, -7.47130012512207, -6.310100078582764, -6.736999988555908, -7.0177001953125, -5.733099937438965, -5.901800155639648, -6.403600215911865, -6.786900043487549, -6.510499954223633, -6.27839994430542, -5.316500186920166, -6.543600082397461, -6.916100025177002, -6.9253997802734375, -5.975900173187256, -6.65310001373291, -5.93209981918335, -6.023600101470947, -5.659599781036377, -5.987500190734863, -6.4116997718811035, -6.166500091552734, -5.193699836730957, -5.220099925994873, -5.547599792480469, -6.256100177764893, -5.1641998291015625, -5.623300075531006, -5.608399868011475, -5.622499942779541, -5.814799785614014, -5.548900127410889, -6.075799942016602, -5.44789981842041, -5.755099773406982, -5.592199802398682, -5.055300235748291, -5.7600998878479, -5.2804999351501465, -5.788400173187256, -5.766300201416016, -5.923900127410889, -5.774700164794922, -5.869800090789795, -5.954699993133545, -5.965799808502197, -5.953400135040283, -6.1468000411987305, -5.849800109863281, -6.588799953460693, -6.444300174713135, -6.322700023651123, -5.9618000984191895, -6.8958001136779785, -6.686100006103516, -6.698800086975098, -7.2153000831604, -7.219900131225586, -6.9446001052856445, -6.773399829864502, -6.780799865722656, -6.6143999099731445, -6.788099765777588, -7.014699935913086, -7.304800033569336, -7.02869987487793, -7.331099987030029, -7.341400146484375, -7.349599838256836, -7.3531999588012695, -7.3649001121521, -7.39739990234375, -7.400599956512451, -7.402599811553955, -7.121500015258789, -7.409999847412109, -7.412799835205078, -6.74370002746582, -6.75029993057251, -6.105299949645996, -6.363999843597412, -6.226500034332275, -4.667099952697754, -4.976500034332275, -6.064799785614014, -6.628499984741211, -6.127699851989746, -5.808800220489502, -4.9593000411987305, -5.389500141143799, -5.834199905395508, -5.448800086975098, -6.00439977645874, -5.723499774932861, -4.693900108337402, -5.428999900817871, -5.731100082397461, -5.626500129699707, -5.821199893951416, -5.597899913787842, -6.269499778747559, -5.690400123596191, -5.835999965667725, -6.019999980926514, -5.946199893951416, -5.691699981689453, -5.741000175476074, -5.7870001792907715, -5.775599956512451, -5.770699977874756, -5.906199932098389, -5.956600189208984, -5.999899864196777, -5.984899997711182, -5.977099895477295, -5.980000019073486], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.7725000381469727, 1.7610000371932983, 1.756700038909912, 1.753600001335144, 1.732800006866455, 1.7254999876022339, 1.7144999504089355, 1.7138999700546265, 1.693600058555603, 1.670799970626831, 1.6643999814987183, 1.6572999954223633, 1.6526999473571777, 1.6517000198364258, 1.6511000394821167, 1.638200044631958, 1.6309000253677368, 1.6220999956130981, 1.610200047492981, 1.5943000316619873, 1.5922000408172607, 1.5901999473571777, 1.5889999866485596, 1.5806000232696533, 1.5801000595092773, 1.5799000263214111, 1.5784000158309937, 1.5671000480651855, 1.5627000331878662, 1.558500051498413, 1.5575000047683716, 1.516700029373169, 1.4558000564575195, 1.5032999515533447, 1.4883999824523926, 1.4882999658584595, 1.2674000263214111, 1.50409996509552, 1.4455000162124634, 1.403499960899353, 1.5189000368118286, 1.2350000143051147, 1.44350004196167, 1.2280999422073364, 0.7235999703407288, 1.1204999685287476, 1.2242000102996826, 0.8263000249862671, 1.0110000371932983, 0.79339998960495, 0.6654999852180481, 1.0650999546051025, 0.9957000017166138, 1.1744999885559082, 0.8751000165939331, 0.647599995136261, 0.7129999995231628, 0.7296000123023987, -0.41499999165534973, 0.7278000116348267, 0.052400000393390656, 0.6593000292778015, 0.7537000179290771, 0.421999990940094, 0.4410000145435333, -0.2937000095844269, -0.3456999957561493, -0.15360000729560852, 0.16040000319480896, -0.019700000062584877, 1.8544000387191772, 1.8488999605178833, 1.8453999757766724, 1.8411999940872192, 1.8316999673843384, 1.8234000205993652, 1.8020000457763672, 1.7890000343322754, 1.7847000360488892, 1.7802000045776367, 1.7625000476837158, 1.7594000101089478, 1.7457000017166138, 1.7424999475479126, 1.7330000400543213, 1.7324999570846558, 1.731600046157837, 1.7232999801635742, 1.718400001525879, 1.718000054359436, 1.7152999639511108, 1.705199956893921, 1.7027000188827515, 1.6901999711990356, 1.6833000183105469, 1.6821000576019287, 1.6793999671936035, 1.6792000532150269, 1.6786999702453613, 1.6754000186920166, 1.6712000370025635, 1.6612000465393066, 1.6298999786376953, 1.5261000394821167, 1.5118999481201172, 1.6481000185012817, 1.3617000579833984, 1.1277999877929688, 1.062600016593933, 0.6173999905586243, 1.5241999626159668, 1.413599967956543, 1.1145000457763672, 1.0896999835968018, 1.0918999910354614, 1.3035000562667847, 0.6650000214576721, 0.6618000268936157, 0.36730000376701355, 0.580299973487854, 0.7192000150680542, 0.8123000264167786, 0.6784999966621399, 0.6351000070571899, 0.2653999924659729, 0.6801999807357788, 0.2547000050544739, 0.6625000238418579, 0.9089000225067139, 0.7401999831199646, 0.6388999819755554, 0.5475999712944031, 0.11919999867677689, 0.18250000476837158, 0.2535000145435333, -0.29789999127388, 0.15459999442100525, 0.37720000743865967, -0.8700000047683716, 1.937600016593933, 1.9213000535964966, 1.875499963760376, 1.865399956703186, 1.8609000444412231, 1.8568999767303467, 1.8473000526428223, 1.8408000469207764, 1.8209999799728394, 1.8199000358581543, 1.8186999559402466, 1.8137999773025513, 1.795199990272522, 1.7907999753952026, 1.7904000282287598, 1.7874000072479248, 1.780400037765503, 1.766700029373169, 1.7618000507354736, 1.7422000169754028, 1.7419999837875366, 1.7374999523162842, 1.715000033378601, 1.714900016784668, 1.7135000228881836, 1.704800009727478, 1.697100043296814, 1.6928999423980713, 1.6892999410629272, 1.688599944114685, 1.683500051498413, 1.6868000030517578, 1.6754000186920166, 1.667199969291687, 1.6726000308990479, 1.583799958229065, 1.332800030708313, 1.4763000011444092, 1.278499960899353, 1.1176999807357788, 1.424299955368042, 1.4234000444412231, 0.9301999807357788, 1.2373000383377075, 0.39500001072883606, 1.500100016593933, 1.4107999801635742, 0.28519999980926514, 1.2649999856948853, 1.2309000492095947, 0.7468000054359436, 0.4641999900341034, 0.8321999907493591, 0.334199994802475, 0.5565999746322632, 0.6065999865531921, 0.8877999782562256, 0.5989999771118164, 0.045099999755620956, 0.43959999084472656, 0.9210000038146973, 0.748199999332428, 0.2295999974012375, 0.08569999784231186, 0.21709999442100525, 0.5350000262260437, 0.03539999946951866, 0.6057000160217285, -0.25099998712539673, 0.8068000078201294, 0.2906999886035919, -0.4410000145435333, 1.9498000144958496, 1.934399962425232, 1.9009000062942505, 1.8938000202178955, 1.8841999769210815, 1.8513000011444092, 1.8483999967575073, 1.8463000059127808, 1.8315999507904053, 1.8278000354766846, 1.8213000297546387, 1.8107999563217163, 1.8014999628067017, 1.7979999780654907, 1.7905000448226929, 1.789199948310852, 1.784600019454956, 1.7633999586105347, 1.7603000402450562, 1.7544000148773193, 1.751099944114685, 1.751099944114685, 1.7452000379562378, 1.7452000379562378, 1.7446999549865723, 1.7318999767303467, 1.7316999435424805, 1.715399980545044, 1.7148000001907349, 1.7130999565124512, 1.7111999988555908, 1.6723999977111816, 1.2482000589370728, 1.4341000318527222, 1.4153000116348267, 1.4729000329971313, 1.472499966621399, 1.0492000579833984, 0.9258000254631042, 1.2081999778747559, 1.5327999591827393, 1.2807999849319458, 1.2141000032424927, 0.9490000009536743, 0.9124000072479248, 0.7491999864578247, 0.8579999804496765, 0.4627000093460083, 0.7860999703407288, 0.6474000215530396, -0.027000000700354576, 0.7042999863624573, -0.48579999804496765, 0.43070000410079956, 0.612500011920929, 0.6358000040054321, 0.513700008392334, 0.4690999984741211, 0.5710999965667725, 0.6689000129699707, 0.30730000138282776, -0.26019999384880066, 0.5726000070571899, -0.1565999984741211, 2.0392000675201416, 2.0176000595092773, 1.9946999549865723, 1.968000054359436, 1.9639999866485596, 1.9621000289916992, 1.9349000453948975, 1.920799970626831, 1.9176000356674194, 1.9085999727249146, 1.906999945640564, 1.8947999477386475, 1.8865000009536743, 1.885599970817566, 1.8847999572753906, 1.882200002670288, 1.8818999528884888, 1.881100058555603, 1.8763999938964844, 1.8680000305175781, 1.8624999523162842, 1.8597999811172485, 1.853700041770935, 1.8466999530792236, 1.8408000469207764, 1.840000033378601, 1.8329999446868896, 1.8258999586105347, 1.8229000568389893, 1.8177000284194946, 1.8006000518798828, 1.725600004196167, 1.780400037765503, 1.7455999851226807, 1.6476000547409058, 1.7173000574111938, 1.732800006866455, 1.5642999410629272, 1.770799994468689, 1.466599941253662, 1.1959999799728394, 1.1445000171661377, 1.6863000392913818, 1.4249999523162842, 0.43720000982284546, 0.883899986743927, 0.532800018787384, 0.033900000154972076, 0.6139000058174133, 1.0095000267028809, 0.38449999690055847, 0.6474000215530396, 0.9312999844551086, 0.4230000078678131, 1.4127999544143677, 0.09430000185966492, 0.3555000126361847, 0.557200014591217, 0.20819999277591705, 0.7821999788284302, 0.7405999898910522, 0.2513999938964844, 0.41940000653266907, 0.492900013923645, 0.7024000287055969, 0.3280999958515167, -0.44609999656677246, 0.2046000063419342, 2.1895999908447266, 2.059799909591675, 2.0596001148223877, 2.057300090789795, 2.0443999767303467, 2.041300058364868, 2.0004000663757324, 1.9910999536514282, 1.9866000413894653, 1.9754999876022339, 1.9505000114440918, 1.9385000467300415, 1.9330999851226807, 1.9210000038146973, 1.9075000286102295, 1.9038000106811523, 1.8966000080108643, 1.8795000314712524, 1.8732999563217163, 1.8722000122070312, 1.8686000108718872, 1.8655999898910522, 1.8615000247955322, 1.860700011253357, 1.8530999422073364, 1.8526999950408936, 1.8526999950408936, 1.8494999408721924, 1.844599962234497, 1.8401000499725342, 1.8173999786376953, 1.8251999616622925, 1.8011000156402588, 1.730299949645996, 1.826799988746643, 1.7623000144958496, 1.7943999767303467, 1.6993999481201172, 1.5591000318527222, 1.638100028038025, 1.7178000211715698, 1.7661999464035034, 1.805999994277954, 1.6047999858856201, 1.6576000452041626, 1.44760000705719, 1.1227999925613403, 1.0404000282287598, 1.1504000425338745, 1.4026999473571777, 1.1972999572753906, 1.1434999704360962, 0.8453999757766724, 1.3141000270843506, 0.4562000036239624, 0.8503000140190125, 1.3858000040054321, 0.6460999846458435, 0.5486999750137329, 0.34779998660087585, 0.767799973487854, -0.40220001339912415, 0.6168000102043152, 0.6154000163078308, 0.8792999982833862, 0.5436999797821045, 0.4577000141143799, 0.5942000150680542, 0.20260000228881836, 0.37290000915527344, 0.024399999529123306, 0.7073000073432922, 2.1333000659942627, 2.082900047302246, 2.0478999614715576, 2.02239990234375, 2.0211000442504883, 2.016900062561035, 1.9966000318527222, 1.9943000078201294, 1.9823999404907227, 1.9818999767303467, 1.9802000522613525, 1.9617999792099, 1.9434000253677368, 1.9428999423980713, 1.9416999816894531, 1.9315999746322632, 1.9187999963760376, 1.9180999994277954, 1.9163000583648682, 1.9156999588012695, 1.9147000312805176, 1.9110000133514404, 1.9052000045776367, 1.898800015449524, 1.8898999691009521, 1.8859000205993652, 1.8831000328063965, 1.875100016593933, 1.872499942779541, 1.8716000318527222, 1.8619999885559082, 1.8486000299453735, 1.8407000303268433, 1.7970000505447388, 1.861299991607666, 1.7964999675750732, 1.6647000312805176, 1.4501999616622925, 1.6122000217437744, 1.259600043296814, 1.3294999599456787, 1.4422999620437622, 1.6607999801635742, 1.1996999979019165, 0.8942999839782715, 1.1165000200271606, 1.3906999826431274, 0.6969000101089478, 1.5839999914169312, 0.9739000201225281, -0.11320000141859055, 0.8680999875068665, 0.4632999897003174, 0.5570999979972839, 1.0608999729156494, -0.20229999721050262, 0.311599999666214, 0.3422999978065491, 0.05860000103712082, 0.7537999749183655, 0.32839998602867126, 0.5914999842643738, -0.1615000069141388, 0.9261000156402588, 0.48500001430511475, 2.3143999576568604, 2.254499912261963, 2.2251999378204346, 2.2125000953674316, 2.1600000858306885, 2.1087000370025635, 2.1029999256134033, 2.0929999351501465, 2.081899881362915, 2.043600082397461, 2.0192999839782715, 2.0085999965667725, 2.002000093460083, 1.9765000343322754, 1.9703999757766724, 1.9585000276565552, 1.9572999477386475, 1.954699993133545, 1.9530999660491943, 1.9347000122070312, 1.9256000518798828, 1.9200999736785889, 1.9198999404907227, 1.917199969291687, 1.8997999429702759, 1.8819999694824219, 1.8802000284194946, 1.8767999410629272, 1.8763999938964844, 1.868899941444397, 1.8626999855041504, 1.8639999628067017, 1.867799997329712, 1.850600004196167, 1.6934000253677368, 1.7862000465393066, 1.7331000566482544, 1.8628000020980835, 1.2526999711990356, 1.7961000204086304, 1.5728000402450562, 1.4005999565124512, 1.472100019454956, 0.9261000156402588, 1.1517000198364258, 1.2402000427246094, 1.5214999914169312, 0.991100013256073, 1.4558000564575195, 1.3035999536514282, 0.9283999800682068, 1.6110999584197998, 0.5782999992370605, 1.0047999620437622, 0.05260000005364418, 1.3466999530792236, 1.327299952507019, 0.630299985408783, 0.9034000039100647, -0.049800001084804535, 0.4544999897480011, 0.7128000259399414, 0.02539999969303608, 0.984499990940094, 0.02800000086426735, 0.5870000123977661, 0.5903000235557556, 0.32019999623298645, 0.6315000057220459, 0.7961000204086304, 0.6190000176429749, -0.037700001150369644, 0.3434999883174896, 2.155100107192993, 2.142199993133545, 2.1410999298095703, 2.1259000301361084, 2.104099988937378, 2.0820000171661377, 2.081899881362915, 2.0815999507904053, 2.0810999870300293, 2.074199914932251, 2.056299924850464, 2.031599998474121, 2.0225000381469727, 2.014899969100952, 2.001300096511841, 2.000499963760376, 2.0004000663757324, 1.99590003490448, 1.9930000305175781, 1.9912999868392944, 1.986899971961975, 1.9859000444412231, 1.9830000400543213, 1.9805999994277954, 1.979599952697754, 1.9696999788284302, 1.9672000408172607, 1.9664000272750854, 1.965000033378601, 1.9631999731063843, 1.917099952697754, 1.8509999513626099, 1.893399953842163, 1.6484999656677246, 1.6200000047683716, 1.722599983215332, 1.8061000108718872, 1.721500039100647, 1.621399998664856, 1.3015999794006348, 1.680799961090088, 1.8141000270843506, 1.8085999488830566, 1.3947999477386475, 1.6917999982833862, 1.3278000354766846, 1.368399977684021, 1.1536999940872192, 1.294100046157837, 1.5146000385284424, 1.3496999740600586, 0.597599983215332, 0.5360000133514404, 0.7529000043869019, 1.3550000190734863, 0.30160000920295715, 0.6784999966621399, 0.5820000171661377, 0.5878000259399414, 0.7918000221252441, 0.42250001430511475, 1.0924999713897705, 0.2345000058412552, 0.6553999781608582, 0.36899998784065247, -0.5069000124931335, 0.6061999797821045, -0.32199999690055847, 0.48190000653266907, 0.3312000036239624, 0.5918999910354614, -0.27399998903274536, 0.0007999999797903001, 0.2856000065803528, 0.15629999339580536, -0.027699999511241913, 2.4660000801086426, 2.40310001373291, 2.3547000885009766, 2.3078999519348145, 2.2844998836517334, 2.282900094985962, 2.2697999477386475, 2.2555999755859375, 2.2427000999450684, 2.233299970626831, 2.2283999919891357, 2.2184998989105225, 2.1642000675201416, 2.1547000408172607, 2.1452999114990234, 2.1433000564575195, 2.141900062561035, 2.1356000900268555, 2.128700017929077, 2.1068999767303467, 2.101900100708008, 2.0954999923706055, 2.092099905014038, 2.080699920654297, 2.045099973678589, 2.04010009765625, 2.0387001037597656, 2.0316998958587646, 2.031399965286255, 2.0288000106811523, 2.011399984359741, 2.00600004196167, 1.8660999536514282, 1.874400019645691, 1.8242000341415405, 1.430400013923645, 1.3437999486923218, 1.628100037574768, 1.825700044631958, 1.5789999961853027, 1.4277000427246094, 1.0018999576568604, 1.2050000429153442, 1.329800009727478, 0.8258000016212463, 1.2769999504089355, 0.95660001039505, -0.14560000598430634, 0.6089000105857849, 0.8906000256538391, 0.7315000295639038, 0.909500002861023, 0.5924999713897705, 1.4710999727249146, 0.6100999712944031, 0.7501000165939331, 1.0605000257492065, 0.8984000086784363, 0.27970001101493835, 0.24779999256134033, -0.03099999949336052, -0.2750000059604645, -0.3050000071525574, 0.21580000221729279, 0.4020000100135803, 0.6863999962806702, 0.38530001044273376, -0.4404999911785126, -1.0216000080108643]}, \"token.table\": {\"Topic\": [7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 7, 8, 9, 8, 1, 4, 1, 4, 7, 8, 9, 6, 1, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 5, 7, 1, 5, 6, 9, 4, 5, 2, 5, 7, 2, 3, 5, 7, 8, 9, 1, 3, 6, 10, 1, 2, 3, 6, 8, 9, 10, 3, 3, 4, 7, 8, 10, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 7, 8, 4, 1, 2, 1, 6, 9, 1, 2, 3, 4, 5, 6, 7, 8, 5, 9, 1, 2, 3, 4, 5, 6, 7, 10, 7, 5, 6, 8, 1, 3, 1, 3, 4, 5, 6, 7, 8, 10, 9, 3, 5, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 5, 1, 2, 5, 6, 9, 10, 2, 8, 1, 2, 3, 4, 6, 7, 9, 10, 2, 2, 4, 5, 9, 4, 9, 5, 2, 3, 4, 5, 10, 7, 4, 9, 10, 1, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 10, 2, 4, 6, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 5, 2, 4, 7, 10, 3, 4, 6, 3, 6, 1, 4, 7, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 7, 8, 1, 5, 9, 5, 2, 3, 4, 8, 10, 1, 2, 3, 4, 5, 6, 9, 10, 6, 9, 2, 4, 9, 1, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 6, 9, 2, 1, 2, 3, 4, 5, 6, 7, 8, 9, 8, 3, 6, 10, 2, 6, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 8, 1, 2, 4, 5, 7, 10, 2, 3, 8, 2, 3, 4, 5, 6, 7, 8, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 3, 4, 6, 8, 10, 1, 1, 2, 3, 8, 2, 3, 1, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 8, 9, 10, 1, 1, 3, 4, 5, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 3, 4, 6, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 6, 7, 8, 9, 10, 1, 2, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 6, 2, 8, 1, 4, 7, 8, 9, 10, 2, 3, 6, 6, 10, 10, 9, 1, 2, 5, 6, 9, 10, 1, 5, 6, 6, 2, 3, 4, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 9, 10, 1, 2, 3, 4, 5, 7, 8, 9, 10, 2, 2, 5, 1, 3, 4, 5, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 1, 2, 5, 6, 9, 2, 3, 6, 10, 1, 4, 6, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 9, 2, 6, 10, 1, 10, 7, 6, 9, 2, 3, 5, 6, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 3, 1, 5, 10, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 8, 1, 3, 1, 2, 3, 6, 8, 3, 1, 2, 3, 4, 6, 7, 8, 3, 1, 2, 3, 4, 8, 4, 6, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 9, 1, 2, 3, 4, 5, 7, 9, 10, 6, 1, 1, 2, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 5, 1, 2, 3, 4, 5, 6, 8, 9, 10, 2, 5, 1, 3, 5, 8, 9, 1, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 1, 2, 3, 4, 2, 3, 4, 5, 6, 7, 9, 10, 6, 7, 9, 3, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 1, 3, 4, 1, 1, 5, 4, 2, 6, 6, 9, 2, 2, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 8, 1, 2, 3, 6, 8, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 4, 6, 8, 1, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 6, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 9, 10, 6, 1, 3, 1, 4, 2, 4, 7, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 2, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 3, 3, 4, 5, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 5, 8, 8, 3, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 8, 2, 8, 5, 9, 6, 1, 5, 8, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 7, 4, 5, 7, 8, 5, 2, 1, 2, 10, 3, 4, 6, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 1, 2, 3, 4, 5, 6, 8, 1, 9, 6, 1, 3, 4, 5, 6, 2, 5, 7, 9, 1, 2, 3, 4, 6, 7, 8, 9, 10, 2, 3, 10, 1, 6, 9, 7, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 4, 5, 7, 8, 3, 6, 5, 9, 2, 3, 4, 5, 8, 10, 9, 9, 5, 1, 2, 3, 4, 5, 7, 8, 10, 9, 1, 5, 6, 7, 9, 10, 2, 2, 6, 10, 5, 10, 3, 10, 5, 1, 4, 1, 4, 5, 7, 1, 3, 4, 5, 6, 7, 8, 9, 10, 5, 3, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 10, 10, 1, 2, 4, 5, 6, 9, 10, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 10, 9, 1, 5, 7, 10, 3, 6, 3, 4, 1, 2, 3, 4, 5, 6, 7, 9, 10, 1, 2, 6, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 9, 6, 1, 2, 3, 4, 5, 7, 8, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 8, 9, 2, 1, 2, 3, 4, 5, 6, 7, 8, 10, 5, 10, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 8, 9, 10, 10, 2, 4, 7, 8, 2, 4, 6, 7, 8, 2, 1, 3, 4, 5, 6, 7, 8, 9, 10, 7, 10, 1, 2, 3, 4, 5, 6, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 3, 4, 5, 6, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 4, 8, 7, 6, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 6, 7, 8, 9, 1, 2, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 6, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 3, 4, 5, 6, 8, 1, 3, 5, 7, 8, 9, 10, 1, 2, 3, 4, 5, 8, 9, 10, 3, 2, 7, 8, 9, 7, 2, 3, 4, 6, 8, 9, 1, 2, 4, 9, 3, 2, 10, 2, 5, 7, 2, 3, 4, 7, 9, 10, 4, 1, 5, 7, 10, 5, 4, 4, 9, 1, 2, 3, 4, 5, 6, 7, 9, 10, 1, 2, 3, 5, 6, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 4, 6, 9, 1, 2, 3, 8, 5, 7, 8, 3, 7, 2, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 4, 5, 6, 7, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 8, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 5, 7, 9, 1, 2, 6, 5, 2, 4, 8, 10, 2, 1, 2, 5, 6, 9, 10, 2, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 4, 6, 8, 5, 6, 8, 10, 1, 2, 3, 4, 5, 6, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 8, 1, 1, 2, 3, 4, 6, 7, 9, 10, 6, 2, 3, 4, 6, 7, 9, 10, 2, 4, 6, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 6, 10, 9, 2, 3, 4, 5, 6, 7, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 4, 6, 5, 10, 4, 5, 8, 6, 1, 2, 3, 4, 5, 6, 7, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 1, 2, 3, 4, 6, 7, 9, 10, 7, 10, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 8, 1, 2, 9, 1, 3, 4, 6, 7, 9, 10, 10, 3, 3, 3, 2, 3, 1, 2, 3, 5, 6, 7, 9, 10, 7, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 1, 3, 4, 5, 8, 9, 10, 1, 4, 1, 2, 3, 4, 6, 7, 8, 9, 2, 4, 5, 7, 10, 1, 2, 6, 8, 10, 1, 10, 3, 5, 6, 1, 4, 7, 8, 1, 2, 5, 6, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 3, 4, 5, 7, 1, 10, 9, 7, 2, 5, 7, 1, 2, 4, 7, 8, 9, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 3, 4, 6, 10, 3, 4, 6, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 4, 1, 2, 3, 4, 5, 6, 7, 9, 10, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 7, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 5, 1, 8, 1, 8, 1, 2, 3, 4, 5, 8, 2, 7, 10, 9, 3, 5, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 4, 1, 2, 3, 4, 5, 6, 7, 8, 10, 6, 2, 7, 8, 3, 4, 5, 8, 3, 5, 2, 3, 9, 10, 2, 3, 1, 2, 3, 4, 5, 6, 8, 9, 10, 7, 6, 5, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 8, 1, 2, 3, 4, 5, 6, 7, 10, 1, 5, 2, 3, 6, 7, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 4, 6, 9, 1, 5, 9, 6, 1, 4, 5, 6, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 1, 2, 3, 1, 4, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 3, 4, 7, 8, 3], \"Freq\": [0.6973022222518921, 0.0634961649775505, 0.1428663730621338, 0.03174808248877525, 0.03174808248877525, 0.23811061680316925, 0.19048850238323212, 0.03174808248877525, 0.015874041244387627, 0.1428663730621338, 0.126992329955101, 0.7524037957191467, 0.09559285640716553, 0.21030427515506744, 0.09559285640716553, 0.07647428661584854, 0.09559285640716553, 0.09559285640716553, 0.15294857323169708, 0.05735571309924126, 0.07647428661584854, 0.03823714330792427, 0.19800764322280884, 0.5940229296684265, 0.4071992337703705, 0.39580392837524414, 0.6279807686805725, 0.12559615075588226, 0.11613350361585617, 0.11613350361585617, 0.6968010067939758, 0.7958267331123352, 0.6128020286560059, 0.6128497123718262, 0.5576643347740173, 0.17695561051368713, 0.7078224420547485, 0.047944556921720505, 0.07191683351993561, 0.2636950612068176, 0.16780593991279602, 0.07191683351993561, 0.047944556921720505, 0.09588911384344101, 0.14383366703987122, 0.07191683351993561, 0.023972278460860252, 0.09023778885602951, 0.09023778885602951, 0.7219023108482361, 0.16005802154541016, 0.08002901077270508, 0.5602030754089355, 0.08002901077270508, 0.6166121363639832, 0.7399889826774597, 0.7892327904701233, 0.6172395944595337, 0.15430989861488342, 0.1372923105955124, 0.04576410353183746, 0.04576410353183746, 0.1372923105955124, 0.5491692423820496, 0.04576410353183746, 0.05592462047934532, 0.7270200848579407, 0.11184924095869064, 0.05592462047934532, 0.05009712278842926, 0.10019424557685852, 0.10019424557685852, 0.4007769823074341, 0.15029136836528778, 0.05009712278842926, 0.10019424557685852, 0.7476961612701416, 0.520334005355835, 0.10406679660081863, 0.10406679660081863, 0.10406679660081863, 0.10406679660081863, 0.7002533674240112, 0.1775810420513153, 0.059193678200244904, 0.11838735640048981, 0.08879052102565765, 0.029596839100122452, 0.029596839100122452, 0.029596839100122452, 0.14798419177532196, 0.26637154817581177, 0.059193678200244904, 0.5882501602172852, 0.5964930057525635, 0.6137118339538574, 0.7432572841644287, 0.18581432104110718, 0.1340665966272354, 0.6703329682350159, 0.1340665966272354, 0.21226899325847626, 0.10613449662923813, 0.053067248314619064, 0.053067248314619064, 0.053067248314619064, 0.053067248314619064, 0.1592017412185669, 0.3184034824371338, 0.7444056272506714, 0.7306077480316162, 0.1890573799610138, 0.0945286899805069, 0.14179302752017975, 0.04726434499025345, 0.04726434499025345, 0.14179302752017975, 0.0945286899805069, 0.23632171750068665, 0.5850578546524048, 0.5272939801216125, 0.17576465010643005, 0.17576465010643005, 0.18551671504974365, 0.556550145149231, 0.07226800173521042, 0.5058760046958923, 0.07226800173521042, 0.21680401265621185, 0.07226800173521042, 0.07226800173521042, 0.07226800173521042, 0.07226800173521042, 0.6114823818206787, 0.20123761892318726, 0.20123761892318726, 0.4024752378463745, 0.07596755027770996, 0.05697566270828247, 0.24689453840255737, 0.1899188756942749, 0.03798377513885498, 0.07596755027770996, 0.05697566270828247, 0.11395132541656494, 0.09495943784713745, 0.01899188756942749, 0.6152448654174805, 0.07231329381465912, 0.07231329381465912, 0.14462658762931824, 0.2892531752586365, 0.07231329381465912, 0.3615664541721344, 0.23888948559761047, 0.47777897119522095, 0.07480774074792862, 0.07480774074792862, 0.14961548149585724, 0.07480774074792862, 0.14961548149585724, 0.07480774074792862, 0.07480774074792862, 0.2992309629917145, 0.5955312848091125, 0.2445557564496994, 0.1222778782248497, 0.1222778782248497, 0.4891115128993988, 0.6128504276275635, 0.4070168733596802, 0.6154300570487976, 0.11185391992330551, 0.11185391992330551, 0.6711235046386719, 0.11185391992330551, 0.6143969893455505, 0.7790940999984741, 0.273784339427948, 0.410676509141922, 0.4113084077835083, 0.7472501993179321, 0.23756980895996094, 0.4751396179199219, 0.09240758419036865, 0.03696303442120552, 0.05544454976916313, 0.07392606884241104, 0.01848151721060276, 0.46203792095184326, 0.07392606884241104, 0.14785213768482208, 0.03696303442120552, 0.0743606761097908, 0.3718034029006958, 0.0371803380548954, 0.0743606761097908, 0.0371803380548954, 0.0743606761097908, 0.0371803380548954, 0.223082035779953, 0.0371803380548954, 0.08775926381349564, 0.61431485414505, 0.08775926381349564, 0.17551852762699127, 0.4463592767715454, 0.03188280761241913, 0.03188280761241913, 0.1275312304496765, 0.06376561522483826, 0.03188280761241913, 0.09564841538667679, 0.09564841538667679, 0.06376561522483826, 0.03188280761241913, 0.7051392197608948, 0.17422713339328766, 0.5226814150810242, 0.6639897227287292, 0.4105953872203827, 0.6620113849639893, 0.09457305818796158, 0.09457305818796158, 0.6298387050628662, 0.12596774101257324, 0.16598452627658844, 0.08299226313829422, 0.4979535639286041, 0.08299226313829422, 0.30967310070991516, 0.12386923283338547, 0.1858038604259491, 0.12386923283338547, 0.030967308208346367, 0.030967308208346367, 0.09290193021297455, 0.09290193021297455, 0.030967308208346367, 0.030967308208346367, 0.587257981300354, 0.10247285664081573, 0.03415761888027191, 0.03415761888027191, 0.13663047552108765, 0.13663047552108765, 0.06831523776054382, 0.2732609510421753, 0.10247285664081573, 0.06831523776054382, 0.03415761888027191, 0.02109207957983017, 0.0738222748041153, 0.18982870876789093, 0.30583515763282776, 0.052730198949575424, 0.052730198949575424, 0.1476445496082306, 0.08436831831932068, 0.052730198949575424, 0.02109207957983017, 0.7443615198135376, 0.5876124501228333, 0.5947727560997009, 0.36029720306396484, 0.09007430076599121, 0.36029720306396484, 0.7783395051956177, 0.665957510471344, 0.07399527728557587, 0.07399527728557587, 0.14799055457115173, 0.40844693779945374, 0.0453273206949234, 0.1359819620847702, 0.0453273206949234, 0.0453273206949234, 0.1359819620847702, 0.4986005127429962, 0.0453273206949234, 0.0453273206949234, 0.6079109311103821, 0.4071718454360962, 0.2427162081003189, 0.12135810405015945, 0.4854324162006378, 0.24115711450576782, 0.48231422901153564, 0.4549936056137085, 0.008584785275161266, 0.1631109118461609, 0.04292392358183861, 0.1631109118461609, 0.017169570550322533, 0.05150870978832245, 0.04292392358183861, 0.034339141100645065, 0.017169570550322533, 0.25505614280700684, 0.012752806767821312, 0.3060673773288727, 0.05101122707128525, 0.05101122707128525, 0.025505613535642624, 0.038258422166109085, 0.05101122707128525, 0.12752807140350342, 0.08926965296268463, 0.11001116037368774, 0.2200223207473755, 0.440044641494751, 0.5938768982887268, 0.0442914217710495, 0.23622091114521027, 0.014763806946575642, 0.14763806760311127, 0.014763806946575642, 0.29527613520622253, 0.029527613893151283, 0.16240186989307404, 0.07381903380155563, 0.39572298526763916, 0.13444170355796814, 0.5377668142318726, 0.13444170355796814, 0.2826622724533081, 0.09422075748443604, 0.4711037874221802, 0.06750710308551788, 0.30378198623657227, 0.20252132415771484, 0.10126066207885742, 0.06750710308551788, 0.03375355154275894, 0.03375355154275894, 0.03375355154275894, 0.06750710308551788, 0.10126066207885742, 0.39591872692108154, 0.0609976164996624, 0.0609976164996624, 0.1829928457736969, 0.4269833266735077, 0.1829928457736969, 0.0609976164996624, 0.059424690902233124, 0.059424690902233124, 0.7725209593772888, 0.059403084218502045, 0.059403084218502045, 0.059403084218502045, 0.17820926010608673, 0.11880616843700409, 0.47522467374801636, 0.059403084218502045, 0.059403084218502045, 0.11335723847150803, 0.09716334193944931, 0.09716334193944931, 0.11335723847150803, 0.09716334193944931, 0.14574502408504486, 0.048581670969724655, 0.08096945285797119, 0.14574502408504486, 0.06477556377649307, 0.14031198620796204, 0.07015599310398102, 0.14031198620796204, 0.07015599310398102, 0.3507799804210663, 0.07015599310398102, 0.7425442934036255, 0.12977980077266693, 0.12977980077266693, 0.12977980077266693, 0.5191192030906677, 0.18731331825256348, 0.5619399547576904, 0.7001024484634399, 0.10001463443040848, 0.12597787380218506, 0.031494468450546265, 0.2834502160549164, 0.06298893690109253, 0.06298893690109253, 0.031494468450546265, 0.031494468450546265, 0.15747234225273132, 0.12597787380218506, 0.09448341280221939, 0.24607715010643005, 0.1135740727186203, 0.09464506059885025, 0.0757160484790802, 0.09464506059885025, 0.0757160484790802, 0.0757160484790802, 0.05678703635931015, 0.1514320969581604, 0.05678703635931015, 0.1195392981171608, 0.0597696490585804, 0.1195392981171608, 0.0597696490585804, 0.1793089509010315, 0.0597696490585804, 0.2988482415676117, 0.0597696490585804, 0.5573359727859497, 0.5655167102813721, 0.09425278753042221, 0.18850557506084442, 0.09425278753042221, 0.23793476819992065, 0.713804304599762, 0.018503282219171524, 0.1665295511484146, 0.2220393866300583, 0.25904595851898193, 0.03700656443834305, 0.03700656443834305, 0.11101969331502914, 0.09251641482114792, 0.05550984665751457, 0.018503282219171524, 0.4225198030471802, 0.07041996717453003, 0.07041996717453003, 0.2112599015235901, 0.14083993434906006, 0.1426306515932083, 0.03169569745659828, 0.20602203905582428, 0.20602203905582428, 0.11093494296073914, 0.03169569745659828, 0.09508709609508514, 0.09508709609508514, 0.04754354804754257, 0.01584784872829914, 0.08229979872703552, 0.22632445394992828, 0.04114989936351776, 0.18517455458641052, 0.06172484904527664, 0.04114989936351776, 0.26747435331344604, 0.02057494968175888, 0.04114989936351776, 0.05133812129497528, 0.05133812129497528, 0.05133812129497528, 0.4620431065559387, 0.10267624258995056, 0.05133812129497528, 0.05133812129497528, 0.05133812129497528, 0.10267624258995056, 0.027988653630018234, 0.15860237181186676, 0.13061371445655823, 0.1679319143295288, 0.027988653630018234, 0.027988653630018234, 0.1865910142660141, 0.21457967162132263, 0.046647753566503525, 0.00932955089956522, 0.62051922082901, 0.6094938516616821, 0.6621865630149841, 0.1324373185634613, 0.07393400371074677, 0.07393400371074677, 0.5914720296859741, 0.07393400371074677, 0.14786800742149353, 0.07393400371074677, 0.27959883213043213, 0.09319960325956345, 0.5591976642608643, 0.8216912150382996, 0.2054228037595749, 0.7457491755485535, 0.4070420265197754, 0.23127861320972443, 0.046255722641944885, 0.09251144528388977, 0.3237900733947754, 0.3237900733947754, 0.046255722641944885, 0.1515081822872162, 0.1515081822872162, 0.6060327291488647, 0.816035807132721, 0.1649772673845291, 0.38494694232940674, 0.054992418736219406, 0.054992418736219406, 0.10998483747243881, 0.054992418736219406, 0.054992418736219406, 0.08445258438587189, 0.056301720440387726, 0.11260344088077545, 0.3659611940383911, 0.16890516877174377, 0.056301720440387726, 0.056301720440387726, 0.056301720440387726, 0.056301720440387726, 0.057758722454309464, 0.1732761710882187, 0.1732761710882187, 0.11551744490861893, 0.08663808554410934, 0.057758722454309464, 0.2887936234474182, 0.057758722454309464, 0.028879361227154732, 0.5939456224441528, 0.20665894448757172, 0.619976818561554, 0.746552050113678, 0.11126629263162613, 0.11126629263162613, 0.55633145570755, 0.11126629263162613, 0.06935252249240875, 0.34676262736320496, 0.05548201873898506, 0.16644605994224548, 0.04161151498556137, 0.05548201873898506, 0.09709353744983673, 0.11096403747797012, 0.04161151498556137, 0.013870504684746265, 0.6687641143798828, 0.7469216585159302, 0.1373451203107834, 0.5493804812431335, 0.1373451203107834, 0.1373451203107834, 0.5181450843811035, 0.25907254219055176, 0.2063063532114029, 0.6189190745353699, 0.10254371166229248, 0.6152622699737549, 0.10254371166229248, 0.6134200692176819, 0.038383372128009796, 0.26868361234664917, 0.42221710085868835, 0.038383372128009796, 0.07676674425601959, 0.038383372128009796, 0.038383372128009796, 0.038383372128009796, 0.038383372128009796, 0.038383372128009796, 0.07746315747499466, 0.12910525500774384, 0.10328420996665955, 0.07746315747499466, 0.12910525500774384, 0.12910525500774384, 0.12910525500774384, 0.1807473599910736, 0.025821052491664886, 0.025821052491664886, 0.6114963889122009, 0.30600109696388245, 0.10200036317110062, 0.40800145268440247, 0.664294958114624, 0.8228767514228821, 0.7758116722106934, 0.8125686049461365, 0.4074297249317169, 0.2528567612171173, 0.05057135596871376, 0.05057135596871376, 0.6068562269210815, 0.41142481565475464, 0.2655050754547119, 0.04827364906668663, 0.21723142266273499, 0.12068412452936172, 0.12068412452936172, 0.024136824533343315, 0.024136824533343315, 0.04827364906668663, 0.0724104791879654, 0.04827364906668663, 0.2617049217224121, 0.07851147651672363, 0.2617049217224121, 0.18319344520568848, 0.05234098061919212, 0.02617049030959606, 0.02617049030959606, 0.02617049030959606, 0.02617049030959606, 0.05234098061919212, 0.11113738268613815, 0.7779616713523865, 0.15271802246570587, 0.15271802246570587, 0.4581540822982788, 0.7413538694381714, 0.05167469382286072, 0.05167469382286072, 0.15502408146858215, 0.10334938764572144, 0.05167469382286072, 0.05167469382286072, 0.20669877529144287, 0.05167469382286072, 0.3100481629371643, 0.39572563767433167, 0.5593183040618896, 0.6763816475868225, 0.03274308145046234, 0.03274308145046234, 0.26194465160369873, 0.3274308145046234, 0.3274308145046234, 0.6705257296562195, 0.04317855462431908, 0.04317855462431908, 0.04317855462431908, 0.04317855462431908, 0.04317855462431908, 0.6908568739891052, 0.04317855462431908, 0.7518742680549622, 0.09865815192461014, 0.19731630384922028, 0.09865815192461014, 0.19731630384922028, 0.39463260769844055, 0.17456166446208954, 0.17456166446208954, 0.5236849784851074, 0.0567992702126503, 0.0567992702126503, 0.14199817180633545, 0.08519890904426575, 0.19879744946956635, 0.0567992702126503, 0.2271970808506012, 0.02839963510632515, 0.1135985404253006, 0.0567992702126503, 0.40710365772247314, 0.1574392020702362, 0.052479732781648636, 0.052479732781648636, 0.052479732781648636, 0.5247973203659058, 0.052479732781648636, 0.052479732781648636, 0.052479732781648636, 0.6081079244613647, 0.561229407787323, 0.07525232434272766, 0.3762616217136383, 0.03762616217136383, 0.11287848651409149, 0.07525232434272766, 0.07525232434272766, 0.03762616217136383, 0.15050464868545532, 0.03762616217136383, 0.5606935024261475, 0.6736037135124207, 0.16840092837810516, 0.7473350763320923, 0.08791490644216537, 0.21978725492954254, 0.04395745322108269, 0.021978726610541344, 0.15385107696056366, 0.19780853390693665, 0.021978726610541344, 0.021978726610541344, 0.15385107696056366, 0.06593617796897888, 0.15245702862739563, 0.15245702862739563, 0.6098281145095825, 0.08120006322860718, 0.04060003161430359, 0.08120006322860718, 0.08120006322860718, 0.08120006322860718, 0.04060003161430359, 0.4060003459453583, 0.04060003161430359, 0.08120006322860718, 0.07413019239902496, 0.2075645476579666, 0.05930415540933609, 0.08895623683929443, 0.13343435525894165, 0.07413019239902496, 0.1037822738289833, 0.07413019239902496, 0.08895623683929443, 0.08895623683929443, 0.2693844735622406, 0.06734611839056015, 0.1346922367811203, 0.15714094042778015, 0.06734611839056015, 0.06734611839056015, 0.022448705509305, 0.15714094042778015, 0.06734611839056015, 0.022448705509305, 0.6175917387008667, 0.39361873269081116, 0.16400781273841858, 0.09840468317270279, 0.13120624423027039, 0.06560312211513519, 0.032801561057567596, 0.06560312211513519, 0.032801561057567596, 0.032801561057567596, 0.7932456135749817, 0.739463210105896, 0.07498084753751755, 0.6748276352882385, 0.07498084753751755, 0.07498084753751755, 0.07498084753751755, 0.6928780674934387, 0.13857561349868774, 0.024436520412564278, 0.14661912620067596, 0.024436520412564278, 0.048873040825128555, 0.048873040825128555, 0.048873040825128555, 0.41542086005210876, 0.024436520412564278, 0.048873040825128555, 0.1710556447505951, 0.6079246997833252, 0.14937466382980347, 0.14937466382980347, 0.07468733191490173, 0.4481239914894104, 0.3627234101295471, 0.1318994164466858, 0.03297485411167145, 0.0659497082233429, 0.03297485411167145, 0.1318994164466858, 0.16487427055835724, 0.03297485411167145, 0.0916796624660492, 0.45839834213256836, 0.2750389873981476, 0.7967067360877991, 0.7019038200378418, 0.09500942379236221, 0.09500942379236221, 0.11401131004095078, 0.038003768771886826, 0.13301318883895874, 0.13301318883895874, 0.09500942379236221, 0.07600753754377365, 0.11401131004095078, 0.11401131004095078, 0.6218027472496033, 0.09385953843593597, 0.056315723806619644, 0.07508762925863266, 0.07508762925863266, 0.15017525851726532, 0.11263144761323929, 0.16894716024398804, 0.03754381462931633, 0.07508762925863266, 0.15017525851726532, 0.08760391175746918, 0.17520782351493835, 0.09556790441274643, 0.2707757353782654, 0.023891976103186607, 0.023891976103186607, 0.06371193379163742, 0.1513158529996872, 0.06371193379163742, 0.05574794486165047, 0.4097896218299866, 0.5604203343391418, 0.11208406090736389, 0.11208406090736389, 0.6651722192764282, 0.1754555106163025, 0.70182204246521, 0.6134538650512695, 0.2029794454574585, 0.6089383363723755, 0.8122243285179138, 0.40692585706710815, 0.5949100852012634, 0.5331626534461975, 0.35544177889823914, 0.021273093298077583, 0.08509237319231033, 0.1276385486125946, 0.1276385486125946, 0.08509237319231033, 0.10636546462774277, 0.2978232800960541, 0.08509237319231033, 0.04254618659615517, 0.04254618659615517, 0.39799362421035767, 0.05684223398566246, 0.22736893594264984, 0.05684223398566246, 0.11368446797132492, 0.3978956639766693, 0.05684223398566246, 0.07627248018980026, 0.07627248018980026, 0.07627248018980026, 0.20339329540729523, 0.07627248018980026, 0.025424161925911903, 0.25424161553382874, 0.05084832385182381, 0.10169664770364761, 0.05084832385182381, 0.1234586164355278, 0.17284205555915833, 0.04938344657421112, 0.09876689314842224, 0.04938344657421112, 0.04938344657421112, 0.14815033972263336, 0.22222550213336945, 0.02469172328710556, 0.02469172328710556, 0.05314340814948082, 0.10628681629896164, 0.42514726519584656, 0.21257363259792328, 0.10628681629896164, 0.5579684376716614, 0.6959993839263916, 0.04884761571884155, 0.14654284715652466, 0.11397776752710342, 0.2605206072330475, 0.0976952314376831, 0.06513015180826187, 0.032565075904130936, 0.11397776752710342, 0.06513015180826187, 0.032565075904130936, 0.8085597157478333, 0.6072303056716919, 0.023435482755303383, 0.23435483872890472, 0.046870965510606766, 0.0703064501285553, 0.046870965510606766, 0.023435482755303383, 0.0703064501285553, 0.4452741742134094, 0.023435482755303383, 0.023435482755303383, 0.046357035636901855, 0.13907110691070557, 0.046357035636901855, 0.09271407127380371, 0.046357035636901855, 0.37085628509521484, 0.13907110691070557, 0.09271407127380371, 0.046357035636901855, 0.8147323131561279, 0.12441417574882507, 0.6220709085464478, 0.7892272472381592, 0.6129288673400879, 0.5940638780593872, 0.8190799355506897, 0.837236762046814, 0.16744735836982727, 0.2639501690864563, 0.050937749445438385, 0.15744395554065704, 0.10650620609521866, 0.15281325578689575, 0.027784226462244987, 0.07872197777032852, 0.07872197777032852, 0.06019916012883186, 0.027784226462244987, 0.28822970390319824, 0.05764594301581383, 0.14987945556640625, 0.05764594301581383, 0.06917513161897659, 0.05764594301581383, 0.13835026323795319, 0.05764594301581383, 0.08070431649684906, 0.05764594301581383, 0.7131356596946716, 0.892102062702179, 0.19451594352722168, 0.09725797176361084, 0.17020145058631897, 0.09725797176361084, 0.04862898588180542, 0.04862898588180542, 0.04862898588180542, 0.19451594352722168, 0.04862898588180542, 0.07294347882270813, 0.6108084917068481, 0.736461341381073, 0.7466809749603271, 0.1120406985282898, 0.560203492641449, 0.1120406985282898, 0.1120406985282898, 0.27462145686149597, 0.09154048562049866, 0.15256747603416443, 0.09154048562049866, 0.06102699041366577, 0.06102699041366577, 0.06102699041366577, 0.12205398082733154, 0.030513495206832886, 0.09154048562049866, 0.23524652421474457, 0.11762326210737228, 0.5881163477897644, 0.715438723564148, 0.16577692329883575, 0.663107693195343, 0.1067882552742958, 0.17086121439933777, 0.12814590334892273, 0.08543060719966888, 0.04271530359983444, 0.04271530359983444, 0.1922188550233841, 0.1067882552742958, 0.04271530359983444, 0.06407295167446136, 0.6127611994743347, 0.7950987219810486, 0.23876339197158813, 0.47752678394317627, 0.7436361908912659, 0.6140517592430115, 0.40810245275497437, 0.5592058897018433, 0.6179825663566589, 0.39650341868400574, 0.6087477207183838, 0.10316731780767441, 0.12036187201738358, 0.051583658903837204, 0.12036187201738358, 0.12036187201738358, 0.10316731780767441, 0.12036187201738358, 0.06877821683883667, 0.13755643367767334, 0.08597276359796524, 0.6989045143127441, 0.11206886172294617, 0.5603442788124084, 0.11206886172294617, 0.11206886172294617, 0.7418464422225952, 0.7925747632980347, 0.6362033486366272, 0.12486425042152405, 0.7491855025291443, 0.5329605340957642, 0.177653506398201, 0.0888267531991005, 0.6104565262794495, 0.07819969952106476, 0.1303328275680542, 0.10426626354455948, 0.07819969952106476, 0.15639939904212952, 0.10426626354455948, 0.1303328275680542, 0.05213313177227974, 0.02606656588613987, 0.1303328275680542, 0.5653517246246338, 0.7531400322914124, 0.02896692417562008, 0.05793384835124016, 0.05793384835124016, 0.05793384835124016, 0.02896692417562008, 0.02896692417562008, 0.5583291053771973, 0.4072892665863037, 0.8132927417755127, 0.5693668723106384, 0.0711708590388298, 0.21351258456707, 0.0711708590388298, 0.0711708590388298, 0.12169347703456879, 0.12169347703456879, 0.12169347703456879, 0.48677390813827515, 0.11846792697906494, 0.5449524521827698, 0.023693585768342018, 0.047387171536684036, 0.0710807517170906, 0.023693585768342018, 0.023693585768342018, 0.09477434307336807, 0.023693585768342018, 0.7675533890724182, 0.06977757811546326, 0.06977757811546326, 0.20200055837631226, 0.20200055837631226, 0.4040011167526245, 0.7333215475082397, 0.612057626247406, 0.1297530084848404, 0.1427283138036728, 0.0648765042424202, 0.0648765042424202, 0.155703604221344, 0.11677771061658859, 0.1297530084848404, 0.0648765042424202, 0.0519012026488781, 0.0908271074295044, 0.17041607201099396, 0.0486903041601181, 0.07303545624017715, 0.07303545624017715, 0.0973806083202362, 0.02434515208005905, 0.0486903041601181, 0.07303545624017715, 0.2921418249607086, 0.0973806083202362, 0.1244094967842102, 0.14929139614105225, 0.09952759742736816, 0.09952759742736816, 0.07464569807052612, 0.19905519485473633, 0.04976379871368408, 0.02488189935684204, 0.07464569807052612, 0.09952759742736816, 0.1370203197002411, 0.05872299522161484, 0.21531765162944794, 0.1565946638584137, 0.09787166118621826, 0.039148665964603424, 0.039148665964603424, 0.1565946638584137, 0.05872299522161484, 0.039148665964603424, 0.608954906463623, 0.0475567951798439, 0.16644878685474396, 0.07133519649505615, 0.0475567951798439, 0.0951135903596878, 0.16644878685474396, 0.0951135903596878, 0.02377839758992195, 0.07133519649505615, 0.2377839833498001, 0.05786512419581413, 0.05786512419581413, 0.028932562097907066, 0.028932562097907066, 0.05786512419581413, 0.1735953688621521, 0.1591290980577469, 0.014466281048953533, 0.11573024839162827, 0.30379191040992737, 0.04507777839899063, 0.09015555679798126, 0.04507777839899063, 0.6761666536331177, 0.04507777839899063, 0.13549794256687164, 0.8129876852035522, 0.1537265181541443, 0.6149060726165771, 0.7916130423545837, 0.16270218789577484, 0.6101332306861877, 0.08135109394788742, 0.04067554697394371, 0.04067554697394371, 0.7329748868942261, 0.6117767691612244, 0.6179373860359192, 0.38636019825935364, 0.19318009912967682, 0.038636017590761185, 0.19318009912967682, 0.07727203518152237, 0.038636017590761185, 0.038636017590761185, 0.038636017590761185, 0.7327742576599121, 0.11071299016475677, 0.11071299016475677, 0.5535649657249451, 0.11071299016475677, 0.11071299016475677, 0.4097517430782318, 0.5934364199638367, 0.6371361613273621, 0.07079290598630905, 0.21237871050834656, 0.6151852011680603, 0.49217909574508667, 0.78111732006073, 0.11158818751573563, 0.7103793621063232, 0.7464664578437805, 0.719740629196167, 0.07201755046844482, 0.6481579542160034, 0.07201755046844482, 0.07201755046844482, 0.5521246194839478, 0.05258329585194588, 0.07887494564056396, 0.05258329585194588, 0.02629164792597294, 0.02629164792597294, 0.15774989128112793, 0.05258329585194588, 0.02629164792597294, 0.6185986399650574, 0.1485888659954071, 0.7429443001747131, 0.04873177409172058, 0.14619532227516174, 0.14619532227516174, 0.23147591948509216, 0.060914717614650726, 0.060914717614650726, 0.07309766113758087, 0.134012371301651, 0.07309766113758087, 0.02436588704586029, 0.06502781808376312, 0.06502781808376312, 0.2601112723350525, 0.13005563616752625, 0.03251390904188156, 0.03251390904188156, 0.19508345425128937, 0.09754172712564468, 0.13005563616752625, 0.4102881848812103, 0.10557656735181808, 0.10557656735181808, 0.10557656735181808, 0.15836484730243683, 0.10557656735181808, 0.31672969460487366, 0.05278828367590904, 0.6140291690826416, 0.1444154679775238, 0.09627698361873627, 0.19255396723747253, 0.09627698361873627, 0.09627698361873627, 0.0722077339887619, 0.0722077339887619, 0.024069245904684067, 0.16848471760749817, 0.048138491809368134, 0.6462268233299255, 0.16155670583248138, 0.7654276490211487, 0.11633577942848206, 0.11633577942848206, 0.6980146765708923, 0.6221136450767517, 0.08161415159702301, 0.8977556824684143, 0.8341085314750671, 0.7311038970947266, 0.06059662625193596, 0.03029831312596798, 0.15149156749248505, 0.2120881825685501, 0.33328142762184143, 0.06059662625193596, 0.03029831312596798, 0.06059662625193596, 0.03029831312596798, 0.634621262550354, 0.1586553156375885, 0.6115477085113525, 0.6194796562194824, 0.28618887066841125, 0.08417319506406784, 0.11784247308969498, 0.11784247308969498, 0.050503917038440704, 0.050503917038440704, 0.10100783407688141, 0.06733855605125427, 0.06733855605125427, 0.06733855605125427, 0.20305165648460388, 0.6091549396514893, 0.14064036309719086, 0.14064036309719086, 0.07032018154859543, 0.2812807261943817, 0.08790022879838943, 0.05274013429880142, 0.08790022879838943, 0.05274013429880142, 0.05274013429880142, 0.035160090774297714, 0.613261878490448, 0.8100863099098206, 0.06652195006608963, 0.13304390013217926, 0.1995658576488495, 0.06652195006608963, 0.399131715297699, 0.06652195006608963, 0.06652195006608963, 0.06652195006608963, 0.09119667857885361, 0.045598339289426804, 0.06839750707149506, 0.20519252121448517, 0.045598339289426804, 0.06839750707149506, 0.31918835639953613, 0.06839750707149506, 0.022799169644713402, 0.045598339289426804, 0.7028705477714539, 0.08785881847143173, 0.08785881847143173, 0.5909303426742554, 0.1469217836856842, 0.1469217836856842, 0.1469217836856842, 0.1259329617023468, 0.0209888257086277, 0.1679106056690216, 0.0209888257086277, 0.1469217836856842, 0.0209888257086277, 0.6189118027687073, 0.15472795069217682, 0.6184107661247253, 0.06186912953853607, 0.2474765181541443, 0.0824921727180481, 0.22685347497463226, 0.020623043179512024, 0.0824921727180481, 0.04124608635902405, 0.14436130225658417, 0.04124608635902405, 0.04124608635902405, 0.12773889303207397, 0.04257963225245476, 0.4257963299751282, 0.12773889303207397, 0.04257963225245476, 0.08515926450490952, 0.08515926450490952, 0.04257963225245476, 0.04257963225245476, 0.8253014087677002, 0.5967928171157837, 0.11935856938362122, 0.11935856938362122, 0.11935856938362122, 0.31337597966194153, 0.06267519295215607, 0.06267519295215607, 0.12535038590431213, 0.3760511577129364, 0.5948619246482849, 0.12337350845336914, 0.4626506567001343, 0.09253013134002686, 0.06168675422668457, 0.06168675422668457, 0.12337350845336914, 0.030843377113342285, 0.030843377113342285, 0.030843377113342285, 0.5838090181350708, 0.4094066619873047, 0.05243662744760513, 0.157309889793396, 0.05243662744760513, 0.10487325489521027, 0.05243662744760513, 0.10487325489521027, 0.314619779586792, 0.157309889793396, 0.34489351511001587, 0.024635251611471176, 0.14781150221824646, 0.12317625433206558, 0.07390575110912323, 0.04927050322294235, 0.024635251611471176, 0.04927050322294235, 0.12317625433206558, 0.07390575110912323, 0.030717236921191216, 0.12286894768476486, 0.07679308950901031, 0.12286894768476486, 0.030717236921191216, 0.04607585445046425, 0.3378896117210388, 0.23037926852703094, 0.015358618460595608, 0.015358618460595608, 0.5197008848190308, 0.051970090717077255, 0.051970090717077255, 0.10394018143415451, 0.10394018143415451, 0.051970090717077255, 0.10394018143415451, 0.1065068319439888, 0.09585614502429962, 0.09585614502429962, 0.08520546555519104, 0.11715751141309738, 0.09585614502429962, 0.12780819833278656, 0.07455477863550186, 0.14910955727100372, 0.0532534159719944, 0.4069913625717163, 0.1878267079591751, 0.22539204359054565, 0.056348010897636414, 0.07513067871332169, 0.07513067871332169, 0.09391335397958755, 0.03756533935666084, 0.07513067871332169, 0.056348010897636414, 0.11269602179527283, 0.13309146463871002, 0.13309146463871002, 0.6654573082923889, 0.7839931845664978, 0.6106888055801392, 0.07882621139287949, 0.394131064414978, 0.4729572832584381, 0.05316772311925888, 0.10633544623851776, 0.0886128693819046, 0.05316772311925888, 0.12405801564455032, 0.12405801564455032, 0.12405801564455032, 0.01772257313132286, 0.1772257387638092, 0.12405801564455032, 0.14744992554187775, 0.07372496277093887, 0.5160747170448303, 0.07372496277093887, 0.07372496277093887, 0.11878573894500732, 0.23757147789001465, 0.5939286947250366, 0.1280999332666397, 0.2561998665332794, 0.1537199318408966, 0.0768599659204483, 0.025619987398386, 0.051239974796772, 0.051239974796772, 0.051239974796772, 0.1280999332666397, 0.0768599659204483, 0.14068560302257538, 0.2344760000705719, 0.18758080899715424, 0.10942213237285614, 0.04689520224928856, 0.156317338347435, 0.01563173346221447, 0.06252693384885788, 0.01563173346221447, 0.04689520224928856, 0.44931477308273315, 0.33698609471321106, 0.19781750440597534, 0.0791269987821579, 0.11869050562381744, 0.19781750440597534, 0.11869050562381744, 0.03956349939107895, 0.019781749695539474, 0.03956349939107895, 0.1582539975643158, 0.03956349939107895, 0.2628849446773529, 0.06572123616933823, 0.06572123616933823, 0.13144247233867645, 0.06572123616933823, 0.06572123616933823, 0.32860618829727173, 0.11597968637943268, 0.07731979340314865, 0.11597968637943268, 0.07731979340314865, 0.11597968637943268, 0.07731979340314865, 0.07731979340314865, 0.038659896701574326, 0.11597968637943268, 0.19329948723316193, 0.09540536999702454, 0.14992272853851318, 0.04088801518082619, 0.04088801518082619, 0.1771814078092575, 0.2180694192647934, 0.027258677408099174, 0.027258677408099174, 0.08177603036165237, 0.13629338145256042, 0.6697447299957275, 0.43122121691703796, 0.025365954264998436, 0.15219572186470032, 0.07609786093235016, 0.15219572186470032, 0.025365954264998436, 0.025365954264998436, 0.05073190852999687, 0.05073190852999687, 0.025365954264998436, 0.11218777298927307, 0.11218777298927307, 0.7853143811225891, 0.11218777298927307, 0.4840500056743622, 0.597008466720581, 0.09283135831356049, 0.13924704492092133, 0.09283135831356049, 0.37132543325424194, 0.13924704492092133, 0.04641567915678024, 0.04641567915678024, 0.05688919126987457, 0.2275567650794983, 0.05688919126987457, 0.11377838253974915, 0.05688919126987457, 0.34133514761924744, 0.11377838253974915, 0.05688919126987457, 0.7478501200675964, 0.1704377830028534, 0.1704377830028534, 0.5113133192062378, 0.40724804997444153, 0.5813093781471252, 0.058000676333904266, 0.40600472688674927, 0.11600135266780853, 0.058000676333904266, 0.1740020215511322, 0.058000676333904266, 0.11114755272865295, 0.11114755272865295, 0.6668853163719177, 0.11114755272865295, 0.7977075576782227, 0.17794618010520935, 0.7117847204208374, 0.7485034465789795, 0.14970068633556366, 0.5825473070144653, 0.47786945104599, 0.26065605878829956, 0.043442677706480026, 0.043442677706480026, 0.08688535541296005, 0.08688535541296005, 0.6108091473579407, 0.06898253411054611, 0.6898252964019775, 0.06898253411054611, 0.06898253411054611, 0.6182918548583984, 0.6818321943283081, 0.17544510960578918, 0.5263352990150452, 0.051806408911943436, 0.2590320408344269, 0.025903204455971718, 0.025903204455971718, 0.10361281782388687, 0.18132242560386658, 0.051806408911943436, 0.10361281782388687, 0.18132242560386658, 0.4203612804412842, 0.05254516005516052, 0.05254516005516052, 0.2101806402206421, 0.15763548016548157, 0.05254516005516052, 0.05254516005516052, 0.11952797323465347, 0.08964598178863525, 0.11952797323465347, 0.08964598178863525, 0.23905594646930695, 0.059763986617326736, 0.11952797323465347, 0.029881993308663368, 0.08964598178863525, 0.059763986617326736, 0.1525457352399826, 0.6101829409599304, 0.8078547716140747, 0.6121262907981873, 0.6422874331474304, 0.11677952855825424, 0.11677952855825424, 0.05838976427912712, 0.07803352177143097, 0.7803352475166321, 0.5964006781578064, 0.7473474740982056, 0.7757344841957092, 0.17569886147975922, 0.7027954459190369, 0.17544834315776825, 0.07797703891992569, 0.19494260847568512, 0.15595407783985138, 0.038988519459962845, 0.019494259729981422, 0.07797703891992569, 0.09747130423784256, 0.09747130423784256, 0.058482781052589417, 0.15037348866462708, 0.15037348866462708, 0.4511204659938812, 0.05012449622154236, 0.05012449622154236, 0.05012449622154236, 0.05012449622154236, 0.06171185523271561, 0.07713981717824936, 0.10799574851989746, 0.015427963808178902, 0.015427963808178902, 0.5399787425994873, 0.030855927616357803, 0.09256777912378311, 0.030855927616357803, 0.030855927616357803, 0.594042956829071, 0.8517584204673767, 0.7379767894744873, 0.1631193906068802, 0.03262387961149216, 0.03262387961149216, 0.13049551844596863, 0.26099103689193726, 0.13049551844596863, 0.09787163138389587, 0.03262387961149216, 0.06524775922298431, 0.06524775922298431, 0.14806205034255981, 0.5922482013702393, 0.4070150852203369, 0.09833484143018723, 0.68834388256073, 0.09833484143018723, 0.7403491735458374, 0.15017959475517273, 0.15017959475517273, 0.6007183790206909, 0.4098947048187256, 0.7941176891326904, 0.20896194875240326, 0.052240487188100815, 0.052240487188100815, 0.26120245456695557, 0.4179238975048065, 0.7428393959999084, 0.2452016919851303, 0.4904033839702606, 0.08604230731725693, 0.22432459890842438, 0.17823049426078796, 0.06453173607587814, 0.1014070063829422, 0.06453173607587814, 0.08604230731725693, 0.08911524713039398, 0.04916703328490257, 0.06145879253745079, 0.5651018023490906, 0.09418363869190216, 0.18836727738380432, 0.09418363869190216, 0.12306465953588486, 0.12306465953588486, 0.12306465953588486, 0.49225863814353943, 0.12020748108625412, 0.12020748108625412, 0.12020748108625412, 0.12020748108625412, 0.06010374054312706, 0.06010374054312706, 0.4207261800765991, 0.10518302768468857, 0.3681406080722809, 0.01753050461411476, 0.1753050535917282, 0.01753050461411476, 0.052591513842344284, 0.01753050461411476, 0.21036605536937714, 0.03506100922822952, 0.01753050461411476, 0.7941551804542542, 0.6600915789604187, 0.042205993086099625, 0.08441198617219925, 0.042205993086099625, 0.08441198617219925, 0.25323596596717834, 0.042205993086099625, 0.25323596596717834, 0.1688239723443985, 0.813209593296051, 0.23635342717170715, 0.2836241126060486, 0.04727068543434143, 0.04727068543434143, 0.04727068543434143, 0.2836241126060486, 0.04727068543434143, 0.07209564000368118, 0.28838256001472473, 0.5046694874763489, 0.07209564000368118, 0.24169859290122986, 0.06905674189329147, 0.31075534224510193, 0.06905674189329147, 0.03452837094664574, 0.03452837094664574, 0.10358510911464691, 0.03452837094664574, 0.03452837094664574, 0.03452837094664574, 0.5958671569824219, 0.2065698504447937, 0.6197095513343811, 0.4922787547111511, 0.08025862276554108, 0.12038793414831161, 0.36116379499435425, 0.04012931138277054, 0.04012931138277054, 0.2006465494632721, 0.12038793414831161, 0.04012931138277054, 0.05049305409193039, 0.11360936611890793, 0.03786978870630264, 0.03786978870630264, 0.13885588943958282, 0.27771177887916565, 0.025246527045965195, 0.012623263522982597, 0.11360936611890793, 0.20197221636772156, 0.5634480714797974, 0.16098517179489136, 0.08049258589744568, 0.08049258589744568, 0.6177128553390503, 0.8254984021186829, 0.123995341360569, 0.6199766993522644, 0.6824631690979004, 0.6127287149429321, 0.028596172109246254, 0.05719234421849251, 0.05719234421849251, 0.028596172109246254, 0.31455790996551514, 0.31455790996551514, 0.05719234421849251, 0.05719234421849251, 0.11438468843698502, 0.08648167550563812, 0.11530889570713043, 0.057654447853565216, 0.028827223926782608, 0.20179057121276855, 0.17296335101127625, 0.11530889570713043, 0.028827223926782608, 0.08648167550563812, 0.11530889570713043, 0.8947553634643555, 0.07132310420274734, 0.07132310420274734, 0.07132310420274734, 0.07132310420274734, 0.07132310420274734, 0.07132310420274734, 0.1426462084054947, 0.35661551356315613, 0.7834324836730957, 0.19585812091827393, 0.7311475276947021, 0.039251070469617844, 0.039251070469617844, 0.37288516759872437, 0.19625535607337952, 0.058876603841781616, 0.11775320768356323, 0.019625535234808922, 0.039251070469617844, 0.09812767803668976, 0.039251070469617844, 0.7167566418647766, 0.09908881038427353, 0.6936216354370117, 0.09908881038427353, 0.0936373770236969, 0.04681868851184845, 0.04681868851184845, 0.14045606553554535, 0.6086429357528687, 0.04681868851184845, 0.6169933676719666, 0.7472772598266602, 0.799440860748291, 0.5636190176010132, 0.7456977367401123, 0.789573073387146, 0.13159550726413727, 0.04202660918235779, 0.12607982754707336, 0.04202660918235779, 0.16810643672943115, 0.12607982754707336, 0.12607982754707336, 0.08405321836471558, 0.25215965509414673, 0.5876725316047668, 0.8209476470947266, 0.35726872086524963, 0.032478973269462585, 0.06495794653892517, 0.12991589307785034, 0.06495794653892517, 0.032478973269462585, 0.032478973269462585, 0.06495794653892517, 0.09743691980838776, 0.09743691980838776, 0.08373153209686279, 0.23026171326637268, 0.0627986490726471, 0.0627986490726471, 0.1255972981452942, 0.041865766048431396, 0.10466441512107849, 0.1465301811695099, 0.041865766048431396, 0.08373153209686279, 0.13209207355976105, 0.0825575441122055, 0.07430179417133331, 0.37150895595550537, 0.06604603677988052, 0.03302301838994026, 0.0825575441122055, 0.0825575441122055, 0.024767262861132622, 0.049534525722265244, 0.7295951843261719, 0.42083701491355896, 0.18035872280597687, 0.12023914605379105, 0.06011957302689552, 0.06011957302689552, 0.06011957302689552, 0.06011957302689552, 0.15074482560157776, 0.602979302406311, 0.06037380173802376, 0.24149520695209503, 0.02012460120022297, 0.2213706076145172, 0.2213706076145172, 0.04024920240044594, 0.16099680960178375, 0.02012460120022297, 0.15257340669631958, 0.07628670334815979, 0.38143351674079895, 0.15257340669631958, 0.07628670334815979, 0.07939953356981277, 0.15879906713962555, 0.15879906713962555, 0.47639718651771545, 0.07939953356981277, 0.5616796016693115, 0.4095061123371124, 0.8839295506477356, 0.5525664687156677, 0.27628323435783386, 0.10624699294567108, 0.10624699294567108, 0.6374819278717041, 0.10624699294567108, 0.07479362189769745, 0.037396810948848724, 0.5609521865844727, 0.18698406219482422, 0.037396810948848724, 0.037396810948848724, 0.037396810948848724, 0.1168016791343689, 0.10011572390794754, 0.06674381345510483, 0.16685953736305237, 0.08342976868152618, 0.16685953736305237, 0.06674381345510483, 0.08342976868152618, 0.10011572390794754, 0.05005786195397377, 0.710777223110199, 0.14955653250217438, 0.4486696124076843, 0.07477826625108719, 0.22433480620384216, 0.12384092807769775, 0.7430455684661865, 0.40695708990097046, 0.5876302123069763, 0.21986772119998932, 0.07328923791646957, 0.6596031785011292, 0.07050036638975143, 0.5287527441978455, 0.24675127863883972, 0.03525018319487572, 0.03525018319487572, 0.07050036638975143, 0.7954232692718506, 0.09432443976402283, 0.07074332982301712, 0.11790554970502853, 0.11790554970502853, 0.14148665964603424, 0.11790554970502853, 0.07074332982301712, 0.023581109941005707, 0.09432443976402283, 0.14148665964603424, 0.7939868569374084, 0.5070573091506958, 0.1448735147714615, 0.1448735147714615, 0.07243675738573074, 0.28397423028945923, 0.17038454115390778, 0.3975639343261719, 0.056794848293066025, 0.056794848293066025, 0.028654340654611588, 0.15282315015792847, 0.07641157507896423, 0.057308681309223175, 0.028654340654611588, 0.00955144688487053, 0.2292347252368927, 0.2960948348045349, 0.10506591200828552, 0.00955144688487053, 0.6233540177345276, 0.20778466761112213, 0.045189082622528076, 0.045189082622528076, 0.09037816524505615, 0.13556724786758423, 0.045189082622528076, 0.09037816524505615, 0.045189082622528076, 0.1807563304901123, 0.31632357835769653, 0.7459191083908081, 0.15267741680145264, 0.18321289122104645, 0.09160644561052322, 0.061070963740348816, 0.061070963740348816, 0.09160644561052322, 0.061070963740348816, 0.030535481870174408, 0.061070963740348816, 0.18321289122104645, 0.795535683631897, 0.5856001973152161, 0.6767381429672241, 0.09229083359241486, 0.09229083359241486, 0.12305445224046707, 0.08459993451833725, 0.10767263919115067, 0.1538180559873581, 0.09998174011707306, 0.08459993451833725, 0.10767263919115067, 0.05383631959557533, 0.5575450658798218, 0.0912054032087326, 0.02280135080218315, 0.0456027016043663, 0.1368080973625183, 0.06840404868125916, 0.0912054032087326, 0.3648216128349304, 0.0456027016043663, 0.0456027016043663, 0.06840404868125916, 0.6181146502494812, 0.5566845536231995, 0.5947042107582092, 0.7891809940338135, 0.1578361988067627, 0.17239315807819366, 0.17239315807819366, 0.17239315807819366, 0.08619657903909683, 0.043098289519548416, 0.301688015460968, 0.678643524646759, 0.16966088116168976, 0.4115157723426819, 0.4073454737663269, 0.08302512764930725, 0.08302512764930725, 0.5811759233474731, 0.08302512764930725, 0.08302512764930725, 0.6164519786834717, 0.02724860981106758, 0.1362430453300476, 0.02724860981106758, 0.02724860981106758, 0.10899443924427032, 0.2997347116470337, 0.05449721962213516, 0.02724860981106758, 0.10899443924427032, 0.19074027240276337, 0.6668922901153564, 0.4082152247428894, 0.031253352761268616, 0.06250670552253723, 0.2187734693288803, 0.1875201165676117, 0.09376005828380585, 0.06250670552253723, 0.09376005828380585, 0.2187734693288803, 0.031253352761268616, 0.7641992568969727, 0.16964125633239746, 0.16964125633239746, 0.5089237689971924, 0.49136513471603394, 0.08189418911933899, 0.08189418911933899, 0.24568256735801697, 0.6802911162376404, 0.6154512763023376, 0.7219481468200684, 0.13126330077648163, 0.06563165038824081, 0.06563165038824081, 0.6710566878318787, 0.16776417195796967, 0.01807580329477787, 0.14460642635822296, 0.03615160658955574, 0.01807580329477787, 0.16268222033977509, 0.1807580292224884, 0.05422740802168846, 0.07230321317911148, 0.2711370289325714, 0.7056025266647339, 0.610284686088562, 0.688010573387146, 0.13760212063789368, 0.3970862329006195, 0.08248993009328842, 0.027496643364429474, 0.1099865734577179, 0.05499328672885895, 0.2199731469154358, 0.2199731469154358, 0.027496643364429474, 0.05499328672885895, 0.08248993009328842, 0.1099865734577179, 0.7167993187904358, 0.06332531571388245, 0.06332531571388245, 0.1266506314277649, 0.06332531571388245, 0.1266506314277649, 0.3799518942832947, 0.18997594714164734, 0.06332531571388245, 0.1525869220495224, 0.6103476881980896, 0.09294203668832779, 0.09294203668832779, 0.5576522350311279, 0.09294203668832779, 0.09294203668832779, 0.06263388693332672, 0.04175592586398125, 0.1461457461118698, 0.10438981652259827, 0.12526777386665344, 0.10438981652259827, 0.2296575903892517, 0.0835118517279625, 0.020877962931990623, 0.0835118517279625, 0.08772283792495728, 0.2631685137748718, 0.08772283792495728, 0.4386141896247864, 0.5166110396385193, 0.10332220792770386, 0.20664441585540771, 0.6077150106430054, 0.068289615213871, 0.068289615213871, 0.136579230427742, 0.546316921710968, 0.068289615213871, 0.136579230427742, 0.08872009813785553, 0.08872009813785553, 0.15969617664813995, 0.12420813739299774, 0.08872009813785553, 0.08872009813785553, 0.08872009813785553, 0.10646411776542664, 0.15969617664813995, 0.017744019627571106, 0.22794783115386963, 0.045589566230773926, 0.045589566230773926, 0.3647165298461914, 0.045589566230773926, 0.045589566230773926, 0.045589566230773926, 0.13676869869232178, 0.24571780860424042, 0.07371534407138824, 0.07371534407138824, 0.04914356395602226, 0.1474306881427765, 0.09828712791204453, 0.07371534407138824, 0.07371534407138824, 0.09828712791204453, 0.04914356395602226, 0.10361916571855545, 0.17269860208034515, 0.0690794438123703, 0.03453972190618515, 0.18996846675872803, 0.17269860208034515, 0.017269860953092575, 0.017269860953092575, 0.0690794438123703, 0.17269860208034515, 0.7486310005187988, 0.1971541792154312, 0.5914624929428101, 0.840274453163147, 0.1024927943944931, 0.7174495458602905, 0.1024927943944931, 0.06168770417571068, 0.13365669548511505, 0.12337540835142136, 0.09253155440092087, 0.14393797516822815, 0.13365669548511505, 0.05140642076730728, 0.05140642076730728, 0.13365669548511505, 0.07196898758411407, 0.5937739014625549, 0.7501537799835205, 0.08378884196281433, 0.7540996074676514, 0.08378884196281433, 0.8346447348594666], \"Term\": [\"actigraph\", \"actor\", \"actor\", \"actor\", \"actor\", \"actor\", \"actor\", \"actor\", \"actor\", \"actor\", \"actor\", \"adani\", \"add\", \"add\", \"add\", \"add\", \"add\", \"add\", \"add\", \"add\", \"add\", \"add\", \"administ\", \"administ\", \"admir\", \"admiss\", \"advantag\", \"advantag\", \"aerob\", \"aerob\", \"aerob\", \"affidavit\", \"agneepath\", \"ahsec\", \"aircraft\", \"airport\", \"airport\", \"allow\", \"allow\", \"allow\", \"allow\", \"allow\", \"allow\", \"allow\", \"allow\", \"allow\", \"allow\", \"alphabet\", \"alphabet\", \"alphabet\", \"alter\", \"alter\", \"alter\", \"alter\", \"alumni\", \"amazon\", \"amrish\", \"anaita\", \"anaita\", \"antigen\", \"antigen\", \"antigen\", \"antigen\", \"antigen\", \"antigen\", \"app\", \"app\", \"app\", \"app\", \"appear\", \"appear\", \"appear\", \"appear\", \"appear\", \"appear\", \"appear\", \"appointe\", \"approv\", \"approv\", \"approv\", \"approv\", \"approv\", \"apurva\", \"area\", \"area\", \"area\", \"area\", \"area\", \"area\", \"area\", \"area\", \"area\", \"area\", \"ari\", \"arsenicum\", \"articl\", \"aspen\", \"aspen\", \"assam\", \"assam\", \"assam\", \"assess\", \"assess\", \"assess\", \"assess\", \"assess\", \"assess\", \"assess\", \"assess\", \"athlet\", \"atl\\u00e9tico\", \"attack\", \"attack\", \"attack\", \"attack\", \"attack\", \"attack\", \"attack\", \"attack\", \"attari\", \"babu\", \"babu\", \"babu\", \"ballot\", \"ballot\", \"ban\", \"ban\", \"ban\", \"ban\", \"ban\", \"ban\", \"ban\", \"ban\", \"banerje\", \"barcelona\", \"barcelona\", \"barcelona\", \"base\", \"base\", \"base\", \"base\", \"base\", \"base\", \"base\", \"base\", \"base\", \"base\", \"batra\", \"beauti\", \"beauti\", \"beauti\", \"beauti\", \"beauti\", \"beauti\", \"bed\", \"bed\", \"believ\", \"believ\", \"believ\", \"believ\", \"believ\", \"believ\", \"believ\", \"believ\", \"benchmark\", \"bengal\", \"bengal\", \"bengal\", \"bengal\", \"bengaluru\", \"betti\", \"bezo\", \"bharati\", \"bharati\", \"bharati\", \"bharati\", \"bhattacharya\", \"biden\", \"bihar\", \"bihar\", \"bite\", \"bitter\", \"blood\", \"blood\", \"board\", \"board\", \"board\", \"board\", \"board\", \"board\", \"board\", \"board\", \"board\", \"bodi\", \"bodi\", \"bodi\", \"bodi\", \"bodi\", \"bodi\", \"bodi\", \"bodi\", \"bodi\", \"bombay\", \"bombay\", \"bombay\", \"bombay\", \"border\", \"border\", \"border\", \"border\", \"border\", \"border\", \"border\", \"border\", \"border\", \"border\", \"breakfast\", \"broadcast\", \"broadcast\", \"bypass\", \"calm\", \"canada\", \"canada\", \"canada\", \"canadian\", \"canadian\", \"capac\", \"capac\", \"capac\", \"capac\", \"capit\", \"capit\", \"capit\", \"capit\", \"capit\", \"capit\", \"capit\", \"capit\", \"capit\", \"capit\", \"capricorn\", \"care\", \"care\", \"care\", \"care\", \"care\", \"care\", \"care\", \"care\", \"care\", \"care\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"cash\", \"cbdt\", \"cbse\", \"celina\", \"celina\", \"celina\", \"celsius\", \"cent\", \"cent\", \"cent\", \"cent\", \"chairmanship\", \"check\", \"check\", \"check\", \"check\", \"check\", \"check\", \"check\", \"check\", \"chest\", \"chhath\", \"child\", \"child\", \"child\", \"chin\", \"chin\", \"china\", \"china\", \"china\", \"china\", \"china\", \"china\", \"china\", \"china\", \"china\", \"china\", \"chines\", \"chines\", \"chines\", \"chines\", \"chines\", \"chines\", \"chines\", \"chines\", \"chines\", \"chines\", \"choreograph\", \"choreograph\", \"choreograph\", \"circular\", \"class\", \"class\", \"class\", \"class\", \"class\", \"class\", \"class\", \"class\", \"class\", \"claus\", \"click\", \"click\", \"click\", \"clip\", \"clip\", \"clip\", \"close\", \"close\", \"close\", \"close\", \"close\", \"close\", \"close\", \"close\", \"close\", \"close\", \"cmpdil\", \"coach\", \"coach\", \"coach\", \"coach\", \"coach\", \"coach\", \"coal\", \"coal\", \"coal\", \"colour\", \"colour\", \"colour\", \"colour\", \"colour\", \"colour\", \"colour\", \"colour\", \"come\", \"come\", \"come\", \"come\", \"come\", \"come\", \"come\", \"come\", \"come\", \"come\", \"command\", \"command\", \"command\", \"command\", \"command\", \"command\", \"commend\", \"commerci\", \"commerci\", \"commerci\", \"commerci\", \"commission\", \"commission\", \"communist\", \"communist\", \"compani\", \"compani\", \"compani\", \"compani\", \"compani\", \"compani\", \"compani\", \"compani\", \"compani\", \"compani\", \"continu\", \"continu\", \"continu\", \"continu\", \"continu\", \"continu\", \"continu\", \"continu\", \"continu\", \"continu\", \"contract\", \"contract\", \"contract\", \"contract\", \"contract\", \"contract\", \"contract\", \"contract\", \"contractor\", \"contribut\", \"contribut\", \"contribut\", \"contribut\", \"convalesc\", \"convalesc\", \"coronavirus\", \"coronavirus\", \"coronavirus\", \"coronavirus\", \"coronavirus\", \"coronavirus\", \"coronavirus\", \"coronavirus\", \"coronavirus\", \"coronavirus\", \"council\", \"council\", \"council\", \"council\", \"council\", \"countri\", \"countri\", \"countri\", \"countri\", \"countri\", \"countri\", \"countri\", \"countri\", \"countri\", \"countri\", \"court\", \"court\", \"court\", \"court\", \"court\", \"court\", \"court\", \"court\", \"court\", \"cover\", \"cover\", \"cover\", \"cover\", \"cover\", \"cover\", \"cover\", \"cover\", \"cover\", \"covid\", \"covid\", \"covid\", \"covid\", \"covid\", \"covid\", \"covid\", \"covid\", \"covid\", \"covid\", \"crash\", \"credenti\", \"crematorium\", \"crematorium\", \"cricket\", \"cricket\", \"cricket\", \"cricket\", \"cricket\", \"cricket\", \"crimin\", \"crimin\", \"crimin\", \"crpf\", \"crpf\", \"cupp\", \"cylind\", \"danc\", \"danc\", \"danc\", \"danc\", \"danc\", \"danc\", \"dancer\", \"dancer\", \"dancer\", \"dass\", \"data\", \"data\", \"data\", \"data\", \"data\", \"data\", \"data\", \"death\", \"death\", \"death\", \"death\", \"death\", \"death\", \"death\", \"death\", \"death\", \"decis\", \"decis\", \"decis\", \"decis\", \"decis\", \"decis\", \"decis\", \"decis\", \"decis\", \"deduct\", \"deepika\", \"deepika\", \"defens\", \"degre\", \"degre\", \"degre\", \"degre\", \"delhi\", \"delhi\", \"delhi\", \"delhi\", \"delhi\", \"delhi\", \"delhi\", \"delhi\", \"delhi\", \"delhi\", \"delist\", \"deploy\", \"depress\", \"depress\", \"depress\", \"depress\", \"deputi\", \"deputi\", \"desai\", \"desai\", \"devot\", \"devot\", \"devot\", \"dharavi\", \"digit\", \"digit\", \"digit\", \"digit\", \"digit\", \"digit\", \"digit\", \"digit\", \"digit\", \"digit\", \"direct\", \"direct\", \"direct\", \"direct\", \"direct\", \"direct\", \"direct\", \"direct\", \"direct\", \"direct\", \"distress\", \"doggo\", \"doggo\", \"doggo\", \"donnel\", \"dope\", \"dose\", \"download\", \"dua\", \"dubey\", \"dubey\", \"dubey\", \"dubey\", \"dust\", \"econom\", \"econom\", \"econom\", \"econom\", \"econom\", \"econom\", \"econom\", \"econom\", \"econom\", \"econom\", \"economi\", \"economi\", \"economi\", \"economi\", \"economi\", \"economi\", \"economi\", \"economi\", \"economi\", \"economi\", \"editori\", \"editori\", \"ekta\", \"ekta\", \"ekta\", \"ektarkapoor\", \"elect\", \"elect\", \"elect\", \"elect\", \"elect\", \"elect\", \"elect\", \"elect\", \"elect\", \"entranc\", \"escal\", \"euro\", \"exam\", \"exam\", \"exam\", \"exam\", \"exam\", \"exempt\", \"exercis\", \"exercis\", \"exercis\", \"exercis\", \"exercis\", \"exercis\", \"exercis\", \"explanatori\", \"export\", \"export\", \"export\", \"export\", \"export\", \"exposur\", \"exposur\", \"exposur\", \"famili\", \"famili\", \"famili\", \"famili\", \"famili\", \"famili\", \"famili\", \"famili\", \"famili\", \"famili\", \"farmer\", \"fashion\", \"fashion\", \"fashion\", \"fashion\", \"fashion\", \"fashion\", \"fashion\", \"fashion\", \"fastresult\", \"fcra\", \"feel\", \"feel\", \"feel\", \"feel\", \"feel\", \"feel\", \"feel\", \"feel\", \"feel\", \"felin\", \"ferrari\", \"ferrari\", \"fighter\", \"film\", \"film\", \"film\", \"film\", \"film\", \"film\", \"film\", \"film\", \"film\", \"film\", \"fire\", \"fire\", \"fire\", \"focus\", \"focus\", \"focus\", \"focus\", \"focus\", \"focus\", \"focus\", \"focus\", \"focus\", \"follow\", \"follow\", \"follow\", \"follow\", \"follow\", \"follow\", \"follow\", \"follow\", \"follow\", \"follow\", \"forc\", \"forc\", \"forc\", \"forc\", \"forc\", \"forc\", \"forc\", \"forc\", \"forc\", \"forc\", \"ford\", \"foreign\", \"foreign\", \"foreign\", \"foreign\", \"foreign\", \"foreign\", \"foreign\", \"foreign\", \"foreign\", \"forex\", \"fortun\", \"franc\", \"franc\", \"franc\", \"franc\", \"franc\", \"freedom\", \"freedom\", \"friend\", \"friend\", \"friend\", \"friend\", \"friend\", \"friend\", \"friend\", \"friend\", \"friend\", \"friend\", \"frog\", \"fund\", \"fund\", \"fund\", \"fund\", \"game\", \"game\", \"game\", \"game\", \"game\", \"game\", \"game\", \"game\", \"ganguli\", \"ganguli\", \"ganguli\", \"gemma\", \"giudicelli\", \"go\", \"go\", \"go\", \"go\", \"go\", \"go\", \"go\", \"go\", \"go\", \"go\", \"golf\", \"good\", \"good\", \"good\", \"good\", \"good\", \"good\", \"good\", \"good\", \"good\", \"good\", \"govern\", \"govern\", \"govern\", \"govern\", \"govern\", \"govern\", \"govern\", \"govern\", \"govern\", \"govern\", \"grate\", \"greater\", \"greater\", \"greater\", \"grieder\", \"grief\", \"grief\", \"grim\", \"grime\", \"grime\", \"grimezsz\", \"guru\", \"halp\", \"hamilton\", \"hamilton\", \"health\", \"health\", \"health\", \"health\", \"health\", \"health\", \"health\", \"health\", \"health\", \"health\", \"healthcar\", \"hear\", \"hear\", \"hear\", \"hear\", \"hear\", \"hear\", \"help\", \"help\", \"help\", \"help\", \"help\", \"help\", \"help\", \"help\", \"help\", \"help\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"higher\", \"higher\", \"higher\", \"higher\", \"higher\", \"hilfig\", \"hindustantim\", \"home\", \"home\", \"home\", \"home\", \"home\", \"home\", \"home\", \"home\", \"home\", \"home\", \"homepag\", \"honor\", \"hospit\", \"hospit\", \"hospit\", \"hospit\", \"hospit\", \"hospit\", \"hospit\", \"hospit\", \"hospit\", \"hospit\", \"hous\", \"hous\", \"hous\", \"hous\", \"hous\", \"hous\", \"hous\", \"hous\", \"hous\", \"hsslc\", \"huawei\", \"huawei\", \"hugo\", \"hurdl\", \"hype\", \"iitbhf\", \"indi\", \"indi\", \"india\", \"india\", \"india\", \"india\", \"india\", \"india\", \"india\", \"india\", \"india\", \"india\", \"indian\", \"indian\", \"indian\", \"indian\", \"indian\", \"indian\", \"indian\", \"indian\", \"indian\", \"indian\", \"indirect\", \"inflow\", \"inform\", \"inform\", \"inform\", \"inform\", \"inform\", \"inform\", \"inform\", \"inform\", \"inform\", \"inform\", \"inmat\", \"intel\", \"intellig\", \"intens\", \"intens\", \"intens\", \"intens\", \"intern\", \"intern\", \"intern\", \"intern\", \"intern\", \"intern\", \"intern\", \"intern\", \"intern\", \"intern\", \"iran\", \"iran\", \"iran\", \"iranian\", \"islamabad\", \"islamabad\", \"issu\", \"issu\", \"issu\", \"issu\", \"issu\", \"issu\", \"issu\", \"issu\", \"issu\", \"issu\", \"jagannath\", \"jahangiri\", \"jain\", \"jain\", \"jariwala\", \"jassi\", \"jawan\", \"jinp\", \"johar\", \"joshi\", \"judiciari\", \"june\", \"june\", \"june\", \"june\", \"june\", \"june\", \"june\", \"june\", \"june\", \"june\", \"kane\", \"kangana\", \"kangana\", \"kangana\", \"kangana\", \"karan\", \"karen\", \"karma\", \"kevin\", \"kevin\", \"khalistan\", \"khalistan\", \"khalistan\", \"khanna\", \"know\", \"know\", \"know\", \"know\", \"know\", \"know\", \"know\", \"know\", \"know\", \"know\", \"kovrig\", \"labour\", \"labour\", \"labour\", \"labour\", \"labour\", \"labour\", \"labour\", \"langer\", \"laudabl\", \"lauren\", \"law\", \"law\", \"law\", \"law\", \"law\", \"leagu\", \"leagu\", \"leagu\", \"leagu\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn\", \"leclerc\", \"leclerc\", \"leclerc\", \"legend\", \"legend\", \"legend\", \"libra\", \"liga\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like\", \"line\", \"line\", \"line\", \"line\", \"line\", \"line\", \"line\", \"line\", \"line\", \"line\", \"live\", \"live\", \"live\", \"live\", \"live\", \"live\", \"live\", \"live\", \"live\", \"live\", \"lockdown\", \"lockdown\", \"lockdown\", \"lockdown\", \"lockdown\", \"lockdown\", \"lockdown\", \"lockdown\", \"lockdown\", \"lockdown\", \"login\", \"look\", \"look\", \"look\", \"look\", \"look\", \"look\", \"look\", \"look\", \"look\", \"look\", \"love\", \"love\", \"love\", \"love\", \"love\", \"love\", \"love\", \"love\", \"love\", \"love\", \"lucki\", \"lucki\", \"lucki\", \"lucki\", \"lucki\", \"madhya\", \"madhya\", \"madrid\", \"madrid\", \"mafia\", \"maharashtra\", \"maharashtra\", \"maharashtra\", \"maharashtra\", \"maharashtra\", \"mallorca\", \"mamata\", \"manikarnika\", \"market\", \"market\", \"market\", \"market\", \"market\", \"market\", \"market\", \"market\", \"markit\", \"marriag\", \"marriag\", \"marriag\", \"marriag\", \"marriag\", \"masumimewawalla\", \"matur\", \"maya\", \"maya\", \"maya\", \"meal\", \"memorandum\", \"meng\", \"meng\", \"mental\", \"mgnreg\", \"migrant\", \"migrat\", \"migrat\", \"migrat\", \"migrat\", \"militari\", \"militari\", \"militari\", \"militari\", \"militari\", \"militari\", \"militari\", \"militari\", \"militari\", \"mill\", \"mine\", \"mine\", \"minist\", \"minist\", \"minist\", \"minist\", \"minist\", \"minist\", \"minist\", \"minist\", \"minist\", \"minist\", \"ministri\", \"ministri\", \"ministri\", \"ministri\", \"ministri\", \"ministri\", \"ministri\", \"ministri\", \"ministri\", \"mirror\", \"miss\", \"miss\", \"miss\", \"miss\", \"miss\", \"miss\", \"miss\", \"mona\", \"month\", \"month\", \"month\", \"month\", \"month\", \"month\", \"month\", \"month\", \"month\", \"month\", \"moral\", \"moral\", \"morata\", \"mourinho\", \"mourinho\", \"mourinho\", \"mous\", \"mpbse\", \"mpbse\", \"mpsc\", \"msmes\", \"mumbai\", \"mumbai\", \"mumbai\", \"mumbai\", \"mumbai\", \"mumbai\", \"mumbai\", \"mumbai\", \"mumbai\", \"muslim\", \"muslim\", \"mussoori\", \"namrata\", \"nation\", \"nation\", \"nation\", \"nation\", \"nation\", \"nation\", \"nation\", \"nation\", \"nation\", \"nation\", \"navya\", \"navya\", \"need\", \"need\", \"need\", \"need\", \"need\", \"need\", \"need\", \"need\", \"need\", \"need\", \"newspap\", \"noon\", \"normal\", \"normal\", \"normal\", \"normal\", \"normal\", \"normal\", \"normal\", \"normal\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"odisha\", \"odisha\", \"odisha\", \"offenc\", \"offici\", \"offici\", \"offici\", \"offici\", \"offici\", \"offici\", \"offici\", \"offici\", \"offici\", \"olymp\", \"olymp\", \"onion\", \"onlin\", \"onlin\", \"onlin\", \"onlin\", \"onlin\", \"onlin\", \"onlin\", \"onlin\", \"onlin\", \"onlin\", \"oper\", \"oper\", \"oper\", \"oper\", \"oper\", \"oper\", \"oper\", \"oper\", \"oper\", \"outer\", \"oximet\", \"oximet\", \"oximet\", \"oximet\", \"oxygen\", \"oxygen\", \"oxygen\", \"oxygen\", \"oxygen\", \"pais\", \"pakistan\", \"pakistan\", \"pakistan\", \"pakistan\", \"pakistan\", \"pakistan\", \"pakistan\", \"pakistan\", \"pakistan\", \"pakistani\", \"panel\", \"parent\", \"parent\", \"parent\", \"parent\", \"parent\", \"parent\", \"parent\", \"parent\", \"parti\", \"parti\", \"parti\", \"parti\", \"parti\", \"parti\", \"parti\", \"parti\", \"parti\", \"parti\", \"patient\", \"patient\", \"patient\", \"patient\", \"patient\", \"patient\", \"patient\", \"patient\", \"patient\", \"patient\", \"peac\", \"peac\", \"peac\", \"peac\", \"peac\", \"peac\", \"peac\", \"peopl\", \"peopl\", \"peopl\", \"peopl\", \"peopl\", \"peopl\", \"peopl\", \"peopl\", \"peopl\", \"peopl\", \"perfectionist\", \"person\", \"person\", \"person\", \"person\", \"person\", \"person\", \"person\", \"person\", \"person\", \"person\", \"petit\", \"petit\", \"petit\", \"phil\", \"photograph\", \"plasma\", \"plasma\", \"plasma\", \"play\", \"play\", \"play\", \"play\", \"play\", \"play\", \"play\", \"play\", \"play\", \"play\", \"player\", \"player\", \"player\", \"player\", \"player\", \"plea\", \"plea\", \"plea\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"polic\", \"polic\", \"polic\", \"polic\", \"polic\", \"polic\", \"polic\", \"polic\", \"polic\", \"polic\", \"policemen\", \"policemen\", \"polit\", \"polit\", \"polit\", \"polit\", \"polit\", \"polit\", \"polit\", \"polit\", \"polit\", \"polit\", \"poor\", \"poor\", \"poor\", \"poor\", \"poor\", \"poor\", \"poor\", \"possibl\", \"possibl\", \"possibl\", \"possibl\", \"possibl\", \"possibl\", \"possibl\", \"possibl\", \"possibl\", \"possibl\", \"post\", \"post\", \"post\", \"post\", \"post\", \"post\", \"post\", \"post\", \"post\", \"post\", \"postal\", \"power\", \"power\", \"power\", \"power\", \"power\", \"power\", \"power\", \"power\", \"power\", \"power\", \"prasar\", \"prasar\", \"prasar\", \"prasar\", \"precious\", \"prescript\", \"presid\", \"presid\", \"presid\", \"presid\", \"presid\", \"presid\", \"presid\", \"privat\", \"privat\", \"privat\", \"privat\", \"privat\", \"privat\", \"privat\", \"privat\", \"probationari\", \"procur\", \"procur\", \"procur\", \"prompt\", \"psqi\", \"punjab\", \"punjab\", \"punjab\", \"punjab\", \"punjab\", \"punjab\", \"puri\", \"puri\", \"puri\", \"puri\", \"putin\", \"puzzl\", \"puzzl\", \"queen\", \"queen\", \"questionnair\", \"race\", \"race\", \"race\", \"race\", \"race\", \"race\", \"railway\", \"rain\", \"rain\", \"rain\", \"rain\", \"rainfal\", \"rath\", \"ration\", \"ration\", \"read\", \"read\", \"read\", \"read\", \"read\", \"read\", \"read\", \"read\", \"read\", \"realiti\", \"realiti\", \"realiti\", \"realiti\", \"realiti\", \"realiti\", \"realiti\", \"recent\", \"recent\", \"recent\", \"recent\", \"recent\", \"recent\", \"recent\", \"recent\", \"recent\", \"recent\", \"recruit\", \"recruit\", \"rectangular\", \"refere\", \"reform\", \"reform\", \"reform\", \"reform\", \"refund\", \"refund\", \"reimpos\", \"relianc\", \"remdesivir\", \"reopen\", \"reopen\", \"report\", \"report\", \"report\", \"report\", \"report\", \"report\", \"report\", \"report\", \"report\", \"report\", \"resid\", \"resid\", \"resid\", \"resid\", \"resid\", \"resid\", \"resid\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"reunion\", \"rial\", \"richer\", \"right\", \"right\", \"right\", \"right\", \"right\", \"right\", \"right\", \"right\", \"right\", \"right\", \"romant\", \"romant\", \"roshan\", \"rupe\", \"rupe\", \"rupe\", \"salt\", \"sampl\", \"sampl\", \"sampl\", \"sandeep\", \"sania\", \"saroj\", \"saroj\", \"saroj\", \"saroj\", \"saroj\", \"satisfi\", \"sawant\", \"sawant\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"scenario\", \"scenario\", \"scenario\", \"scenario\", \"scene\", \"scene\", \"scene\", \"scene\", \"scheme\", \"scheme\", \"scheme\", \"scheme\", \"scheme\", \"scheme\", \"scheme\", \"school\", \"school\", \"school\", \"school\", \"school\", \"school\", \"school\", \"school\", \"school\", \"school\", \"scope\", \"scott\", \"screen\", \"screen\", \"screen\", \"screen\", \"screen\", \"screen\", \"screen\", \"screen\", \"screengrab\", \"season\", \"season\", \"season\", \"season\", \"season\", \"season\", \"season\", \"secondari\", \"secondari\", \"secondari\", \"secondari\", \"secur\", \"secur\", \"secur\", \"secur\", \"secur\", \"secur\", \"secur\", \"secur\", \"secur\", \"secur\", \"sensex\", \"serial\", \"serial\", \"setien\", \"shah\", \"shah\", \"shah\", \"shah\", \"shah\", \"shah\", \"shah\", \"shah\", \"share\", \"share\", \"share\", \"share\", \"share\", \"share\", \"share\", \"share\", \"share\", \"share\", \"sheet\", \"sheet\", \"sheet\", \"sheet\", \"shefali\", \"shehnaaz\", \"shekhar\", \"shekhar\", \"shelar\", \"shilpa\", \"shoot\", \"shoot\", \"shoot\", \"shoot\", \"shoot\", \"shoot\", \"shoot\", \"shoot\", \"shoot\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"sidharth\", \"sign\", \"sign\", \"sign\", \"sign\", \"sign\", \"sign\", \"sign\", \"sign\", \"simmon\", \"simmon\", \"sindoor\", \"singh\", \"singh\", \"singh\", \"singh\", \"singh\", \"singh\", \"singh\", \"singh\", \"singh\", \"singh\", \"sion\", \"sisodia\", \"sisodia\", \"sisodia\", \"sleep\", \"sleep\", \"sleep\", \"sleep\", \"sleep\", \"sleep\", \"smriti\", \"somebodi\", \"sovereignti\", \"spavor\", \"speedi\", \"spielberg\", \"spielberg\", \"sport\", \"sport\", \"sport\", \"sport\", \"sport\", \"sport\", \"sport\", \"sport\", \"squad\", \"srpf\", \"stand\", \"stand\", \"stand\", \"stand\", \"stand\", \"stand\", \"stand\", \"stand\", \"stand\", \"stand\", \"start\", \"start\", \"start\", \"start\", \"start\", \"start\", \"start\", \"start\", \"start\", \"start\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"strang\", \"strateg\", \"strateg\", \"strateg\", \"strateg\", \"strateg\", \"strateg\", \"strateg\", \"stray\", \"stray\", \"student\", \"student\", \"student\", \"student\", \"student\", \"student\", \"student\", \"student\", \"style\", \"style\", \"style\", \"style\", \"style\", \"submit\", \"submit\", \"submit\", \"submit\", \"submit\", \"succeed\", \"sudha\", \"sudhakar\", \"suicid\", \"suicid\", \"surgeri\", \"surgeri\", \"surgeri\", \"surgeri\", \"sushant\", \"sushant\", \"sushant\", \"sushant\", \"sushant\", \"sushant\", \"sushant\", \"take\", \"take\", \"take\", \"take\", \"take\", \"take\", \"take\", \"take\", \"take\", \"take\", \"tale\", \"talli\", \"talli\", \"talli\", \"talli\", \"tallulah\", \"tallulah\", \"taskmast\", \"taurus\", \"taxpay\", \"taxpay\", \"taxpay\", \"teacher\", \"teacher\", \"teacher\", \"teacher\", \"teacher\", \"teacher\", \"tehran\", \"tell\", \"tell\", \"tell\", \"tell\", \"tell\", \"tell\", \"tell\", \"tell\", \"tell\", \"tell\", \"tenni\", \"terror\", \"terror\", \"terror\", \"terror\", \"terrorist\", \"terrorist\", \"terrorist\", \"terrorist\", \"terrorist\", \"test\", \"test\", \"test\", \"test\", \"test\", \"test\", \"test\", \"test\", \"test\", \"test\", \"thane\", \"thane\", \"thank\", \"thank\", \"thank\", \"thank\", \"thank\", \"thank\", \"thank\", \"thank\", \"thank\", \"therapeut\", \"think\", \"think\", \"think\", \"think\", \"think\", \"think\", \"think\", \"think\", \"think\", \"think\", \"throne\", \"ticket\", \"tiktok\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"timm\", \"today\", \"today\", \"today\", \"today\", \"today\", \"today\", \"today\", \"today\", \"today\", \"today\", \"tomato\", \"tommi\", \"tonn\", \"tourism\", \"tourism\", \"trade\", \"trade\", \"trade\", \"trade\", \"trade\", \"trade\", \"trailer\", \"trailer\", \"traumat\", \"trendsett\", \"trump\", \"trump\", \"trump\", \"trump\", \"trump\", \"tulsi\", \"twitter\", \"twitter\", \"twitter\", \"twitter\", \"twitter\", \"twitter\", \"twitter\", \"twitter\", \"twitter\", \"twitter\", \"unctad\", \"undergradu\", \"union\", \"union\", \"union\", \"union\", \"union\", \"union\", \"union\", \"union\", \"union\", \"urdu\", \"valid\", \"valid\", \"valid\", \"valu\", \"valu\", \"valu\", \"valu\", \"vancouv\", \"vermicelli\", \"verstappen\", \"verstappen\", \"verstappen\", \"verstappen\", \"vettel\", \"vettel\", \"video\", \"video\", \"video\", \"video\", \"video\", \"video\", \"video\", \"video\", \"video\", \"virgo\", \"visibl\", \"vogu\", \"vogu\", \"waiver\", \"want\", \"want\", \"want\", \"want\", \"want\", \"want\", \"want\", \"want\", \"want\", \"want\", \"ward\", \"wear\", \"wear\", \"wear\", \"wear\", \"wear\", \"wear\", \"wear\", \"wear\", \"weather\", \"weather\", \"websit\", \"websit\", \"websit\", \"websit\", \"websit\", \"week\", \"week\", \"week\", \"week\", \"week\", \"week\", \"week\", \"week\", \"week\", \"week\", \"welfar\", \"welfar\", \"welfar\", \"welfar\", \"western\", \"western\", \"western\", \"window\", \"woman\", \"woman\", \"woman\", \"woman\", \"woman\", \"woman\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"worker\", \"worker\", \"worker\", \"worker\", \"worker\", \"worker\", \"worker\", \"worker\", \"world\", \"world\", \"world\", \"world\", \"world\", \"world\", \"world\", \"world\", \"world\", \"world\", \"write\", \"write\", \"write\", \"write\", \"write\", \"write\", \"write\", \"write\", \"write\", \"write\", \"xinjiang\", \"yaara\", \"yaara\", \"yara\", \"yatra\", \"yatra\", \"yatra\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"youngest\", \"zhao\", \"zodiac\", \"zodiac\", \"zodiac\", \"zonal\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 4, 7, 9, 5, 3, 2, 8, 6, 10]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el1241404475002830007593808241\", ldavis_el1241404475002830007593808241_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el1241404475002830007593808241\", ldavis_el1241404475002830007593808241_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el1241404475002830007593808241\", ldavis_el1241404475002830007593808241_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ],
            "text/plain": [
              "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
              "topic                                                \n",
              "0     -0.000288  0.042000       1        1  12.812829\n",
              "3      0.014162 -0.093457       2        1  12.018830\n",
              "6      0.042771  0.006993       3        1  11.952091\n",
              "8      0.062473 -0.002646       4        1  10.705054\n",
              "4     -0.051246  0.054833       5        1   9.824071\n",
              "2     -0.086967 -0.046753       6        1   9.624974\n",
              "1      0.046827  0.051422       7        1   9.486127\n",
              "7      0.088651 -0.028521       8        1   8.348923\n",
              "5     -0.038607  0.033721       9        1   8.032031\n",
              "9     -0.077776 -0.017592      10        1   7.195073, topic_info=        Term        Freq       Total Category  logprob  loglift\n",
              "614     test  104.000000  104.000000  Default  30.0000  30.0000\n",
              "274    china  116.000000  116.000000  Default  29.0000  29.0000\n",
              "849   result   64.000000   64.000000  Default  28.0000  28.0000\n",
              "1500    love   69.000000   69.000000  Default  27.0000  27.0000\n",
              "1513   share   79.000000   79.000000  Default  26.0000  26.0000\n",
              "...      ...         ...         ...      ...      ...      ...\n",
              "563   person    5.726450   53.240566  Topic10  -5.9566   0.4020\n",
              "1151    know    5.483520   38.363319  Topic10  -5.9999   0.6864\n",
              "319       go    5.566634   52.626358  Topic10  -5.9849   0.3853\n",
              "224    state    5.609883  121.127632  Topic10  -5.9771  -0.4405\n",
              "113    india    5.593893  215.949860  Topic10  -5.9800  -1.0216\n",
              "\n",
              "[728 rows x 6 columns], token_table=      Topic      Freq       Term\n",
              "term                            \n",
              "5160      7  0.697302  actigraph\n",
              "1102      1  0.063496      actor\n",
              "1102      2  0.142866      actor\n",
              "1102      3  0.031748      actor\n",
              "1102      4  0.031748      actor\n",
              "...     ...       ...        ...\n",
              "1450      3  0.750154       zhao\n",
              "4875      4  0.083789     zodiac\n",
              "4875      7  0.754100     zodiac\n",
              "4875      8  0.083789     zodiac\n",
              "4923      3  0.834645      zonal\n",
              "\n",
              "[2169 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[1, 4, 7, 9, 5, 3, 2, 8, 6, 10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1Kg6NCqdTG6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Gensim provides a wrapper to implement Mallet’s LDA from within Gensim itself. \n",
        "#You only need to download the zipfile, unzip it and provide the path to mallet in the unzipped directory to gensim.models.wrappers.LdaMallet\n",
        "# Download File: http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\n",
        "! wget http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5jbFJB3drRq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mallet_path = 'mallet-2.0.8/bin/mallet' # update this path\n",
        "ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=bow_corpus, num_topics=10, id2word=dictionary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geqY3dmvdrON",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For each topic, we will explore the words occuring in that topic and its relative weight.\n",
        "for idx, topic in ldamallet.show_topics(formatted=False):\n",
        "    print('Topic: {} \\nWords: {}'.format(idx, topic))\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_05-tF4WdrMs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute Perplexity\n",
        "# print('\\nPerplexity: ', ldamallet.log_perplexity(bow_corpus))  # a measure of how good the model is. lower the better.\n",
        "\n",
        "# Compute Coherence Score\n",
        "coherence_model_ldamallet = CoherenceModel(model=ldamallet, texts=processed_docs, dictionary=dictionary, coherence='c_v')\n",
        "coherence_ldamallet = coherence_model_ldamallet.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_ldamallet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93iGDnAgdrJu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualize the topics\n",
        "# pyLDAvis.enable_notebook()\n",
        "# vis = pyLDAvis.gensim.prepare(ldamallet, bow_corpus, dictionary)\n",
        "# vis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfXwqy3ydrHt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train our lda model using gensim.models.LdaMulticore and save it to ‘lda_model’\n",
        "lda_model_tf_idf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=dictionary, passes=2, workers=2)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EH2jyG8Ad4ty",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "6b50dd35-b0d1-4368-fe66-060bf2f81b2e"
      },
      "source": [
        "# For each topic, we will explore the words occuring in that topic and its relative weight.\n",
        "for idx, topic in lda_model_tf_idf.print_topics(-1):\n",
        "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic: 0 \n",
            "Words: 0.001*\"coal\" + 0.001*\"maya\" + 0.001*\"saroj\" + 0.001*\"kravitz\" + 0.001*\"athlet\" + 0.001*\"coach\" + 0.001*\"rial\" + 0.001*\"bless\" + 0.001*\"exercis\" + 0.001*\"sleep\"\n",
            "Topic: 1 \n",
            "Words: 0.001*\"china\" + 0.001*\"chines\" + 0.001*\"india\" + 0.001*\"ganguli\" + 0.001*\"militari\" + 0.001*\"border\" + 0.001*\"crpf\" + 0.001*\"love\" + 0.001*\"foreign\" + 0.001*\"share\"\n",
            "Topic: 2 \n",
            "Words: 0.001*\"board\" + 0.001*\"result\" + 0.001*\"shah\" + 0.001*\"exam\" + 0.001*\"refund\" + 0.001*\"mpbse\" + 0.001*\"rain\" + 0.001*\"china\" + 0.001*\"celina\" + 0.001*\"film\"\n",
            "Topic: 3 \n",
            "Words: 0.001*\"singh\" + 0.001*\"intel\" + 0.001*\"assam\" + 0.001*\"video\" + 0.001*\"lola\" + 0.001*\"deepika\" + 0.001*\"woman\" + 0.001*\"morata\" + 0.001*\"oximet\" + 0.001*\"billion\"\n",
            "Topic: 4 \n",
            "Words: 0.001*\"dubey\" + 0.001*\"test\" + 0.001*\"prasar\" + 0.001*\"bharati\" + 0.001*\"navya\" + 0.001*\"gemma\" + 0.001*\"throne\" + 0.001*\"class\" + 0.001*\"case\" + 0.001*\"app\"\n",
            "Topic: 5 \n",
            "Words: 0.002*\"school\" + 0.002*\"learn\" + 0.001*\"india\" + 0.001*\"china\" + 0.001*\"delhi\" + 0.001*\"sushant\" + 0.001*\"labour\" + 0.001*\"kevin\" + 0.001*\"court\" + 0.001*\"indian\"\n",
            "Topic: 6 \n",
            "Words: 0.001*\"franc\" + 0.001*\"dubey\" + 0.001*\"cgbse\" + 0.001*\"migrat\" + 0.001*\"drug\" + 0.001*\"patient\" + 0.001*\"shoot\" + 0.001*\"alter\" + 0.001*\"mous\" + 0.001*\"chhattisgarh\"\n",
            "Topic: 7 \n",
            "Words: 0.001*\"covid\" + 0.001*\"plasma\" + 0.001*\"patient\" + 0.001*\"putin\" + 0.001*\"polic\" + 0.001*\"shoot\" + 0.001*\"makeup\" + 0.001*\"govern\" + 0.001*\"sudhakar\" + 0.001*\"test\"\n",
            "Topic: 8 \n",
            "Words: 0.001*\"tallulah\" + 0.001*\"flood\" + 0.001*\"leclerc\" + 0.001*\"verstappen\" + 0.001*\"lalbazaar\" + 0.001*\"cent\" + 0.001*\"race\" + 0.001*\"crime\" + 0.001*\"inund\" + 0.001*\"point\"\n",
            "Topic: 9 \n",
            "Words: 0.001*\"china\" + 0.001*\"scheme\" + 0.001*\"chines\" + 0.001*\"exam\" + 0.001*\"poor\" + 0.001*\"villag\" + 0.001*\"antigen\" + 0.001*\"app\" + 0.001*\"power\" + 0.001*\"test\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fd6CRYegd4qz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "48e26172-c13f-4929-851e-6411019d86da"
      },
      "source": [
        "# Compute Perplexity\n",
        "print('\\nPerplexity: ', lda_model_tf_idf.log_perplexity(corpus_tfidf))  # a measure of how good the model is. lower the better.\n",
        "\n",
        "# Compute Coherence Score\n",
        "coherence_model_lda = CoherenceModel(model=lda_model_tf_idf, texts=processed_docs, dictionary=dictionary, coherence='c_v')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda)\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Perplexity:  -13.64994474715381\n",
            "\n",
            "Coherence Score:  0.5792533155231394\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFfcQqaCcbAq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 861
        },
        "outputId": "dddc5a0d-7147-4ea6-b706-e7b4aed715df"
      },
      "source": [
        "# Visualize the topics\n",
        "pyLDAvis.enable_notebook()\n",
        "vis = pyLDAvis.gensim.prepare(lda_model_tf_idf, corpus_tfidf, dictionary)\n",
        "vis"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el1241404474137013923365459731\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el1241404474137013923365459731_data = {\"mdsDat\": {\"x\": [0.02349022257322813, 0.0017184918474151684, -0.0003329138263710853, -0.000991999556260456, -0.006427076466691986, -0.005493628714438935, -0.00034143530132864467, -0.003906936386430167, -0.0035225602547236013, -0.0041921639143984255], \"y\": [-0.002744055362090288, 0.02021107311185861, -0.007588672225365001, -0.007940993814973549, -0.0005359437210610393, -0.00224301486611498, 0.001649067760496876, -0.0002230601510246684, 0.0011900964016303838, -0.0017744971333563829], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [18.27070426940918, 12.853691101074219, 12.725726127624512, 12.033596992492676, 9.875732421875, 9.204123497009277, 7.941735744476318, 7.130216598510742, 5.687336444854736, 4.277135848999023]}, \"tinfo\": {\"Term\": [\"dubey\", \"tallulah\", \"exam\", \"coal\", \"board\", \"maya\", \"flood\", \"leclerc\", \"china\", \"plasma\", \"shoot\", \"learn\", \"school\", \"shah\", \"franc\", \"verstappen\", \"refund\", \"cgbse\", \"saroj\", \"assam\", \"mpbse\", \"rain\", \"race\", \"app\", \"prasar\", \"bharati\", \"film\", \"intel\", \"migrat\", \"navya\", \"kevin\", \"labour\", \"mourinho\", \"deepen\", \"learn\", \"tie\", \"punjab\", \"shekhar\", \"verma\", \"policemen\", \"islamabad\", \"school\", \"strateg\", \"pakistani\", \"proxim\", \"sushant\", \"biden\", \"cross\", \"interest\", \"trump\", \"ankita\", \"price\", \"smart\", \"converg\", \"undermin\", \"mafia\", \"teacher\", \"grief\", \"reach\", \"distribut\", \"delhi\", \"pakistan\", \"high\", \"india\", \"econom\", \"court\", \"technolog\", \"game\", \"indian\", \"china\", \"capit\", \"maharashtra\", \"need\", \"state\", \"coronavirus\", \"govern\", \"death\", \"test\", \"putin\", \"makeup\", \"sudhakar\", \"meng\", \"plasma\", \"cash\", \"sidharth\", \"giudicelli\", \"vehicl\", \"yatra\", \"chadha\", \"bombay\", \"jain\", \"seiz\", \"professor\", \"colleg\", \"shoot\", \"odisha\", \"convalesc\", \"alumni\", \"kangana\", \"embassi\", \"fashion\", \"zhao\", \"thane\", \"devot\", \"rath\", \"ford\", \"medic\", \"vogu\", \"covid\", \"isol\", \"patient\", \"cover\", \"lockdown\", \"polic\", \"govern\", \"citi\", \"home\", \"delhi\", \"peopl\", \"posit\", \"test\", \"love\", \"onlin\", \"order\", \"hospit\", \"student\", \"scheme\", \"karma\", \"kabul\", \"setien\", \"stray\", \"crematorium\", \"poor\", \"antigen\", \"muslim\", \"villag\", \"shilpa\", \"sheet\", \"jariwala\", \"rescu\", \"airport\", \"confus\", \"safe\", \"madrid\", \"vihar\", \"app\", \"leader\", \"welfar\", \"free\", \"bihar\", \"frog\", \"ration\", \"strang\", \"anim\", \"shefali\", \"deserv\", \"eastern\", \"exam\", \"power\", \"line\", \"claim\", \"china\", \"chines\", \"west\", \"parti\", \"bodi\", \"polit\", \"test\", \"nation\", \"court\", \"militari\", \"board\", \"india\", \"ganguli\", \"crpf\", \"rupe\", \"shelar\", \"lucki\", \"hugo\", \"command\", \"breakfast\", \"golf\", \"jaffer\", \"zodiac\", \"terrorist\", \"grieder\", \"alphabet\", \"tomato\", \"onion\", \"border\", \"foreign\", \"inflow\", \"donnel\", \"mirror\", \"salt\", \"langer\", \"timm\", \"hilfig\", \"tommi\", \"militari\", \"jawan\", \"search\", \"dass\", \"friend\", \"maya\", \"lesson\", \"saroj\", \"danc\", \"captain\", \"compani\", \"chines\", \"hear\", \"love\", \"share\", \"china\", \"india\", \"forc\", \"parti\", \"maharashtra\", \"area\", \"good\", \"sushant\", \"indian\", \"refund\", \"rain\", \"celina\", \"mpbse\", \"dope\", \"aspen\", \"spielberg\", \"tourism\", \"puzzl\", \"jassi\", \"mona\", \"shah\", \"taxpay\", \"amrish\", \"indi\", \"apurva\", \"scenario\", \"madhya\", \"celsius\", \"communist\", \"simmon\", \"unctad\", \"websit\", \"scott\", \"therapeut\", \"cupp\", \"zonal\", \"mpsc\", \"felin\", \"pradesh\", \"board\", \"exam\", \"result\", \"film\", \"haryana\", \"china\", \"sport\", \"provid\", \"intel\", \"assam\", \"lola\", \"deepika\", \"morata\", \"delist\", \"postal\", \"woman\", \"bailey\", \"puppi\", \"ahsec\", \"ballot\", \"sinha\", \"nepot\", \"exposur\", \"andheri\", \"troll\", \"oximet\", \"kid\", \"singh\", \"bath\", \"fortun\", \"amazon\", \"mallorca\", \"atl\\u00e9tico\", \"khalistan\", \"pupper\", \"child\", \"coupl\", \"depress\", \"billion\", \"video\", \"mental\", \"write\", \"comment\", \"sushant\", \"compani\", \"class\", \"share\", \"base\", \"post\", \"prasar\", \"bharati\", \"navya\", \"gemma\", \"throne\", \"dubey\", \"yaara\", \"merced\", \"fastest\", \"recruit\", \"inmat\", \"hamilton\", \"race\", \"yara\", \"brazil\", \"friendship\", \"plea\", \"broadcast\", \"ektarkapoor\", \"mclaren\", \"app\", \"editori\", \"mantra\", \"australian\", \"convert\", \"swami\", \"waiver\", \"admiss\", \"claus\", \"cri\", \"tale\", \"vika\", \"thank\", \"quarantin\", \"test\", \"class\", \"case\", \"onlin\", \"student\", \"cricket\", \"school\", \"learn\", \"screen\", \"coach\", \"offici\", \"chines\", \"game\", \"film\", \"actor\", \"coal\", \"kravitz\", \"rial\", \"athlet\", \"namrata\", \"markit\", \"maya\", \"bless\", \"babu\", \"memoir\", \"sawant\", \"aerob\", \"reopen\", \"olymp\", \"mahesh\", \"queen\", \"exercis\", \"saroj\", \"karen\", \"circular\", \"iranian\", \"sleep\", \"mirza\", \"mine\", \"iran\", \"sania\", \"tenni\", \"coach\", \"council\", \"bypass\", \"contract\", \"danc\", \"decis\", \"love\", \"teacher\", \"school\", \"cgbse\", \"franc\", \"migrat\", \"mous\", \"chhattisgarh\", \"urdu\", \"alter\", \"dubey\", \"desai\", \"grime\", \"euro\", \"drug\", \"dose\", \"remdesivir\", \"khanna\", \"mussoori\", \"treatment\", \"migrant\", \"airlin\", \"orang\", \"crimin\", \"musk\", \"chest\", \"authoris\", \"worth\", \"fire\", \"grimezsz\", \"imag\", \"subject\", \"reflect\", \"shoot\", \"hous\", \"crore\", \"plasma\", \"patient\", \"twitter\", \"covid\", \"class\", \"exam\", \"state\", \"resid\", \"health\", \"tallulah\", \"leclerc\", \"flood\", \"verstappen\", \"lalbazaar\", \"inund\", \"kaushik\", \"kolkata\", \"cent\", \"transgress\", \"vaccin\", \"sensex\", \"benchmark\", \"drown\", \"goalpara\", \"water\", \"deliveri\", \"hermesparcel\", \"thankyou\", \"foetus\", \"side\", \"race\", \"friendship\", \"crime\", \"settl\", \"volatil\", \"flux\", \"fault\", \"vettel\", \"ferrari\", \"end\", \"conflict\", \"hamilton\", \"point\", \"season\", \"district\", \"signific\", \"draw\"], \"Freq\": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25107434391975403, 0.2705540359020233, 0.21754615008831024, 0.2146805077791214, 0.34650692343711853, 0.20624558627605438, 0.2218354344367981, 0.17862634360790253, 0.16847434639930725, 0.19371001422405243, 0.1584184616804123, 0.3488117456436157, 0.21273106336593628, 0.14220654964447021, 0.16203762590885162, 0.29632923007011414, 0.13636073470115662, 0.14830821752548218, 0.17477233707904816, 0.16852836310863495, 0.12921269237995148, 0.1318611353635788, 0.13418449461460114, 0.12702973186969757, 0.1245516687631607, 0.12208414077758789, 0.2275562584400177, 0.12302350252866745, 0.1631433069705963, 0.13073298335075378, 0.29655781388282776, 0.19599249958992004, 0.18579059839248657, 0.34119370579719543, 0.20125631988048553, 0.2457185685634613, 0.1684085726737976, 0.19222910702228546, 0.2442903071641922, 0.33505862951278687, 0.1771441102027893, 0.19881084561347961, 0.18230317533016205, 0.1963207870721817, 0.18444566428661346, 0.1947103589773178, 0.18387827277183533, 0.19475813210010529, 0.16952238976955414, 0.16047725081443787, 0.14946798980236053, 0.14536848664283752, 0.1754818856716156, 0.13751962780952454, 0.12976734340190887, 0.1263669729232788, 0.1305895894765854, 0.11451157182455063, 0.10800949484109879, 0.13850632309913635, 0.11044460535049438, 0.1096247211098671, 0.11158536374568939, 0.10677938908338547, 0.1609419882297516, 0.1022731363773346, 0.09340374916791916, 0.09272778034210205, 0.1046866625547409, 0.0913013145327568, 0.13204802572727203, 0.090471051633358, 0.10811886191368103, 0.09440560638904572, 0.0892399474978447, 0.08870275318622589, 0.12558697164058685, 0.09433303028345108, 0.1900726556777954, 0.11965361982584, 0.16997791826725006, 0.11077731847763062, 0.14009203016757965, 0.16775111854076385, 0.15617097914218903, 0.11838413774967194, 0.12868419289588928, 0.1452351063489914, 0.12971901893615723, 0.12781229615211487, 0.14749778807163239, 0.1295299530029297, 0.1263662874698639, 0.11957131326198578, 0.12052324414253235, 0.11997424066066742, 0.1837775558233261, 0.1220511868596077, 0.11963058263063431, 0.11708596348762512, 0.11648492515087128, 0.12163853645324707, 0.14283396303653717, 0.1389094740152359, 0.0995069220662117, 0.13905943930149078, 0.09897994250059128, 0.11538173258304596, 0.09205842018127441, 0.10177575051784515, 0.09743776172399521, 0.09013672173023224, 0.10497551411390305, 0.10388030111789703, 0.08656848967075348, 0.13535091280937195, 0.10822024196386337, 0.11862210929393768, 0.10584103316068649, 0.09492868930101395, 0.08104241639375687, 0.09184359014034271, 0.08111817389726639, 0.10186614841222763, 0.07451342791318893, 0.0793989822268486, 0.09470263123512268, 0.1615140289068222, 0.1341230571269989, 0.11911123991012573, 0.10687779635190964, 0.2250320166349411, 0.16742883622646332, 0.10966257750988007, 0.12287238240242004, 0.11027032881975174, 0.11733634769916534, 0.1337215006351471, 0.11619271337985992, 0.12105775624513626, 0.11189384758472443, 0.1133715882897377, 0.11318226903676987, 0.15308579802513123, 0.13594025373458862, 0.12686045467853546, 0.11918679624795914, 0.12428898364305496, 0.11539609730243683, 0.11155888438224792, 0.0917801782488823, 0.10006774961948395, 0.08688607066869736, 0.08583788573741913, 0.11060690134763718, 0.08382637798786163, 0.08082634955644608, 0.07993115484714508, 0.07993100583553314, 0.13751111924648285, 0.12888115644454956, 0.07282460480928421, 0.07011102885007858, 0.06841796636581421, 0.06808197498321533, 0.06804128736257553, 0.06804128736257553, 0.06804122775793076, 0.06804107874631882, 0.1446283459663391, 0.06678775697946548, 0.0667877122759819, 0.06678730249404907, 0.11777538806200027, 0.10290840268135071, 0.07461213320493698, 0.09380148351192474, 0.09774556010961533, 0.08447310328483582, 0.1064959466457367, 0.16525602340698242, 0.09898470342159271, 0.1295941323041916, 0.12813900411128998, 0.18173083662986755, 0.1576218605041504, 0.09643760323524475, 0.10281781107187271, 0.10419909656047821, 0.0952310860157013, 0.0935196727514267, 0.09750133752822876, 0.0962204784154892, 0.1403873711824417, 0.12799151241779327, 0.12056519836187363, 0.13789868354797363, 0.10628104954957962, 0.10557994991540909, 0.10580561310052872, 0.1011781319975853, 0.09951793402433395, 0.09654717147350311, 0.09654705971479416, 0.1441204696893692, 0.10824132710695267, 0.09073743969202042, 0.09293660521507263, 0.08559774607419968, 0.09023650735616684, 0.08013129979372025, 0.0736575648188591, 0.08685208112001419, 0.07875563204288483, 0.07330913841724396, 0.09160244464874268, 0.0723528042435646, 0.07220256328582764, 0.07220254838466644, 0.07185833901166916, 0.07185815274715424, 0.07037629932165146, 0.0909072607755661, 0.17156821489334106, 0.14296284317970276, 0.1485714614391327, 0.11306019872426987, 0.08177544921636581, 0.12776809930801392, 0.08377715200185776, 0.07407733798027039, 0.11577997356653214, 0.1111598014831543, 0.10032914578914642, 0.09967837482690811, 0.09703072905540466, 0.08420664817094803, 0.08420640975236893, 0.09794706851243973, 0.07240695506334305, 0.07240688800811768, 0.07147756218910217, 0.07482542097568512, 0.06763999164104462, 0.07957898080348969, 0.06703216582536697, 0.06604396551847458, 0.06602902710437775, 0.08866015821695328, 0.07038667798042297, 0.1167692169547081, 0.06458267569541931, 0.06349687278270721, 0.06349679827690125, 0.06254430115222931, 0.06254427880048752, 0.06047043949365616, 0.058445725589990616, 0.06727715581655502, 0.06519313156604767, 0.0696026012301445, 0.08815532177686691, 0.1043454110622406, 0.06843774765729904, 0.08398820459842682, 0.07575257122516632, 0.08322513103485107, 0.07266467809677124, 0.0763501301407814, 0.07373455911874771, 0.06980684399604797, 0.06773098558187485, 0.0980643779039383, 0.0980643555521965, 0.09501659125089645, 0.09009592235088348, 0.09009580314159393, 0.10384765267372131, 0.07234767079353333, 0.06286577880382538, 0.05845898017287254, 0.05769882723689079, 0.05581445246934891, 0.06093882396817207, 0.0732305571436882, 0.052310045808553696, 0.05664057284593582, 0.054366689175367355, 0.06705155223608017, 0.05050179362297058, 0.04664529114961624, 0.044898755848407745, 0.08110987395048141, 0.06165052950382233, 0.04348674416542053, 0.043178167194128036, 0.04204946011304855, 0.042256295680999756, 0.041352711617946625, 0.04135269299149513, 0.041352588683366776, 0.042256228625774384, 0.04506445303559303, 0.044721316546201706, 0.06316470354795456, 0.05056421086192131, 0.10255623608827591, 0.08990954607725143, 0.08604096621274948, 0.07525402307510376, 0.07594174146652222, 0.05656454339623451, 0.07643231749534607, 0.0698336660861969, 0.05346948280930519, 0.05466759204864502, 0.0585823580622673, 0.06320279091596603, 0.05747593194246292, 0.056004445999860764, 0.055896300822496414, 0.1190381720662117, 0.08134369552135468, 0.07490203529596329, 0.0809783935546875, 0.07113160938024521, 0.06729567050933838, 0.10026903450489044, 0.07297132909297943, 0.06401381641626358, 0.06639941036701202, 0.059940155595541, 0.059499286115169525, 0.06351572275161743, 0.06406913697719574, 0.06110683083534241, 0.06022284924983978, 0.07257089018821716, 0.0813683345913887, 0.05539451166987419, 0.054900433868169785, 0.054381951689720154, 0.07256541401147842, 0.07249903678894043, 0.052282508462667465, 0.06137114390730858, 0.04941260442137718, 0.04941260442137718, 0.07631102949380875, 0.06133485957980156, 0.044113386422395706, 0.06777366995811462, 0.06263666599988937, 0.06039847433567047, 0.060764461755752563, 0.05817760154604912, 0.056036245077848434, 0.06944964081048965, 0.0730932205915451, 0.06319344788789749, 0.05072256922721863, 0.04997473210096359, 0.047251712530851364, 0.052214961498975754, 0.07037508487701416, 0.046039484441280365, 0.044654734432697296, 0.04225296154618263, 0.060390111058950424, 0.04014851525425911, 0.040148429572582245, 0.03701769933104515, 0.03700656816363335, 0.043757833540439606, 0.039834607392549515, 0.03444594889879227, 0.03624773025512695, 0.04422091320157051, 0.036247458308935165, 0.033994439989328384, 0.03610951453447342, 0.044985879212617874, 0.03491862863302231, 0.030547594651579857, 0.03952693194150925, 0.03743217512965202, 0.03354790061712265, 0.05751379206776619, 0.04394005611538887, 0.0496785007417202, 0.046552225947380066, 0.059900108724832535, 0.0437634140253067, 0.049331050366163254, 0.0479733943939209, 0.04225461557507515, 0.042769186198711395, 0.03851253166794777, 0.040127936750650406, 0.0682191476225853, 0.05561734735965729, 0.058047741651535034, 0.049078017473220825, 0.04091407358646393, 0.03010295145213604, 0.02797017991542816, 0.02797011472284794, 0.04007859155535698, 0.026208769530057907, 0.02532549761235714, 0.025325346738100052, 0.025325341150164604, 0.02292022295296192, 0.02292010374367237, 0.025366351008415222, 0.024068767204880714, 0.02181091345846653, 0.021810904145240784, 0.0214980635792017, 0.02795945480465889, 0.03324473276734352, 0.02568245492875576, 0.03114362247288227, 0.024793380871415138, 0.020318927243351936, 0.020318927243351936, 0.020318910479545593, 0.021165743470191956, 0.02116571180522442, 0.027132892981171608, 0.02493506483733654, 0.024632424116134644, 0.029013294726610184, 0.027254145592451096, 0.024654153734445572, 0.023988502100110054, 0.022837260738015175], \"Total\": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.39706918597221375, 0.4343646764755249, 0.36354026198387146, 0.36708271503448486, 0.595986008644104, 0.3621802031993866, 0.3917098343372345, 0.3311292827129364, 0.31446802616119385, 0.36574018001556396, 0.3060709238052368, 0.6746912598609924, 0.42201173305511475, 0.2882002294063568, 0.3306749165058136, 0.611285388469696, 0.2823542058467865, 0.3101634681224823, 0.3668384850025177, 0.35532742738723755, 0.27520641684532166, 0.2809250056743622, 0.28615328669548035, 0.2730232775211334, 0.27054521441459656, 0.27113330364227295, 0.5061327219009399, 0.27461349964141846, 0.36466869711875916, 0.2937965989112854, 0.6847869157791138, 0.449350506067276, 0.42803794145584106, 0.8734450936317444, 0.48244452476501465, 0.628606915473938, 0.3869922459125519, 0.4613277316093445, 0.640585720539093, 1.0105128288269043, 0.41490691900253296, 0.5199075937271118, 0.44738179445266724, 0.598818838596344, 0.49567911028862, 0.635450005531311, 0.5142968893051147, 0.7642288208007812, 0.3231041729450226, 0.3214429020881653, 0.30305007100105286, 0.29895004630088806, 0.3645910620689392, 0.2988416850566864, 0.2833486795425415, 0.27994829416275024, 0.30019089579582214, 0.268092542886734, 0.2615905702114105, 0.33636778593063354, 0.27118319272994995, 0.27774685621261597, 0.282950758934021, 0.2788364589214325, 0.4207035005092621, 0.26810169219970703, 0.24698492884635925, 0.24630896747112274, 0.28018856048583984, 0.24488230049610138, 0.3549337387084961, 0.24405208230018616, 0.29192492365837097, 0.25624769926071167, 0.2428208440542221, 0.24228358268737793, 0.3444356918334961, 0.2588880956172943, 0.7028002142906189, 0.371410608291626, 0.6406720280647278, 0.3325982093811035, 0.5027168989181519, 0.6854421496391296, 0.635450005531311, 0.40440019965171814, 0.4885254502296448, 0.6847869157791138, 0.5166301131248474, 0.4957459270954132, 0.7642288208007812, 0.5588375926017761, 0.532172441482544, 0.4375993311405182, 0.5138056874275208, 0.5676330327987671, 0.39311695098876953, 0.27560362219810486, 0.2731832265853882, 0.2706385552883148, 0.27346622943878174, 0.289506196975708, 0.346714049577713, 0.34217578172683716, 0.25305917859077454, 0.3574802279472351, 0.25584614276885986, 0.29906827211380005, 0.24561059474945068, 0.276696115732193, 0.2677198350429535, 0.24804601073265076, 0.2892822027206421, 0.28713560104370117, 0.24012085795402527, 0.3788524866104126, 0.3052986264228821, 0.3386622667312622, 0.30343326926231384, 0.2733345329761505, 0.23459480702877045, 0.26848748326301575, 0.24013751745224, 0.30388858914375305, 0.2280653864145279, 0.24330367147922516, 0.29057058691978455, 0.5218563675880432, 0.45885664224624634, 0.3977421224117279, 0.3433368504047394, 1.0105128288269043, 0.7157741189002991, 0.3675907552242279, 0.4758685231208801, 0.3805854320526123, 0.48880165815353394, 0.7642288208007812, 0.49945324659347534, 0.628606915473938, 0.47605594992637634, 0.564325213432312, 0.8734450936317444, 0.30783095955848694, 0.29068535566329956, 0.28880128264427185, 0.27393102645874023, 0.29041460156440735, 0.2701408863067627, 0.29219546914100647, 0.24652418494224548, 0.2760181427001953, 0.24163034558296204, 0.2405819147825241, 0.3130349814891815, 0.23857049643993378, 0.23557022213935852, 0.2346751093864441, 0.2346750795841217, 0.4104396104812622, 0.39932700991630554, 0.2275686264038086, 0.22485488653182983, 0.2231619507074356, 0.22282597422599792, 0.22278526425361633, 0.22278526425361633, 0.22278526425361633, 0.22278527915477753, 0.47605594992637634, 0.221531942486763, 0.2215319126844406, 0.22153188288211823, 0.3931851387023926, 0.34458106756210327, 0.2485073208808899, 0.3176683187484741, 0.33707448840141296, 0.28584426641464233, 0.39450639486312866, 0.7157741189002991, 0.3684190809726715, 0.5588375926017761, 0.5549887418746948, 1.0105128288269043, 0.8734450936317444, 0.39514151215553284, 0.4758685231208801, 0.5199075937271118, 0.4177631139755249, 0.4119228422641754, 0.611285388469696, 0.640585720539093, 0.2982478439807892, 0.29203546047210693, 0.27842432260513306, 0.3250085711479187, 0.2641404867172241, 0.26343902945518494, 0.2662017047405243, 0.25903743505477905, 0.25737759470939636, 0.2544064223766327, 0.2544064223766327, 0.38027554750442505, 0.2875770926475525, 0.24859663844108582, 0.2629632353782654, 0.24964085221290588, 0.2674837112426758, 0.2507905960083008, 0.231516495347023, 0.273031622171402, 0.24809330701828003, 0.2311682105064392, 0.28968191146850586, 0.23021169006824493, 0.2300616204738617, 0.2300616055727005, 0.2297174334526062, 0.2297174036502838, 0.22823522984981537, 0.2950836718082428, 0.564325213432312, 0.5218563675880432, 0.5478519201278687, 0.4304049015045166, 0.2990376353263855, 1.0105128288269043, 0.36973869800567627, 0.4128648042678833, 0.2746483087539673, 0.2824007272720337, 0.25919708609580994, 0.25854647159576416, 0.25589844584465027, 0.24307455122470856, 0.24307455122470856, 0.2932801842689514, 0.2312745898962021, 0.2312745898962021, 0.2303454726934433, 0.24328960478305817, 0.22650739550590515, 0.26750490069389343, 0.22590240836143494, 0.22491158545017242, 0.22489643096923828, 0.30211693048477173, 0.24178524315357208, 0.40339377522468567, 0.22345007956027985, 0.22236421704292297, 0.22236423194408417, 0.2214118093252182, 0.2214118242263794, 0.21934127807617188, 0.21731333434581757, 0.25111010670661926, 0.2443915754556656, 0.26133257150650024, 0.3347720801830292, 0.49590781331062317, 0.26529523730278015, 0.4687897562980652, 0.3793884217739105, 0.611285388469696, 0.39450639486312866, 0.665498673915863, 0.5549887418746948, 0.38247695565223694, 0.4950636923313141, 0.25897178053855896, 0.25897184014320374, 0.255923330783844, 0.251002699136734, 0.2510027289390564, 0.3241044580936432, 0.23325377702713013, 0.22604715824127197, 0.22160635888576508, 0.22179584205150604, 0.21672305464744568, 0.2379225641489029, 0.29516470432281494, 0.2132161557674408, 0.23879803717136383, 0.23240523040294647, 0.29233989119529724, 0.22279594838619232, 0.2075510174036026, 0.20580443739891052, 0.3788524866104126, 0.2880052626132965, 0.20440921187400818, 0.20514929294586182, 0.20296010375022888, 0.2063550502061844, 0.20225849747657776, 0.20225852727890015, 0.20225851237773895, 0.2074771672487259, 0.22166188061237335, 0.22115077078342438, 0.32945820689201355, 0.26826682686805725, 0.7642288208007812, 0.665498673915863, 0.653235673904419, 0.532172441482544, 0.5676330327987671, 0.33883175253868103, 0.6746912598609924, 0.595986008644104, 0.3106071650981903, 0.33540669083595276, 0.43958404660224915, 0.7157741189002991, 0.4613277316093445, 0.4304049015045166, 0.5127434730529785, 0.2811277210712433, 0.24343225359916687, 0.23699094355106354, 0.26356399059295654, 0.2332201600074768, 0.22938387095928192, 0.34458106756210327, 0.2562945485115051, 0.23616249859333038, 0.24560688436031342, 0.22202882170677185, 0.2215874195098877, 0.23820538818836212, 0.2414366900920868, 0.2325507551431656, 0.23168551921844482, 0.28067103028297424, 0.3176683187484741, 0.21748286485671997, 0.2169884294271469, 0.21647050976753235, 0.2900087535381317, 0.2967570722103119, 0.21437107026576996, 0.2544387876987457, 0.2115008533000946, 0.2115008682012558, 0.33540669083595276, 0.2863169312477112, 0.20620150864124298, 0.3413873612880707, 0.33707448840141296, 0.3698117733001709, 0.5588375926017761, 0.5061327219009399, 0.6746912598609924, 0.23385532200336456, 0.2656850814819336, 0.24462534487247467, 0.21512773633003235, 0.2143801897764206, 0.21276412904262543, 0.23934553563594818, 0.3241044580936432, 0.2204965353012085, 0.21463832259178162, 0.20665772259235382, 0.2982674241065979, 0.2045537233352661, 0.2045537829399109, 0.20190255343914032, 0.20192112028598785, 0.23989999294281006, 0.22288165986537933, 0.19885075092315674, 0.20928426086902618, 0.2565667927265167, 0.21075770258903503, 0.19839923083782196, 0.21507921814918518, 0.2693730294704437, 0.2204497903585434, 0.1949523687362671, 0.2582662105560303, 0.24628567695617676, 0.22591175138950348, 0.4207035005092621, 0.3121090829372406, 0.3974546194076538, 0.3645910620689392, 0.6406720280647278, 0.3777332305908203, 0.7028002142906189, 0.665498673915863, 0.5218563675880432, 0.598818838596344, 0.30060556530952454, 0.4838988780975342, 0.23509633541107178, 0.22249363362789154, 0.2387869507074356, 0.2246941179037094, 0.20778992772102356, 0.19697828590869904, 0.19484621286392212, 0.19484630227088928, 0.2936210632324219, 0.19309791922569275, 0.2062077522277832, 0.20716898143291473, 0.20716898143291473, 0.18979541957378387, 0.18979550898075104, 0.21730008721351624, 0.20798154175281525, 0.1886925846338272, 0.1886925846338272, 0.18837480247020721, 0.24802452325820923, 0.29516470432281494, 0.23240523040294647, 0.2837033271789551, 0.22665710747241974, 0.18721997737884521, 0.1872200071811676, 0.1872200071811676, 0.1968568116426468, 0.19685684144496918, 0.25771844387054443, 0.2374652773141861, 0.2379225641489029, 0.3549218475818634, 0.3247291147708893, 0.3113122284412384, 0.28139108419418335, 0.2496684193611145], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -6.814599990844727, -6.7399001121521, -6.957900047302246, -6.971199989318848, -6.492499828338623, -7.011300086975098, -6.938399791717529, -7.155099868774414, -7.213600158691406, -7.073999881744385, -7.275100231170654, -6.485799789428711, -6.980299949645996, -7.3831000328063965, -7.252500057220459, -6.648900032043457, -7.425099849700928, -7.341100215911865, -7.1768999099731445, -7.2133002281188965, -7.478899955749512, -7.458600044250488, -7.441100120544434, -7.4959001541137695, -7.515600204467773, -7.535600185394287, -6.913000106811523, -7.5279998779296875, -7.245699882507324, -7.467199802398682, -6.648099899291992, -7.062300205230713, -7.115699768066406, -6.507900238037109, -7.035799980163574, -6.83620023727417, -7.214000225067139, -7.081699848175049, -6.8420000076293945, -6.526100158691406, -7.163400173187256, -7.047999858856201, -7.134699821472168, -7.0605998039245605, -7.123000144958496, -7.06879997253418, -7.126100063323975, -7.068600177764893, -6.8557000160217285, -6.9105000495910645, -6.981599807739258, -7.009399890899658, -6.821199893951416, -7.064899921417236, -7.122900009155273, -7.149499893188477, -7.116600036621094, -7.248000144958496, -7.30649995803833, -7.057799816131592, -7.284200191497803, -7.291600227355957, -7.273900032043457, -7.31790018081665, -6.907599925994873, -7.361000061035156, -7.4517998695373535, -7.459000110626221, -7.337699890136719, -7.4745001792907715, -7.105500221252441, -7.483699798583984, -7.305500030517578, -7.441100120544434, -7.497399806976318, -7.503399848937988, -7.155700206756592, -7.44189977645874, -6.741300106048584, -7.204100131988525, -6.853000164031982, -7.281199932098389, -7.04640007019043, -6.866199970245361, -6.937699794769287, -7.214799880981445, -7.13129997253418, -7.010300159454346, -7.123300075531006, -7.1381001472473145, -6.994900226593018, -7.124800205230713, -7.149499893188477, -7.204800128936768, -7.196800231933594, -7.201399803161621, -6.764999866485596, -7.174200057983398, -7.194300174713135, -7.215799808502197, -7.220900058746338, -7.177599906921387, -7.017000198364258, -7.044899940490723, -7.378499984741211, -7.043799877166748, -7.383800029754639, -7.230400085449219, -7.456299781799316, -7.355899810791016, -7.399499893188477, -7.477399826049805, -7.324999809265137, -7.335400104522705, -7.5177998542785645, -7.070799827575684, -7.29449987411499, -7.202700138092041, -7.316699981689453, -7.425600051879883, -7.583700180053711, -7.458600044250488, -7.582799911499023, -7.355000019073486, -7.667699813842773, -7.6041998863220215, -7.4278998374938965, -6.894100189208984, -7.079899787902832, -7.198599815368652, -7.307000160217285, -6.562399864196777, -6.858099937438965, -7.281300067901611, -7.167500019073486, -7.2758002281188965, -7.213600158691406, -7.082900047302246, -7.223400115966797, -7.182400226593018, -7.261099815368652, -7.248000144958496, -7.24970006942749, -6.8917999267578125, -7.010499954223633, -7.079699993133545, -7.142099857330322, -7.100200176239014, -7.1743998527526855, -7.208199977874756, -7.40339994430542, -7.31689977645874, -7.458199977874756, -7.470300197601318, -7.216800212860107, -7.49399995803833, -7.5304999351501465, -7.541600227355957, -7.541600227355957, -6.999100208282471, -7.063899993896484, -7.634699821472168, -7.672699928283691, -7.6971001625061035, -7.702099800109863, -7.702600002288818, -7.702600002288818, -7.702600002288818, -7.702700138092041, -6.948599815368652, -7.721199989318848, -7.721199989318848, -7.72130012512207, -7.1539998054504395, -7.288899898529053, -7.610499858856201, -7.3815999031066895, -7.340400218963623, -7.486299991607666, -7.254700183868408, -6.815299987792969, -7.3277997970581055, -7.0584001541137695, -7.0696001052856445, -6.720200061798096, -6.862599849700928, -7.353899955749512, -7.28980016708374, -7.276500225067139, -7.366499900817871, -7.3846001625061035, -7.342899799346924, -7.356100082397461, -6.780700206756592, -6.873199939727783, -6.933000087738037, -6.798600196838379, -7.059100151062012, -7.065700054168701, -7.063499927520752, -7.10830020904541, -7.124800205230713, -7.155099868774414, -7.155099868774414, -6.754499912261963, -7.040800094604492, -7.217199802398682, -7.19320011138916, -7.2754998207092285, -7.222700119018555, -7.3414998054504395, -7.4257001876831055, -7.260900020599365, -7.358799934387207, -7.430500030517578, -7.207699775695801, -7.443600177764893, -7.445700168609619, -7.445700168609619, -7.450399875640869, -7.450399875640869, -7.47130012512207, -7.2153000831604, -6.5802001953125, -6.762599945068359, -6.724100112915039, -6.997200012207031, -7.321199893951416, -6.874899864196777, -7.296999931335449, -7.420000076293945, -6.9029998779296875, -6.943699836730957, -7.046299934387207, -7.052800178527832, -7.079699993133545, -7.221399784088135, -7.221399784088135, -7.070300102233887, -7.372399806976318, -7.372399806976318, -7.385300159454346, -7.339600086212158, -7.440499782562256, -7.2779998779296875, -7.44950008392334, -7.464399814605713, -7.464600086212158, -7.169899940490723, -7.400700092315674, -6.894499778747559, -7.486800193786621, -7.503699779510498, -7.503699779510498, -7.518799781799316, -7.518799781799316, -7.552599906921387, -7.586599826812744, -7.445899963378906, -7.477399826049805, -7.411900043487549, -7.175600051879883, -7.006999969482422, -7.428800106048584, -7.223999977111816, -7.327199935913086, -7.2332000732421875, -7.368899822235107, -7.319399833679199, -7.3541998863220215, -7.408999919891357, -7.439199924468994, -6.921599864959717, -6.921599864959717, -6.953100204467773, -7.00629997253418, -7.00629997253418, -6.864299774169922, -7.2256999015808105, -7.366199970245361, -7.438899993896484, -7.452000141143799, -7.485199928283691, -7.397299766540527, -7.213600158691406, -7.550000190734863, -7.4704999923706055, -7.51140022277832, -7.301700115203857, -7.58519983291626, -7.664599895477295, -7.7027997970581055, -7.111400127410889, -7.385700225830078, -7.7347002029418945, -7.7418999671936035, -7.7683000564575195, -7.763400077819824, -7.785099983215332, -7.785099983215332, -7.785099983215332, -7.763400077819824, -7.699100017547607, -7.706699848175049, -7.361400127410889, -7.583899974822998, -6.876800060272217, -7.008399963378906, -7.0524001121521, -7.186299800872803, -7.177199840545654, -7.471799850463867, -7.17080020904541, -7.261099815368652, -7.52810001373291, -7.505899906158447, -7.436800003051758, -7.360799789428711, -7.4558000564575195, -7.481800079345703, -7.483699798583984, -6.619999885559082, -7.000699996948242, -7.083199977874756, -7.005199909210205, -7.134900093078613, -7.190299987792969, -6.791500091552734, -7.109300136566162, -7.240300178527832, -7.203700065612793, -7.306099891662598, -7.313399791717529, -7.2480998039245605, -7.2393999099731445, -7.286799907684326, -7.301400184631348, -7.114799976348877, -7.000400066375732, -7.384900093078613, -7.393899917602539, -7.40339994430542, -7.1149001121521, -7.115799903869629, -7.442699909210205, -7.28249979019165, -7.499199867248535, -7.499199867248535, -7.064599990844727, -7.283100128173828, -7.612599849700928, -7.183199882507324, -7.2621002197265625, -7.298399925231934, -7.292399883270264, -7.335899829864502, -7.3734002113342285, -6.932700157165527, -6.8815999031066895, -7.027100086212158, -7.2469000816345215, -7.2617998123168945, -7.317800045013428, -7.217899799346924, -6.91949987411499, -7.343800067901611, -7.374300003051758, -7.429599761962891, -7.072500228881836, -7.4807000160217285, -7.4807000160217285, -7.5619001388549805, -7.56220006942749, -7.394599914550781, -7.48859977722168, -7.633900165557861, -7.582900047302246, -7.384099960327148, -7.582900047302246, -7.64709997177124, -7.586699962615967, -7.367000102996826, -7.620299816131592, -7.754000186920166, -7.496300220489502, -7.55079984664917, -7.660299777984619, -7.121300220489502, -7.390500068664551, -7.2677001953125, -7.332699775695801, -7.080599784851074, -7.394499778747559, -7.274700164794922, -7.302700042724609, -7.429599761962891, -7.417500019073486, -7.522299766540527, -7.481200218200684, -6.665599822998047, -6.869800090789795, -6.827099800109863, -6.994900226593018, -7.1768999099731445, -7.483699798583984, -7.557199954986572, -7.557199954986572, -7.197500228881836, -7.622300148010254, -7.656499862670898, -7.656499862670898, -7.656499862670898, -7.75629997253418, -7.75629997253418, -7.654900074005127, -7.707399845123291, -7.8059000968933105, -7.8059000968933105, -7.820400238037109, -7.557600021362305, -7.384399890899658, -7.642499923706055, -7.449699878692627, -7.677800178527832, -7.876800060272217, -7.876800060272217, -7.876800060272217, -7.835999965667725, -7.835999965667725, -7.587600231170654, -7.672100067138672, -7.684299945831299, -7.520599842071533, -7.583099842071533, -7.6834001541137695, -7.7108001708984375, -7.760000228881836], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.2415000200271606, 1.2265000343322754, 1.186400055885315, 1.1634000539779663, 1.1576000452041626, 1.1368000507354736, 1.1312999725341797, 1.0827000141143799, 1.0757999420166016, 1.0642999410629272, 1.0413000583648682, 1.0400999784469604, 1.0148999691009521, 0.9934999942779541, 0.9865999817848206, 0.9757999777793884, 0.972000002861023, 0.9621000289916992, 0.9584000110626221, 0.9538999795913696, 0.9437999725341797, 0.9434999823570251, 0.9426000118255615, 0.9347000122070312, 0.9241999983787537, 0.9020000100135803, 0.9004999995231628, 0.8968999981880188, 0.8955000042915344, 0.8901000022888184, 0.8629999756813049, 0.8701000213623047, 0.8652999997138977, 0.7598999738693237, 0.8256000280380249, 0.7605999708175659, 0.867900013923645, 0.8245000243186951, 0.73580002784729, 0.5960000157356262, 0.848800003528595, 0.7386000156402588, 0.8021000027656555, 0.5846999883651733, 0.7113000154495239, 0.5170999765396118, 0.6712999939918518, 0.3328000009059906, 1.406499981880188, 1.3568999767303467, 1.3446999788284302, 1.3305000066757202, 1.3202999830245972, 1.2754000425338745, 1.2705999612808228, 1.256100058555603, 1.2192000150680542, 1.2008999586105347, 1.1670000553131104, 1.164199948310852, 1.1533000469207764, 1.121899962425232, 1.1210999488830566, 1.0916999578475952, 1.0907000303268433, 1.0878000259399414, 1.0791000127792358, 1.0745999813079834, 1.0670000314712524, 1.0649000406265259, 1.0628000497817993, 1.0592000484466553, 1.0583000183105469, 1.0529999732971191, 1.0505000352859497, 1.0467000007629395, 1.0426000356674194, 1.0420000553131104, 0.7439000010490417, 0.9187999963760376, 0.7246999740600586, 0.9520999789237976, 0.7738000154495239, 0.6439999938011169, 0.6481999754905701, 0.8230999708175659, 0.7174999713897705, 0.5008000135421753, 0.6696000099182129, 0.6959999799728394, 0.4065000116825104, 0.5896000266075134, 0.6137999892234802, 0.7541000247001648, 0.6014999747276306, 0.49729999899864197, 1.301200032234192, 1.246999979019165, 1.23580002784729, 1.2237000465393066, 1.2080999612808228, 1.1943999528884888, 1.1747000217437744, 1.159999966621399, 1.128100037574768, 1.117400050163269, 1.111899971961975, 1.1090999841690063, 1.080199956893921, 1.061400055885315, 1.0507999658584595, 1.049299955368042, 1.0478999614715576, 1.044800043106079, 1.0413000583648682, 1.0322999954223633, 1.024399995803833, 1.0125000476837158, 1.0082999467849731, 1.003999948501587, 0.9987000226974487, 0.9887999892234802, 0.9761999845504761, 0.968500018119812, 0.9429000020027161, 0.9416999816894531, 0.9404000043869019, 0.888700008392334, 0.83160001039505, 0.8557999730110168, 0.8945000171661377, 0.5595999956130981, 0.6086999773979187, 0.8519999980926514, 0.7074999809265137, 0.8227999806404114, 0.6345999836921692, 0.31839999556541443, 0.6032999753952026, 0.41429999470710754, 0.6136000156402588, 0.45660001039505005, 0.01810000091791153, 1.4189000129699707, 1.3573999404907227, 1.294800043106079, 1.2853000164031982, 1.2688000202178955, 1.2668999433517456, 1.1546000242233276, 1.1294000148773193, 1.1028000116348267, 1.0946999788284302, 1.086899995803833, 1.0771000385284424, 1.0715999603271484, 1.0477999448776245, 1.0404000282287598, 1.0404000282287598, 1.023900032043457, 0.9865999817848206, 0.9781000018119812, 0.9520999789237976, 0.9351999759674072, 0.9318000078201294, 0.9314000010490417, 0.9314000010490417, 0.9314000010490417, 0.9314000010490417, 0.9261000156402588, 0.91839998960495, 0.91839998960495, 0.91839998960495, 0.9120000004768372, 0.9089999794960022, 0.9143000245094299, 0.897599995136261, 0.8794999718666077, 0.8985000252723694, 0.8079000115394592, 0.6516000032424927, 0.8032000064849854, 0.656000018119812, 0.6516000032424927, 0.4018000066280365, 0.4052000045776367, 0.707099974155426, 0.5853000283241272, 0.5101000070571899, 0.6388999819755554, 0.6348000168800354, 0.2818000018596649, 0.22169999778270721, 1.5615999698638916, 1.4902000427246094, 1.4780999422073364, 1.457800030708313, 1.4047000408172607, 1.4006999731063843, 1.3924000263214111, 1.375, 1.36489999294281, 1.3461999893188477, 1.3461999893188477, 1.3447999954223633, 1.3380000591278076, 1.3071999549865723, 1.274999976158142, 1.2446999549865723, 1.2285000085830688, 1.1741000413894653, 1.1698999404907227, 1.169700026512146, 1.1676000356674194, 1.166599988937378, 1.1638000011444092, 1.1576000452041626, 1.1562000513076782, 1.1562000513076782, 1.152899980545044, 1.152899980545044, 1.1385999917984009, 1.1376999616622925, 1.124400019645691, 1.020300030708313, 1.010200023651123, 0.9782999753952026, 1.0184999704360962, 0.24709999561309814, 0.8305000066757202, 0.597100019454956, 1.5217000246047974, 1.4531999826431274, 1.436400055885315, 1.4323999881744385, 1.4157999753952026, 1.3253999948501587, 1.3253999948501587, 1.2888000011444092, 1.2242000102996826, 1.2242000102996826, 1.2152999639511108, 1.2064000368118286, 1.176900029182434, 1.1730999946594238, 1.1706000566482544, 1.160099983215332, 1.159999966621399, 1.159500002861023, 1.1514999866485596, 1.145799994468689, 1.1442999839782715, 1.132200002670288, 1.132200002670288, 1.121399998664856, 1.121399998664856, 1.097000002861023, 1.0722999572753906, 1.0684000253677368, 1.0641000270843506, 1.0625, 1.051200032234192, 0.8267999887466431, 1.0305999517440796, 0.6660000085830688, 0.774399995803833, 0.39149999618530273, 0.6937000155448914, 0.22030000388622284, 0.367000013589859, 0.6845999956130981, 0.39640000462532043, 1.561900019645691, 1.561900019645691, 1.542199969291687, 1.5083999633789062, 1.5083999633789062, 1.3948999643325806, 1.3624000549316406, 1.2532999515533447, 1.2005000114440918, 1.1864999532699585, 1.1764999628067017, 1.1710000038146973, 1.1390999555587769, 1.1279000043869019, 1.094099998474121, 1.080299973487854, 1.0606000423431396, 1.048799991607666, 1.0401999950408936, 1.0104999542236328, 0.9916999936103821, 0.9915000200271606, 0.9854000210762024, 0.9746000170707703, 0.958899974822998, 0.9472000002861023, 0.9455999732017517, 0.9455999732017517, 0.9455999732017517, 0.9417999982833862, 0.9399999976158142, 0.9345999956130981, 0.8812999725341797, 0.864300012588501, 0.5246000289916992, 0.5313000082969666, 0.5059000253677368, 0.5769000053405762, 0.5214999914169312, 0.742900013923645, 0.35519999265670776, 0.3889000117778778, 0.7735999822616577, 0.718999981880188, 0.5175999999046326, 0.10599999874830246, 0.450300008058548, 0.4936999976634979, 0.31679999828338623, 1.781499981880188, 1.544700026512146, 1.4889999628067017, 1.4607000350952148, 1.4534000158309937, 1.4144999980926514, 1.4063999652862549, 1.384600043296814, 1.3353999853134155, 1.332800030708313, 1.3314000368118286, 1.3259999752044678, 1.319000005722046, 1.3142000436782837, 1.3042999505996704, 1.2934999465942383, 1.2882000207901, 1.2788000106811523, 1.2732000350952148, 1.2664999961853027, 1.2594000101089478, 1.2553999423980713, 1.2315000295639038, 1.2297999858856201, 1.2187000513076782, 1.1868000030517578, 1.1868000030517578, 1.1603000164031982, 1.100100040435791, 1.0987000465393066, 1.0240000486373901, 0.9578999876976013, 0.8288000226020813, 0.421999990940094, 0.47749999165534973, 0.1526000052690506, 1.6527999639511108, 1.5764000415802002, 1.5133999586105347, 1.4220999479293823, 1.4106999635696411, 1.3622000217437744, 1.3444000482559204, 1.3396999835968018, 1.3005000352859497, 1.2969000339508057, 1.2795000076293945, 1.2697999477386475, 1.238700032234192, 1.238700032234192, 1.1705000400543213, 1.1700999736785889, 1.1654000282287598, 1.1449999809265137, 1.113800048828125, 1.1136000156402588, 1.1087000370025635, 1.106600046157837, 1.1028000116348267, 1.0824999809265137, 1.0772000551223755, 1.0242999792099, 1.0134999752044678, 0.9898999929428101, 0.9829999804496765, 0.9598000049591064, 0.8769999742507935, 0.9064000248908997, 0.7874000072479248, 0.8087000250816345, 0.49709999561309814, 0.7114999890327454, 0.21040000021457672, 0.2370000034570694, 0.3531999886035919, 0.22779999673366547, 0.8120999932289124, 0.37709999084472656, 1.9146000146865845, 1.7654999494552612, 1.7375999689102173, 1.6305999755859375, 1.5268000364303589, 1.2733999490737915, 1.210800051689148, 1.210800051689148, 1.1604000329971313, 1.1548000574111938, 1.054800033569336, 1.0501999855041504, 1.0501999855041504, 1.0379999876022339, 1.0379999876022339, 1.003999948501587, 0.9954000115394592, 0.9941999912261963, 0.9941999912261963, 0.9814000129699707, 0.9690999984741211, 0.9682000279426575, 0.9491999745368958, 0.9426000118255615, 0.9390000104904175, 0.9312000274658203, 0.9312000274658203, 0.9312000274658203, 0.9218000173568726, 0.9218000173568726, 0.9007999897003174, 0.8981000185012817, 0.8840000033378601, 0.6477000117301941, 0.6740999817848206, 0.6159999966621399, 0.6897000074386597, 0.7601000070571899]}, \"token.table\": {\"Topic\": [], \"Freq\": [], \"Term\": []}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [6, 8, 10, 2, 3, 4, 5, 1, 7, 9]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el1241404474137013923365459731\", ldavis_el1241404474137013923365459731_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el1241404474137013923365459731\", ldavis_el1241404474137013923365459731_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el1241404474137013923365459731\", ldavis_el1241404474137013923365459731_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ],
            "text/plain": [
              "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
              "topic                                                \n",
              "5      0.023490 -0.002744       1        1  18.270704\n",
              "7      0.001718  0.020211       2        1  12.853691\n",
              "9     -0.000333 -0.007589       3        1  12.725726\n",
              "1     -0.000992 -0.007941       4        1  12.033597\n",
              "2     -0.006427 -0.000536       5        1   9.875732\n",
              "3     -0.005494 -0.002243       6        1   9.204123\n",
              "4     -0.000341  0.001649       7        1   7.941736\n",
              "0     -0.003907 -0.000223       8        1   7.130217\n",
              "6     -0.003523  0.001190       9        1   5.687336\n",
              "8     -0.004192 -0.001774      10        1   4.277136, topic_info=          Term      Freq     Total Category  logprob  loglift\n",
              "4519     dubey  0.000000  0.000000  Default  30.0000  30.0000\n",
              "5740  tallulah  0.000000  0.000000  Default  29.0000  29.0000\n",
              "2533      exam  0.000000  0.000000  Default  28.0000  28.0000\n",
              "4099      coal  0.000000  0.000000  Default  27.0000  27.0000\n",
              "1581     board  0.000000  0.000000  Default  26.0000  26.0000\n",
              "...        ...       ...       ...      ...      ...      ...\n",
              "164      point  0.029013  0.354922  Topic10  -7.5206   0.6477\n",
              "1851    season  0.027254  0.324729  Topic10  -7.5831   0.6741\n",
              "1239  district  0.024654  0.311312  Topic10  -7.6834   0.6160\n",
              "700   signific  0.023989  0.281391  Topic10  -7.7108   0.6897\n",
              "941       draw  0.022837  0.249668  Topic10  -7.7600   0.7601\n",
              "\n",
              "[467 rows x 6 columns], token_table=Empty DataFrame\n",
              "Columns: [Topic, Freq, Term]\n",
              "Index: [], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[6, 8, 10, 2, 3, 4, 5, 1, 7, 9])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Adb8Hgpod4oH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mallet_path = 'mallet-2.0.8/bin/mallet' # update this path\n",
        "ldamallet_tf_idf = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus_tfidf, num_topics=10, id2word=dictionary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqRRPEfgd4mC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For each topic, we will explore the words occuring in that topic and its relative weight.\n",
        "for idx, topic in ldamallet_tf_idf.show_topics(formatted=False):\n",
        "    print('Topic: {} \\nWords: {}'.format(idx, topic))\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmuxVke4eL1A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute Perplexity\n",
        "#print('\\nPerplexity: ', lda_model_tf_idf.log_perplexity(corpus_tfidf))  # a measure of how good the model is. lower the better.\n",
        "\n",
        "# Compute Coherence Score\n",
        "coherence_model_lda = CoherenceModel(model=ldamallet_tf_idf, texts=processed_docs, dictionary=dictionary, coherence='c_v')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6uNjQh2eLx1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualize the topics\n",
        "# pyLDAvis.enable_notebook()\n",
        "# vis = pyLDAvis.gensim.prepare(ldamallet_tf_idf, corpus_tfidf, dictionary)\n",
        "# vis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBk_7x7AeLv-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
        "    \"\"\"\n",
        "    Compute c_v coherence for various number of topics\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    dictionary : Gensim dictionary\n",
        "    corpus : Gensim corpus\n",
        "    texts : List of input texts\n",
        "    limit : Max num of topics\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "    model_list : List of LDA topic models\n",
        "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
        "    \"\"\"\n",
        "    coherence_values = []\n",
        "    model_list = []\n",
        "    for num_topics in range(start, limit, step):\n",
        "        model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=dictionary)\n",
        "        model_list.append(model)\n",
        "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
        "        coherence_values.append(coherencemodel.get_coherence())\n",
        "\n",
        "    return model_list, coherence_values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-O7NwMckeZSJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_list, coherence_values = compute_coherence_values(dictionary=dictionary, corpus=bow_corpus, texts=processed_docs, start=2, limit=40, step=6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VChSS1fEeZPJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show graph\n",
        "limit=40; start=2; step=6;\n",
        "x = range(start, limit, step)\n",
        "plt.plot(x, coherence_values)\n",
        "plt.xlabel(\"Num Topics\")\n",
        "plt.ylabel(\"Coherence score\")\n",
        "plt.legend((\"coherence_values\"), loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IA8LmPUfeZNU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print the coherence scores\n",
        "for m, cv in zip(x, coherence_values):\n",
        "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6yondOneiCm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Select the model and print the topics\n",
        "optimal_model = model_list[2]\n",
        "model_topics = optimal_model.show_topics(formatted=False)\n",
        "print(optimal_model.print_topics(num_words=10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeVOKrEveh-a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#finding the dominant topic in each sentence\n",
        "# de-tokenization\n",
        "detokenized_doc = []\n",
        "for text in processed_docs:\n",
        "    t = ' '.join(text)\n",
        "    detokenized_doc.append(t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSXKuhdWeh9M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def format_topics_sentences(ldamodel=lda_model, corpus=bow_corpus, texts=detokenized_doc):\n",
        "\n",
        "    # Init output\n",
        "    sent_topics_df = pd.DataFrame()\n",
        "\n",
        "    # Get main topic in each document\n",
        "    for i, row in enumerate(ldamodel[corpus]):\n",
        "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
        "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
        "        for j, (topic_num, prop_topic) in enumerate(row):\n",
        "            if j == 0:  # => dominant topic\n",
        "                wp = ldamodel.show_topic(topic_num)\n",
        "                topic_keywords = \", \".join([word for word, prop in wp])\n",
        "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
        "            else:\n",
        "                break\n",
        "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
        "\n",
        "    # Add original text to the end of the output\n",
        "    contents = pd.Series(texts)\n",
        "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
        "    return(sent_topics_df)\n",
        "\n",
        "\n",
        "df_topic_sents_keywords = format_topics_sentences(ldamodel=optimal_model, corpus=bow_corpus, texts=detokenized_doc)\n",
        "\n",
        "# Format\n",
        "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
        "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
        "\n",
        "# Show\n",
        "df_dominant_topic.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1E6vpGj4fJCH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Find the most representative document for each topic\n",
        "# Group top 5 sentences under each topic\n",
        "sent_topics_sorteddf_mallet = pd.DataFrame()\n",
        "\n",
        "sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
        "\n",
        "for i, grp in sent_topics_outdf_grpd:\n",
        "    sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet, \n",
        "                                             grp.sort_values(['Perc_Contribution'], ascending=[0]).head(1)], \n",
        "                                            axis=0)\n",
        "\n",
        "# Reset Index    \n",
        "sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Format\n",
        "sent_topics_sorteddf_mallet.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Text\"]\n",
        "\n",
        "# Show\n",
        "sent_topics_sorteddf_mallet.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fg7BnX-nfI-p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Topic distribution across documents\n",
        "# Number of Documents for Each Topic\n",
        "topic_counts = df_topic_sents_keywords['Dominant_Topic'].value_counts()\n",
        "\n",
        "# Percentage of Documents for Each Topic\n",
        "topic_contribution = round(topic_counts/topic_counts.sum(), 4)\n",
        "\n",
        "# Topic Number and Keywords\n",
        "topic_num_keywords = df_topic_sents_keywords[['Dominant_Topic', 'Topic_Keywords']]\n",
        "\n",
        "# Concatenate Column wise\n",
        "df_dominant_topics = pd.concat([topic_num_keywords, topic_counts, topic_contribution], axis=1)\n",
        "\n",
        "# Change Column names\n",
        "df_dominant_topics.columns = ['Dominant_Topic', 'Topic_Keywords', 'Num_Documents', 'Perc_Documents']\n",
        "\n",
        "# Show\n",
        "df_dominant_topics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nk4UM9ryfI8R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Latent Sentiment Analysis\n",
        "# Document Term Matrix\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(stop_words='english', \n",
        "max_features= 1000, # keep top 1000 terms \n",
        "max_df = 0.5, \n",
        "smooth_idf=True)\n",
        "\n",
        "X = vectorizer.fit_transform(detokenized_doc)\n",
        "\n",
        "X.shape # check shape of the document-term matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iM5I4kNgfI5v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "# SVD represent documents and terms in vectors \n",
        "svd_model = TruncatedSVD(n_components=20, algorithm='randomized', n_iter=100, random_state=122)\n",
        "\n",
        "svd_model.fit(X)\n",
        "\n",
        "len(svd_model.components_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xi7SCi3Hfv2i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The components of svd_model are our topics, and we can access them using svdmodel.components. \n",
        "#Finally, let’s print a few most important words in each of the 20 topics and see how our model has done"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sQ1c59xfvy4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "terms = vectorizer.get_feature_names()\n",
        "\n",
        "for i, comp in enumerate(svd_model.components_):\n",
        "    terms_comp = zip(terms, comp)\n",
        "    sorted_terms = sorted(terms_comp, key= lambda x:x[1], reverse=True)[:7]\n",
        "    print(\"Topic \"+str(i)+\": \")\n",
        "    for t in sorted_terms:\n",
        "        print(t[0])\n",
        "        print(\" \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bo84SOZufvwn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Topics Visualization\n",
        "import umap.umap_ as umap\n",
        "\n",
        "X_topics = svd_model.fit_transform(X)\n",
        "embedding = umap.UMAP(n_neighbors=150, min_dist=0.5, random_state=12).fit_transform(X_topics)\n",
        "\n",
        "plt.figure(figsize=(7,5))\n",
        "plt.scatter(embedding[:, 0], embedding[:, 1], \n",
        "c = dataset.target,\n",
        "s = 10, # size\n",
        "edgecolor='none'\n",
        ")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}