{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Topic_modeling and text_clustering.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJoWX-SHqODB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "import gensim\n",
        "from gensim import corpora,models\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models import CoherenceModel\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
        "from nltk.stem.porter import *\n",
        "import numpy as np\n",
        "np.random.seed(2018)\n",
        "\n",
        "#!pip install pyLDAvis\n",
        "\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim \n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Enable logging for gensim - optional\n",
        "import logging\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
        "\n",
        "#import warnings\n",
        "#warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RneP_reKNV00",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this will slove broken link issue with nltk using ssl.\n",
        "#import ssl\n",
        "#try:\n",
        "#    _create_unverified_https_context = ssl._create_unverified_context\n",
        "#except AttributeError:\n",
        "#    pass\n",
        "#else:\n",
        "#    ssl._create_default_https_context = _create_unverified_https_context"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5L5AIMlZ2hoo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "cb91263f-ab89-4f09-edb1-d07ecfe054f9"
      },
      "source": [
        "import nltk\n",
        "#nltk.download('wordnet')\n",
        "#nltk.download('stopwords')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJa95bXeDLH3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oh-Vw6uA2hks",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv('/content/drive/My Drive/cut.csv');"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSoWwYeuGCWM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "674d6027-961d-424d-ee33-64928b0993d5"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBVVZIpe2hjX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data preprocessing\n",
        "stemmer = SnowballStemmer(language='english',ignore_stopwords=True)\n",
        "def lemmatize_stemming(text):\n",
        "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
        "def preprocess(text):\n",
        "    result = []\n",
        "    for token in gensim.utils.simple_preprocess(text):\n",
        "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
        "            result.append(lemmatize_stemming(token))\n",
        "    return result"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIfyn-R72hgb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "15f57480-2271-4977-8ad1-c14ff47a3ea3"
      },
      "source": [
        "# preview after preprocessing\n",
        "doc_sample = data.content[0]\n",
        "print('original document: ')\n",
        "words = []\n",
        "for word in doc_sample.split(' '):\n",
        "    words.append(word)\n",
        "print(words)\n",
        "print('\\n\\n tokenized and lemmatized document: ')\n",
        "print(preprocess(doc_sample))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "original document: \n",
            "['[\"The', 'Video', 'Assistant', 'Referee', '(VAR)', 'system', 'is', 'not', 'being', 'used', 'correctly', 'in', 'La', 'Liga,', 'Barcelona', 'manager', 'Quique', 'Setien', 'said', 'on', 'Monday', 'following', 'Real', 'Madrid’s', 'controversial', 'win', 'at', 'Real', 'Sociedad.\",\"Madrid', 'beat', 'Sociedad', '2-1', 'to', 'climb', 'above', 'Barcelona', 'at', 'the', 'top', 'of', 'La', 'Liga', 'but', 'the', 'home', 'side', 'were', 'aggrieved', 'because', 'they', 'had', 'a', 'goal', 'ruled', 'out', 'by', 'VAR', 'for', 'offside', 'and', 'Karim', 'Benzema’s', 'winner', 'stood', 'after', 'he', 'appeared', 'to', 'control', 'the', 'ball', 'with', 'his', 'arm.\",\"“There', 'are', 'things', 'that', 'we', 'cannot', 'control', 'and', 'that', 'do', 'not', 'depend', 'on', 'us.', 'Everybody', 'saw', 'what', 'happened', 'in', 'Anoeta', 'and', 'everyone', 'will', 'draw', 'their', 'own', 'conclusions,”', 'Setien', 'told', 'reporters', 'ahead', 'of', 'Tuesday’s', 'match', 'against', 'Athletic', 'Bilbao.\",\"“It’s', 'understandable', 'that', 'we', 'think', 'why', 'there', 'are', 'some', 'actions', 'that', 'are', 'reviewed,', 'the', 'referee', 'himself', 'reviews', 'them', 'and', 'they', 'don’t', 'do', 'the', 'same', 'in', 'other', 'plays.', 'They', 'do', 'it', 'on', 'some', 'matches', 'and', 'in', 'some', 'others', '(they', 'don’t).', 'So', 'you', 'could', 'really', 'think', 'that', '(VAR)', 'is', 'not', 'being', 'used', 'correctly.”\",\"Setien', 'said', 'controversies', 'were', 'part', 'of', 'football.', '“We’ve', 'been', 'here', 'for', 'many', 'years', 'and', 'this', 'doesn’t', 'change.', 'It’s', 'always', 'the', 'same,', 'the', 'controversy', 'will', 'always', 'be', 'there,”', 'he', 'added.', '“VAR', 'is', 'a', 'tool', 'that', 'can', 'make', 'us', 'better,', 'but', 'we', 'have', 'to', 'use', 'it', 'to', 'have', 'a', 'clearer', 'view', 'of', 'reality.”\",\"With', '65', 'points', 'each,', 'Real', 'top', 'the', 'standings', 'due', 'to', 'a', 'superior', 'head-to-head', 'record', 'but', 'Setien', 'is', 'convinced', 'the', 'title', 'race', 'is', 'still', 'in', 'Barcelona’s', 'hands.', '“Now', 'the', 'margin', 'of', 'error', 'is', 'smaller,', 'but', 'it’s', 'also', 'smaller', 'for', 'them,”', 'he', 'said.', '“Madrid', 'cannot', 'make', 'any', 'mistakes.', 'Many', 'leagues', 'are', 'decided', 'in', 'the', 'end,', 'there', 'are', 'eight', 'games', 'left.', 'Madrid', 'still', 'have', 'to', 'play', 'difficult', 'games', 'like', 'us.”\"]']\n",
            "\n",
            "\n",
            " tokenized and lemmatized document: \n",
            "['video', 'assist', 'refere', 'correct', 'liga', 'barcelona', 'manag', 'quiqu', 'setien', 'say', 'monday', 'follow', 'real', 'madrid', 'controversi', 'real', 'sociedad', 'madrid', 'beat', 'sociedad', 'climb', 'barcelona', 'liga', 'home', 'aggriev', 'goal', 'rule', 'offsid', 'karim', 'benzema', 'winner', 'stand', 'appear', 'control', 'ball', 'thing', 'control', 'depend', 'everybodi', 'happen', 'anoeta', 'draw', 'conclus', 'setien', 'tell', 'report', 'ahead', 'tuesday', 'match', 'athlet', 'bilbao', 'understand', 'think', 'action', 'review', 'refere', 'review', 'play', 'match', 'think', 'correct', 'setien', 'say', 'controversi', 'footbal', 'year', 'chang', 'controversi', 'add', 'tool', 'better', 'clearer', 'view', 'realiti', 'point', 'real', 'stand', 'superior', 'head', 'head', 'record', 'setien', 'convinc', 'titl', 'race', 'barcelona', 'hand', 'margin', 'error', 'smaller', 'smaller', 'say', 'madrid', 'mistak', 'leagu', 'decid', 'game', 'leav', 'madrid', 'play', 'difficult', 'game', 'like']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIVgkjVL2hec",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "8f2ec0bd-79f0-4d6e-ba0f-dd384b7225ac"
      },
      "source": [
        "# Preprocess the headline text, saving the results as ‘processed_docs’\n",
        "processed_docs = data['processed_content']\n",
        "processed_docs.head(4)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    video assist refere correct liga barcelona man...\n",
              "1    jose mourinho launch impass defenc harri kane ...\n",
              "2    alvaro morata score twice lead atletico madrid...\n",
              "3    despit abl lead india trophi sole india joint ...\n",
              "Name: processed_content, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQhU10ZPcb7c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "dc490eac-0307-4407-942a-c0e09d35ec94"
      },
      "source": [
        "#Create a dictionary from ‘processed_docs’ containing the number of times a word appears in the training set\n",
        "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
        "count = 0\n",
        "for k, v in dictionary.iteritems():\n",
        "    print(k, v)\n",
        "    count += 1\n",
        "    if count > 10:\n",
        "        break"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-623d1e04216a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Create a dictionary from ‘processed_docs’ containing the number of times a word appears in the training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdictionary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpora\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_docs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/corpora/dictionary.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, documents, prune_at)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdocuments\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprune_at\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprune_at\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/corpora/dictionary.py\u001b[0m in \u001b[0;36madd_documents\u001b[0;34m(self, documents, prune_at)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0;31m# update Dictionary with the document\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc2bow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_update\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# ignore the result, here we only care about updating token ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         logger.info(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/corpora/dictionary.py\u001b[0m in \u001b[0;36mdoc2bow\u001b[0;34m(self, document, allow_update, return_missing)\u001b[0m\n\u001b[1;32m    238\u001b[0m         \"\"\"\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"doc2bow expects an array of unicode tokens on input, not a single string\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;31m# Construct (word, frequency) mapping.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: doc2bow expects an array of unicode tokens on input, not a single string"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqIPcn6Ccb5E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9H40fDHXcb1v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# gensim doc2bow\n",
        "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
        "bow_corpus[4310]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFx_Ifpccb0M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preview Bag Of Words for our sample preprocessed document.\n",
        "bow_doc_4310 = bow_corpus[4310]\n",
        "for i in range(len(bow_doc_4310)):\n",
        "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_4310[i][0], \n",
        "                                               dictionary[bow_doc_4310[i][0]], \n",
        "bow_doc_4310[i][1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99zK3Yr_cwbC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tf-idf\n",
        "tfidf = models.TfidfModel(bow_corpus)\n",
        "corpus_tfidf = tfidf[bow_corpus]\n",
        "for doc in corpus_tfidf:\n",
        "    print(doc)\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6GnOwb7cwYN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#LDA using Bag of Words\n",
        "# # Build LDA model\n",
        "# lda_model = gensim.models.ldamodel.LdaModel(corpus=bow_corpus,\n",
        "#                                            id2word=dictionary,\n",
        "#                                            num_topics=10, \n",
        "#                                            random_state=100,\n",
        "#                                            update_every=1,\n",
        "#                                            chunksize=100,\n",
        "#                                            passes=10,\n",
        "#                                            alpha='auto',\n",
        "#                                            per_word_topics=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_6-wc--cwVK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train our lda model using gensim.models.LdaMulticore and save it to ‘lda_model’\n",
        "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=2, workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erHOC2BlcwTe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For each topic, we will explore the words occuring in that topic and its relative weight.\n",
        "for idx, topic in lda_model.print_topics(-1):\n",
        "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFs6ggNWdTL3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute Perplexity\n",
        "print('\\nPerplexity: ', lda_model.log_perplexity(bow_corpus))  # a measure of how good the model is. lower the better.\n",
        "\n",
        "# Compute Coherence Score\n",
        "coherence_model_lda = CoherenceModel(model=lda_model, texts=processed_docs, dictionary=dictionary, coherence='c_v')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJwQSyH1dTI3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualize the topics\n",
        "pyLDAvis.enable_notebook()\n",
        "vis = pyLDAvis.gensim.prepare(lda_model, bow_corpus, dictionary)\n",
        "vis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1Kg6NCqdTG6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Gensim provides a wrapper to implement Mallet’s LDA from within Gensim itself. \n",
        "#You only need to download the zipfile, unzip it and provide the path to mallet in the unzipped directory to gensim.models.wrappers.LdaMallet\n",
        "# Download File: http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\n",
        "! wget http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5jbFJB3drRq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mallet_path = 'mallet-2.0.8/bin/mallet' # update this path\n",
        "ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=bow_corpus, num_topics=10, id2word=dictionary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geqY3dmvdrON",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For each topic, we will explore the words occuring in that topic and its relative weight.\n",
        "for idx, topic in ldamallet.show_topics(formatted=False):\n",
        "    print('Topic: {} \\nWords: {}'.format(idx, topic))\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_05-tF4WdrMs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute Perplexity\n",
        "# print('\\nPerplexity: ', ldamallet.log_perplexity(bow_corpus))  # a measure of how good the model is. lower the better.\n",
        "\n",
        "# Compute Coherence Score\n",
        "coherence_model_ldamallet = CoherenceModel(model=ldamallet, texts=processed_docs, dictionary=dictionary, coherence='c_v')\n",
        "coherence_ldamallet = coherence_model_ldamallet.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_ldamallet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93iGDnAgdrJu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualize the topics\n",
        "# pyLDAvis.enable_notebook()\n",
        "# vis = pyLDAvis.gensim.prepare(ldamallet, bow_corpus, dictionary)\n",
        "# vis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfXwqy3ydrHt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train our lda model using gensim.models.LdaMulticore and save it to ‘lda_model’\n",
        "lda_model_tf_idf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=dictionary, passes=2, workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EH2jyG8Ad4ty",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For each topic, we will explore the words occuring in that topic and its relative weight.\n",
        "for idx, topic in lda_model_tf_idf.print_topics(-1):\n",
        "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fd6CRYegd4qz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute Perplexity\n",
        "print('\\nPerplexity: ', lda_model_tf_idf.log_perplexity(corpus_tfidf))  # a measure of how good the model is. lower the better.\n",
        "\n",
        "# Compute Coherence Score\n",
        "coherence_model_lda = CoherenceModel(model=lda_model_tf_idf, texts=processed_docs, dictionary=dictionary, coherence='c_v')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda)\n",
        "\n",
        "# Visualize the topics\n",
        "pyLDAvis.enable_notebook()\n",
        "vis = pyLDAvis.gensim.prepare(lda_model_tf_idf, corpus_tfidf, dictionary)\n",
        "vis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Adb8Hgpod4oH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mallet_path = 'mallet-2.0.8/bin/mallet' # update this path\n",
        "ldamallet_tf_idf = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus_tfidf, num_topics=10, id2word=dictionary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqRRPEfgd4mC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For each topic, we will explore the words occuring in that topic and its relative weight.\n",
        "for idx, topic in ldamallet_tf_idf.show_topics(formatted=False):\n",
        "    print('Topic: {} \\nWords: {}'.format(idx, topic))\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmuxVke4eL1A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute Perplexity\n",
        "#print('\\nPerplexity: ', lda_model_tf_idf.log_perplexity(corpus_tfidf))  # a measure of how good the model is. lower the better.\n",
        "\n",
        "# Compute Coherence Score\n",
        "coherence_model_lda = CoherenceModel(model=ldamallet_tf_idf, texts=processed_docs, dictionary=dictionary, coherence='c_v')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6uNjQh2eLx1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualize the topics\n",
        "# pyLDAvis.enable_notebook()\n",
        "# vis = pyLDAvis.gensim.prepare(ldamallet_tf_idf, corpus_tfidf, dictionary)\n",
        "# vis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBk_7x7AeLv-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
        "    \"\"\"\n",
        "    Compute c_v coherence for various number of topics\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    dictionary : Gensim dictionary\n",
        "    corpus : Gensim corpus\n",
        "    texts : List of input texts\n",
        "    limit : Max num of topics\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "    model_list : List of LDA topic models\n",
        "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
        "    \"\"\"\n",
        "    coherence_values = []\n",
        "    model_list = []\n",
        "    for num_topics in range(start, limit, step):\n",
        "        model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=dictionary)\n",
        "        model_list.append(model)\n",
        "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
        "        coherence_values.append(coherencemodel.get_coherence())\n",
        "\n",
        "    return model_list, coherence_values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-O7NwMckeZSJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_list, coherence_values = compute_coherence_values(dictionary=dictionary, corpus=bow_corpus, texts=processed_docs, start=2, limit=40, step=6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VChSS1fEeZPJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show graph\n",
        "limit=40; start=2; step=6;\n",
        "x = range(start, limit, step)\n",
        "plt.plot(x, coherence_values)\n",
        "plt.xlabel(\"Num Topics\")\n",
        "plt.ylabel(\"Coherence score\")\n",
        "plt.legend((\"coherence_values\"), loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IA8LmPUfeZNU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print the coherence scores\n",
        "for m, cv in zip(x, coherence_values):\n",
        "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6yondOneiCm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Select the model and print the topics\n",
        "optimal_model = model_list[2]\n",
        "model_topics = optimal_model.show_topics(formatted=False)\n",
        "print(optimal_model.print_topics(num_words=10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeVOKrEveh-a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#finding the dominant topic in each sentence\n",
        "# de-tokenization\n",
        "detokenized_doc = []\n",
        "for text in processed_docs:\n",
        "    t = ' '.join(text)\n",
        "    detokenized_doc.append(t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSXKuhdWeh9M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def format_topics_sentences(ldamodel=lda_model, corpus=bow_corpus, texts=detokenized_doc):\n",
        "\n",
        "    # Init output\n",
        "    sent_topics_df = pd.DataFrame()\n",
        "\n",
        "    # Get main topic in each document\n",
        "    for i, row in enumerate(ldamodel[corpus]):\n",
        "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
        "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
        "        for j, (topic_num, prop_topic) in enumerate(row):\n",
        "            if j == 0:  # => dominant topic\n",
        "                wp = ldamodel.show_topic(topic_num)\n",
        "                topic_keywords = \", \".join([word for word, prop in wp])\n",
        "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
        "            else:\n",
        "                break\n",
        "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
        "\n",
        "    # Add original text to the end of the output\n",
        "    contents = pd.Series(texts)\n",
        "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
        "    return(sent_topics_df)\n",
        "\n",
        "\n",
        "df_topic_sents_keywords = format_topics_sentences(ldamodel=optimal_model, corpus=bow_corpus, texts=detokenized_doc)\n",
        "\n",
        "# Format\n",
        "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
        "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
        "\n",
        "# Show\n",
        "df_dominant_topic.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1E6vpGj4fJCH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Find the most representative document for each topic\n",
        "# Group top 5 sentences under each topic\n",
        "sent_topics_sorteddf_mallet = pd.DataFrame()\n",
        "\n",
        "sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
        "\n",
        "for i, grp in sent_topics_outdf_grpd:\n",
        "    sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet, \n",
        "                                             grp.sort_values(['Perc_Contribution'], ascending=[0]).head(1)], \n",
        "                                            axis=0)\n",
        "\n",
        "# Reset Index    \n",
        "sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Format\n",
        "sent_topics_sorteddf_mallet.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Text\"]\n",
        "\n",
        "# Show\n",
        "sent_topics_sorteddf_mallet.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fg7BnX-nfI-p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Topic distribution across documents\n",
        "# Number of Documents for Each Topic\n",
        "topic_counts = df_topic_sents_keywords['Dominant_Topic'].value_counts()\n",
        "\n",
        "# Percentage of Documents for Each Topic\n",
        "topic_contribution = round(topic_counts/topic_counts.sum(), 4)\n",
        "\n",
        "# Topic Number and Keywords\n",
        "topic_num_keywords = df_topic_sents_keywords[['Dominant_Topic', 'Topic_Keywords']]\n",
        "\n",
        "# Concatenate Column wise\n",
        "df_dominant_topics = pd.concat([topic_num_keywords, topic_counts, topic_contribution], axis=1)\n",
        "\n",
        "# Change Column names\n",
        "df_dominant_topics.columns = ['Dominant_Topic', 'Topic_Keywords', 'Num_Documents', 'Perc_Documents']\n",
        "\n",
        "# Show\n",
        "df_dominant_topics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nk4UM9ryfI8R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Latent Sentiment Analysis\n",
        "# Document Term Matrix\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(stop_words='english', \n",
        "max_features= 1000, # keep top 1000 terms \n",
        "max_df = 0.5, \n",
        "smooth_idf=True)\n",
        "\n",
        "X = vectorizer.fit_transform(detokenized_doc)\n",
        "\n",
        "X.shape # check shape of the document-term matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iM5I4kNgfI5v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "# SVD represent documents and terms in vectors \n",
        "svd_model = TruncatedSVD(n_components=20, algorithm='randomized', n_iter=100, random_state=122)\n",
        "\n",
        "svd_model.fit(X)\n",
        "\n",
        "len(svd_model.components_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xi7SCi3Hfv2i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The components of svd_model are our topics, and we can access them using svdmodel.components. \n",
        "#Finally, let’s print a few most important words in each of the 20 topics and see how our model has done"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sQ1c59xfvy4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "terms = vectorizer.get_feature_names()\n",
        "\n",
        "for i, comp in enumerate(svd_model.components_):\n",
        "    terms_comp = zip(terms, comp)\n",
        "    sorted_terms = sorted(terms_comp, key= lambda x:x[1], reverse=True)[:7]\n",
        "    print(\"Topic \"+str(i)+\": \")\n",
        "    for t in sorted_terms:\n",
        "        print(t[0])\n",
        "        print(\" \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bo84SOZufvwn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Topics Visualization\n",
        "import umap.umap_ as umap\n",
        "\n",
        "X_topics = svd_model.fit_transform(X)\n",
        "embedding = umap.UMAP(n_neighbors=150, min_dist=0.5, random_state=12).fit_transform(X_topics)\n",
        "\n",
        "plt.figure(figsize=(7,5))\n",
        "plt.scatter(embedding[:, 0], embedding[:, 1], \n",
        "c = dataset.target,\n",
        "s = 10, # size\n",
        "edgecolor='none'\n",
        ")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}